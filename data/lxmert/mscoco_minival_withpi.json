[{"img_id": "COCO_val2014_000000368978", "labelf": {"gqa": [{"runway": 1.0}, {"runway": 1.0}, {"air": 1.0}, {"air": 1.0}, {"bottom": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"yes": 1.0}], "visual7w": [{"Air France.": 1.0}, {"In the air.": 1.0}, {"People.": 1.0}, {"Land.": 1.0}, {"Because it is about to land.": 1.0}, {"Green.": 1.0}], "vqa": [{"yes": 1}, {"coming": 1, "going": 1, "yes": 0.3}, {"2": 0.9, "4": 1}, {"evergreen": 0.3, "forest": 0.3, "maple": 0.3, "pine": 1}, {"no": 1, "yes": 1}]}, "sentf": {"gqa": ["Which place could this be?", "Which place is it?", "What is the airplane in?", "The plane is in what?", "Is the fence in the top or in the bottom of the image?", "Is the sky overcast and white?", "Is the field grassy and wide?", "Is it an outdoors scene?", "Does the blue sky seem to be overcast?"], "visual7w": ["What does the plane say on its side?", "Where is the plane?", "What is the plane carrying?", "What is the plane about to do?", "Why is the landing gear of the plane down?", "What color is the grass?"], "vqa": ["Is this plane near a city?", "Is the plane coming or going?", "How many engines are on that plane?", "What kind of trees make the tall row from the bottom left?", "Is this plane headed into port?"], "mscoco2": ["A large airplane flying over a grassy field with trees.", "jumbo jet comes in for a landing over some trees", "An airplane taking off over a field next to a forest. "]}}, {"img_id": "COCO_val2014_000000036124", "labelf": {"vqa": [{"camera": 0.3, "cat": 1}, {"3": 0.3, "4": 0.3, "5": 0.6, "6": 1, "8": 0.3}, {"cat": 0.6, "yes": 1}]}, "sentf": {"vqa": ["What animal are you looking at?", "How many plants are there?", "Is the animal on the ground?"], "mscoco2": ["an orange and white cat is sitting under a car", "this is an image of a cat under a car."]}}, {"img_id": "COCO_val2014_000000081922", "labelf": {"gqa": [{"car": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"outdoors": 1.0}, {"car": 1.0}, {"yes": 1.0}, {"bottom": 1.0}], "visual7w": [{"In the air.": 1.0}, {"Cars.": 1.0}, {"Trees.": 1.0}, {"Soon.": 1.0}, {"Mountains.": 1.0}, {"1.": 1.0}, {"In the distance.": 1.0}, {"On the left side.": 1.0}, {"On the roadway.": 1.0}, {"In the air.": 1.0}, {"On the side of the street in the distance.": 1.0}, {"Down the street.": 1.0}, {"Above the trees in the distance.": 1.0}, {"Clear and hazy.": 1.0}, {"The trees.": 1.0}, {"The mountains.": 1.0}, {"Plane.": 1.0}, {"Airplane.": 1.0}, {"Bus.": 1.0}, {"Car.": 1.0}, {"Cars.": 1.0}, {"An airplane.": 1.0}], "vqa": [{"cars": 0.6, "highway": 0.3, "plane": 0.3, "road": 1}, {"yes": 1}, {"yes": 1}, {"landing": 1, "taking off": 1}, {"1": 1, "2": 1, "3": 0.3, "can't see": 0.3}, {"no": 1, "yes": 0.3}, {"airplane": 1, "california": 0.3, "jet": 0.6, "plane": 0.6}, {"no": 1}, {"no": 1}]}, "sentf": {"gqa": ["Above which kind of vehicle does the airplane fly?", "Does the car in front of the other car look silver?", "Is the red car in the bottom?", "Is the red car to the left or to the right of the car mirror?", "Is it outdoors or indoors?", "Which kind of vehicle is the airplane flying above?", "Is the white car in the bottom of the image?", "Where in the photo is the car, in the bottom part or in the top?"], "visual7w": ["Where is the plane?", "What is under the plane?", "What is green?", "When will it land?", "What is in the background?", "How many planes?", "Where are the mountains?", "Where are the large lights?", "Where are the cars?", "Where is the pane?", "Where are the trees?", "Where are the cars going?", "Where is the fog?", "What is the conditions?", "What is on the sides of the street?", "What is in the distance on the horizon?", "What is in the air?", "What is in th eair?", "What is in the road?", "What is in the road?", "What objects are moving across the road?", "What is moving through the sky?"], "vqa": ["What are they riding over?", "Is the plane airborne?", "Is there an airport nearby?", "Is the plane taking off or landing?", "How many doors are on the plane?", "Does this look like a windy day?", "What are these people flying?", "Is the van's passenger door open?", "Is there a body of water nearby?"], "mscoco2": ["An airplane flies low in the sky over a city street. ", "The plane is flying over top of the cars"]}}, {"img_id": "COCO_val2014_000000570349", "labelf": {"gqa": [{"sky": 1.0}, {"sky": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}], "visual7w": [{"A colorful plane.": 1.0}, {"During the day.": 1.0}, {"To show the plane.": 1.0}, {"Blue, white, red, orange and yellow.": 1.0}, {"In the air.": 1.0}, {"One.": 1.0}, {"Flying.": 1.0}], "vqa": [{"white": 1, "yellow": 1}, {"no": 1, "yes": 0.6}, {"no": 0.3, "yes": 1}]}, "sentf": {"gqa": ["Where is the airplane?", "Where is the plane?", "Are there any horses or fences?", "Do the plane and the sky have the same color?", "Is the weather clear?", "Is the sky foggy?", "Do you see any airplanes there that are not blue?"], "visual7w": ["What is this a photo of?", "When was this photo taken?", "Why was this photo taken?", "What colors are the plane?", "Where is the plane flying?", "How many planes are there?", "What is the plane doing?"], "vqa": ["What color is the nose of the plane?", "Is this a commercial plane?", "Is the plane flying sideways?"], "mscoco2": ["A plane flies over, painted in right colors. "]}}, {"img_id": "COCO_val2014_000000398385", "labelf": {"gqa": [{"left": 1.0}, {"bottom": 1.0}, {"power lines": 1.0}, {"street light": 1.0}, {"yes": 1.0}], "visual7w": [{"Blue.": 1.0}, {"Poles.": 1.0}, {"On poles.": 1.0}, {"Green.": 1.0}, {"Daytime.": 1.0}, {"Gray.": 1.0}, {"In a vehicle.": 1.0}], "vqa": [{"no": 1}, {"light": 0.3, "lights": 0.9, "power lines": 0.3, "traffic light": 0.3, "traffic lights": 0.6}, {"airplane": 0.3, "blue": 0.3, "lights": 0.3, "plane": 1, "sun": 0.3}, {"gray": 0.3, "green": 1, "red": 0.6, "white": 0.6}, {"nobody": 0.6, "traffic lights": 0.3}]}, "sentf": {"gqa": ["On which side of the photo is the mirror?", "Is the airplane in the bottom part or in the top?", "What is in the sky?", "What is on the pole that is made of steel?", "Are the wires in the sky?"], "visual7w": ["What color is the sky?", "What are the traffic lights on?", "Where are the traffic lights?", "What color are the traffic lights?", "When was the picture taken?", "What color are the poles?", "Where was the picture taken?"], "vqa": ["Is the sky overcast?", "What is connected to the poles?", "What is in the sky?", "What color is the light?", "Who is in the picture?"], "mscoco2": ["The sign shining down over the street lights"]}}, {"img_id": "COCO_val2014_000000062443", "labelf": {"vqa": [{"rectangle": 0.6, "square": 1}, {"no": 1}, {"plant": 0.3}]}, "sentf": {"vqa": ["What shape is the window similar to?", "Is this an interior shot?", "What are those things next to the window?"], "mscoco2": ["A view form under a tree of a window"]}}, {"img_id": "COCO_val2014_000000093116", "labelf": {"vqa": [{"no": 1, "yes": 0.3}, {"white": 1, "white and pink": 0.3, "white and red": 0.3}, {"plastic": 1}, {"1": 1}, {"curtain": 0.3, "protection": 0.3, "shower curtain": 0.9, "towel": 0.9}, {"bathroom": 1, "toilet": 0.3}, {"diamond": 0.3, "diamonds": 0.3, "flower": 0.3, "square": 1, "squares": 0.3, "tile": 0.3}, {"no": 1}, {"black": 0.3, "white": 1}, {"boats": 0.3, "sailboat": 0.3, "sailboats": 1}, {"beige": 0.3, "pink": 1, "red": 0.3, "tan": 0.3, "white": 0.3}, {"corner": 0.3, "in corner": 0.3, "on right": 0.3, "under sink": 1}]}, "sentf": {"vqa": ["Are there flowers on the wallpaper?", "What color is the shower curtain?", "Of what material is the shower curtain?", "How many sinks are in the bathroom?", "What is the pink item used for?", "What is this room?", "What geometric shape are the colored accents on the tile?", "Is there butterflies on the shower curtain?", "What color are the tiles?", "What is all over the shower curtain?", "What color is the hand towel?", "Where's the bucket?"], "mscoco2": ["A bathroom with white fixtures and a mirror above the sink. "]}}, {"img_id": "COCO_val2014_000000194875", "labelf": {"vqa": [{"no": 1}, {"bar": 1, "restaurant": 0.3}, {"motorcycle": 1, "motorcycles": 1}, {"bar": 0.3}]}, "sentf": {"vqa": ["Are the people wearing helmets?", "What type of place is this?", "What type of vehicles are parked?", "What is written at the top of the picture?"], "mscoco2": ["some people sitting behind a line of motorcycles "]}}, {"img_id": "COCO_val2014_000000533805", "labelf": {"gqa": [{"top": 1.0}], "visual7w": [{"Airplane.": 1.0}, {"Skywalk.": 1.0}, {"Terminal window.": 1.0}, {"Terminal.": 1.0}, {"Daytime.": 1.0}, {"2.": 1.0}, {"0.": 1.0}, {"1.": 1.0}], "vqa": [{"air": 0.6, "airport": 0.6, "ground": 0.3, "in air": 0.3, "sky": 0.6}, {"0": 1}, {"delta": 0.3}, {"3": 1}, {"no": 1, "yes": 0.3}, {"airport": 1, "metal": 0.3, "tower": 0.3}, {"yes": 1}, {"no": 1}, {"no": 0.3, "yes": 1}, {"2": 1, "20": 0.3, "4": 0.6, "5": 0.3, "7": 0.3}, {"0": 1}, {"no": 1}, {"no": 1, "yes": 0.6}, {"no": 1}, {"no": 0.3, "yes": 1}, {"air": 0.3, "airport": 0.9, "in air": 0.3, "sky": 0.3, "tarmac": 0.3, "yes": 0.3}, {"airplane": 1, "airplanes": 0.3, "plane": 0.6, "planes": 0.3}, {"1": 1, "2": 0.3}, {"no": 1}]}, "sentf": {"gqa": ["Which part of the picture is the airplane in, the top or the bottom?"], "visual7w": ["What is in the air?", "What is docked on the airplane?", "What is the person looking through?", "Where is this shot?", "When was this taken?", "How many airplanes are shown?", "How many people are in the shot?", "How many airplanes are flying?"], "vqa": ["Where is the plane?", "How many sconces?", "Whose name is in the picture?", "How many bars are on the window?", "Does this plane need a tune-up?", "What kind of a structure is this?", "Is the plane flying?", "Are there curtains on the window?", "Is it a sunny day?", "How many distinct objects are there?", "How many giraffes are in the picture?", "Is this a puzzle?", "Is this a private airfield?", "Are there people visible?", "Is it cloudy outside the window?", "Where is this plane?", "What can you see out the window?", "How many airplanes are in the air?", "Are there birds on the railing?"], "mscoco2": ["A plane is flying above the airport terminal"]}}, {"img_id": "COCO_val2014_000000015272", "labelf": {"gqa": [{"yes": 1.0}, {"left": 1.0}], "visual7w": [{"On the left side.": 1.0}], "vqa": [{"red": 1}, {"3": 0.3, "4": 0.3, "5": 0.6, "6": 0.6, "all": 0.9, "all of them": 0.3}, {"yes": 1}]}, "sentf": {"gqa": ["Are there glasses or traffic lights in this picture?", "On which side of the image is the signal light?"], "visual7w": ["Where is the traffic light mounted?"], "vqa": ["What color of light is on?", "How many trees have white flowers?", "Is it springtime?"], "mscoco2": ["a beautiful red bud tree full of flowers under a stop light "]}}, {"img_id": "COCO_val2014_000000000472", "labelf": {"gqa": [{"no": 1.0}, {"no": 1.0}, {"dark": 1.0}, {"yes": 1.0}], "visual7w": [{"Water.": 1.0}, {"The airplane.": 1.0}, {"In the water.": 1.0}, {"The trees and the water.": 1.0}, {"The water.": 1.0}, {"The trees.": 1.0}, {"A jet plane.": 1.0}, {"The bottom right.": 1.0}, {"The jet plane.": 1.0}, {"On the islands.": 1.0}, {"Water.": 1.0}, {"On the islands.": 1.0}, {"The island.": 1.0}, {"On the trees.": 1.0}, {"Under the plane.": 1.0}], "vqa": [{"yes": 1}, {"no": 1, "yes": 0.3}, {"bottom": 0.3, "no": 0.9, "yes": 1}, {"100 feet": 0.3, "jet": 0.3, "large": 0.6, "small": 0.3}, {"no": 1, "yes": 0.3}, {"no": 0.9, "yes": 1}]}, "sentf": {"gqa": ["Are there either motorcycles or boats?", "Does the water have light tone and white color?", "Is the tail yellow or dark?", "Does the water have dark color?"], "visual7w": ["What is the plane flying over?", "What is flying in the air?", "Where are the trees?", "What is beneath the plane?", "What is gray in the image?", "What is in the water?", "What type of plane is in the air?", "Where is the writing in the image?", "What is white in the sky?", "Where are the trees growing?", "What is surrounding the islands?", "Where is the green vegetation?", "What has risen out of the water?", "Where are the green leaves?", "Where is the water?"], "vqa": ["Is that an airplane in the image?", "Is the island inhabited?", "Are the blue patches water?", "How big is the plane?", "Is the water rippling?", "Is this good weather for their flight?"], "mscoco2": ["an air plane flying in the air with water in the background"]}}, {"img_id": "COCO_val2014_000000403863", "labelf": {"vqa": [{"bathroom": 0.6, "on sink": 1, "sink": 0.6}, {"no": 1, "yes": 1}, {"yes": 1}, {"brushing teeth": 0.6, "teeth": 1, "washing": 0.3}]}, "sentf": {"vqa": ["Where is the toothbrush?", "Can this item also clean a toilet?", "Is that brush worn out?", "What is this brush used for?"], "mscoco2": ["Close up of the over-used bristles of a tooth brush"]}}, {"img_id": "COCO_val2014_000000322922", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"bicycle": 0.3, "bicycles": 1, "bikes": 0.6}, {"pink": 0.6, "pink and white": 1}]}, "sentf": {"vqa": ["Is the word fail apart of the picture?", "What vehicles are the boys riding?", "What are the colors on the bus?"], "mscoco2": ["Several bicyclists catching a ride behind a bus."]}}, {"img_id": "COCO_val2014_000000051495", "labelf": {"vqa": [{"airplane": 0.3, "wing": 0.3}, {"blue": 1}, {"yes": 1}, {"beach": 0.6, "city": 0.6, "urban": 0.3}, {"no": 1, "yes": 0.6}, {"0": 0.3, "american": 0.6, "can't tell": 0.3, "delta": 0.3, "no": 0.3, "qantas": 0.3, "qatar": 0.3, "southwest": 0.3}]}, "sentf": {"vqa": ["What is in the picture forefront?", "What color is the water?", "Was the photographer in a plane while taking this picture?", "What kind of landscape it this?", "Are there birds in the picture?", "What airline is this?"], "mscoco2": ["an image of a airplane flying over the water", "an orange and white plane in the air above the water and coast "]}}, {"img_id": "COCO_val2014_000000136833", "labelf": {"visual7w": [{"Black and white.": 1.0}, {"Two.": 1.0}, {"V464KWT.": 1.0}, {"The motorcyclist.": 1.0}, {"Neil Morales.": 1.0}, {"Looking at his bike.": 1.0}, {"Kneeling next to his bike.": 1.0}, {"Black and white.": 1.0}, {"A motorcycle.": 1.0}, {"Kneeling.": 1.0}, {"Kneeling by the bike.": 1.0}, {"A sleep roll.": 1.0}, {"Beyond the field.": 1.0}, {"Heavy clouds.": 1.0}, {"Hills.": 1.0}, {"Helmet.": 1.0}, {"2011.": 1.0}, {"V464 KWT.": 1.0}, {"Past the water on the left.": 1.0}, {"Road next to field.": 1.0}, {"A motorcycle.": 1.0}, {"River.": 1.0}, {"Checking packs on bike.": 1.0}, {"Clouds.": 1.0}, {"Mountains.": 1.0}, {"A field.": 1.0}, {"A man.": 1.0}, {"A motorcycle.": 1.0}, {"Kneeling on the road.": 1.0}, {"A bedroll.": 1.0}, {"Black and white.": 1.0}, {"Motorcycles.": 1.0}, {"Helmet.": 1.0}, {"Cloudy.": 1.0}], "vqa": [{"2": 1}, {"motorbike": 0.3, "motorcycle": 1}, {"don't know": 0.3, "no": 0.6, "yes": 1}]}, "sentf": {"visual7w": ["What format is this photo?", "How many motorbikes are present?", "What is the motorbike's plate number?", "Who has a helmet on?", "Who has copyright this photo?", "What is the man doing?", "Where is the man?", "What kind of photo is this?", "What vehicle is shown?", "What is the man doing?", "Where is the man?", "What is on the back of the first bike?", "Where is the water?", "What kind of weather is in the area?", "What geography is past the water?", "What is the man wearing on the head?", "What year was the picture taken?", "What does the license plate on the first bike read?", "Where are the hills?", "What are the bikes parked on?", "What is parked on the side of the road?", "What is winding through the terrain?", "What is the man doing?", "What is in the sky?", "What is on both sides of the water?", "What is between the motorcycles and water?", "Who is kneeling next to a motorcycle?", "What is parked behind the motorcycle?", "Where is the man?", "What is on the back of the bike?", "What is the style of the photo?", "What vehicles are shown?", "What is the person wearing on head?", "How is the sky?"], "vqa": ["How many motorcycles are in the picture?", "What is this guy riding?", "Is the guy taking a rest?"], "mscoco2": ["The two motorcycles have been pulled over on the side of the road. "]}}, {"img_id": "COCO_val2014_000000499302", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"away": 1, "both": 0.3, "camera": 0.3, "yes": 0.3}, {"sheep": 1}, {"dog": 1}, {"indian": 0.3}, {"herding": 1}, {"no": 1, "yes": 1}, {"dog": 1, "sheepdog": 0.3}, {"yes": 1}, {"farmer": 1}, {"no": 0.9, "yes": 1}, {"yes": 1}, {"no": 1, "yes": 0.3}, {"0": 0.6, "3": 1}, {"no": 0.9, "yes": 1}]}, "sentf": {"vqa": ["Is the dog running?", "Are the front three sheep looking at the camera or away?", "What kind of animals are these?", "What is following the sheep?", "What sitting position are most of the children doing?", "What is the dog doing to the animals?", "Are the sheep shorn?", "What kind of animal is next to the lamb?", "Do you a human in the picture?", "Who most likely owns this dog?", "Are the sheep sheared?", "Is there a dog herding the sheep?", "Would these animals make good house pets?", "How many goats are there?", "Has this sheep been shorn recently?"], "mscoco2": ["A dog running behind three sheep in an open field.."]}}, {"img_id": "COCO_val2014_000000155451", "labelf": {"gqa": [{"yes": 1.0}, {"pole": 1.0}, {"bottom": 1.0}, {"stormy": 1.0}, {"stormy": 1.0}], "visual7w": [{"None.": 1.0}, {"Night.": 1.0}, {"No one.": 1.0}, {"Clouds.": 1.0}, {"Buildings.": 1.0}, {"Late night.": 1.0}, {"On a city street.": 1.0}], "vqa": [{"2": 1, "3": 0.3, "5": 0.6, "6": 0.6, "green": 0.3}, {"green": 1}, {"night": 1, "night time": 0.6, "nighttime": 0.3}, {"green": 0.9, "green and red": 0.9, "green and yellow": 0.3, "yellow": 0.3}, {"no": 1, "unclear": 0.3, "yes": 0.3}]}, "sentf": {"gqa": ["Is there any lamp or pillow in the picture?", "What is the sign on?", "Is the lamp in the bottom or in the top part of the photo?", "How is the weather in the image?", "How is the weather?"], "visual7w": ["How many people are there?", "When was the photo taken?", "Who is in the photo?", "What is in the sky?", "What is in the background?", "What time is it?", "Where was the photo taken?"], "vqa": ["How many colors of traffic lights are glowing?", "What color is the light?", "Why is the sky black?", "What color are the lights?", "Are the people stopped?"], "mscoco2": ["A green traffic light under a bridge on a street"]}}, {"img_id": "COCO_val2014_000000391656", "labelf": {"vqa": [{"bathroom": 1, "toilet": 0.3}, {}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What kind of room is this in?", "Who is in the picture?", "Is this a designer bathroom?"], "mscoco2": ["A large bathroom with a Marlyn picture behind the toliet ."]}}, {"img_id": "COCO_val2014_000000098716", "labelf": {"gqa": [{"left": 1.0}, {"black": 1.0}, {"yes": 1.0}, {"pavement": 1.0}, {"pavement": 1.0}], "visual7w": [{"A cap.": 1.0}, {"Afternoon.": 1.0}, {"Because he is relaxing.": 1.0}, {"A man.": 1.0}, {"One.": 1.0}], "vqa": [{"cap": 1, "hat": 1}, {"man": 1}, {"yes": 1}, {"1": 1, "3": 0.3}, {}, {"no": 0.6, "yes": 1}]}, "sentf": {"gqa": ["On which side of the picture is the woman, the right or the left?", "Is the hat black or green?", "Is the woman to the left of a bench?", "Where is it?", "Which place is it?"], "visual7w": ["What is the man wearing on his head?", "What time of day is it?", "Why is the man leaning back on the bench?", "Who is sitting on the bench?", "How many people are sitting on the bench?"], "vqa": ["What is on the man's head?", "Who is sitting on the bench?", "Is this a black and white photo?", "How many people are on the bench?", "Is the bench occupied or vacant?", "Are they on the beach?"], "mscoco2": ["A man sitting on a bench with a view of the ocean behind him."]}}, {"img_id": "COCO_val2014_000000269105", "labelf": {"vqa": [{"green": 1}, {"not at all": 0.3, "very": 1}, {"no": 1, "yes": 0.3}]}, "sentf": {"vqa": ["What color is the wall?", "How attractive is green in this setting?", "Does the toilet match the wall?"], "mscoco2": ["A white toilet sitting next to a green wall under a picture."]}}, {"img_id": "COCO_val2014_000000102707", "labelf": {"gqa": [{"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"black": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}, {"whisk": 1.0}, {"no": 1.0}, {"stove": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"left": 1.0}], "visual7w": [{"One.": 1.0}, {"Hanging on the wall.": 1.0}, {"Funnel.": 1.0}], "vqa": [{"cup": 0.3}, {"no": 0.3, "yes": 1}, {"close": 0.3}]}, "sentf": {"gqa": ["Does the empty glass have gray color?", "Does the mug look white?", "Are there white mugs or plates?", "Which color is the whisk?", "Is the metal whisk on the left of the photo?", "Does the whisk to the right of the utensil look metallic and silver?", "Is the black mug in the bottom of the photo?", "Do you see both mats and hearts there?", "Is the spoon on the right?", "What is the name of the cooking utensil that has the same color as the mug in the top?", "Is the burner on an oven?", "Which kind of appliance is the burner on?", "Do the whisk and the mug have the same color?", "Are there either any faucets or coins?", "Which side of the image is the utensil on?"], "visual7w": ["How many funnels?", "Where is the whisk?", "What is green?"], "vqa": ["What is the green object?", "Is this a common room?", "What is the purpose of the purple object?"], "mscoco2": ["a bottle a glass and utensils behind a stove"]}}, {"img_id": "COCO_val2014_000000296459", "labelf": {"gqa": [{"right": 1.0}, {"left": 1.0}, {"no": 1.0}, {"desk": 1.0}, {"no": 1.0}, {"right": 1.0}, {"no": 1.0}, {"desk": 1.0}, {"desk": 1.0}, {"left": 1.0}, {"gray": 1.0}, {"no": 1.0}, {"right": 1.0}, {"no": 1.0}, {"left": 1.0}, {"laptop": 1.0}, {"laptop": 1.0}, {"right": 1.0}, {"no": 1.0}, {"blond": 1.0}, {"right": 1.0}, {"no": 1.0}, {"left": 1.0}, {"wallet": 1.0}, {"no": 1.0}, {"no": 1.0}, {"screen": 1.0}, {"yes": 1.0}], "visual7w": [{"1.": 1.0}, {"Brown.": 1.0}, {"Daytime.": 1.0}, {"White.": 1.0}, {"In the table.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"coffee": 1}, {"middle": 0.3, "right": 0.3, "right hand": 0.3}]}, "sentf": {"gqa": ["On which side of the picture is the gray blanket?", "Is the screen to the left or to the right of the man?", "Is the screen on the right side?", "What is the piece of furniture that the wallet is sitting on?", "Do you see any camera in the picture?", "Is he to the right or to the left of the screen that is to the right of the wallet?", "Is he wearing a coat?", "What is the wallet sitting on?", "What is the item of furniture that the mug is on?", "Is the man to the right or to the left of the blanket that looks gray?", "What is the color of the blanket to the right of the man?", "Is the man to the right of a lady?", "Is the blanket to the left or to the right of the man?", "Are there any cell phones to the right of the wallet?", "On which side is the laptop?", "Is that a laptop or a television?", "What type of device is to the right of the wallet that is sitting on the desk?", "Is the wood chair on the left side or on the right?", "Is there a red pillow or blanket?", "Which color is the man's hair, blond or black?", "Is the keyboard to the left or to the right of the screen on the left of the image?", "Are there both windows and doors in the picture?", "On which side is the wallet, the right or the left?", "What is sitting on the desk?", "Is the man typing on a phone?", "Is the person to the right of the wallet wearing a glove?", "Which kind of device is to the left of the keyboard?", "Is the chair on the right?"], "visual7w": ["How many people are there?", "What is the color of the chair?", "When is the picture taken?", "What is the color of the cup?", "Where is the laptop kept?"], "vqa": ["Does this person need to wash his hair?", "What kind of cup is near the mouse?", "Which fingers are off the keyboard?"], "mscoco2": ["The man is sitting in front of a laptop with his hands over it. "]}}, {"img_id": "COCO_val2014_000000440575", "labelf": {"gqa": [{"no": 1.0}, {"right": 1.0}, {"no": 1.0}, {"sky": 1.0}, {"silver": 1.0}], "visual7w": [{"Pilot.": 1.0}, {"Mountains and cities.": 1.0}, {"Up in the sky.": 1.0}, {"Mountains.": 1.0}, {"Buildings.": 1.0}, {"Clouds.": 1.0}, {"Second building from the left.": 1.0}, {"Gray.": 1.0}, {"Gray.": 1.0}, {"Gray.": 1.0}, {"Gray.": 1.0}, {"2.": 1.0}, {"One.": 1.0}, {"2.": 1.0}, {"One.": 1.0}, {"White.": 1.0}, {"Airplane.": 1.0}, {"Mountains.": 1.0}, {"Buildings.": 1.0}, {"One.": 1.0}, {"White.": 1.0}], "vqa": [{"no": 1, "yes": 0.6}, {"no": 1}, {"no": 1, "yes": 0.3}, {"taking off": 1}, {"0": 0.3, "12": 0.3, "16": 0.3, "2": 0.3, "4": 1, "6": 0.3}, {"yes": 1}, {"taking off": 1}, {"can't tell": 0.3, "take off": 1}, {"airplane": 1, "plane": 1}, {"airplane": 0.9, "buildings": 1, "white": 0.3}]}, "sentf": {"gqa": ["Is the weather cloudy in the scene?", "Which side is the silver airplane on?", "Are there kites in the sky?", "Where is the airplane?", "Does the plane in the sky appear to be silver or orange?"], "visual7w": ["Who is driving the plane?", "What is in the background?", "Where is the plane going?", "What is in the background of the photo?", "What is at the bottom of the photo?", "What is the white stuff around the mountain?", "Where is the tallest building?", "What color is the sky?", "What color are the mountains?", "What color is the plane?", "What color are the buildings?", "How many mountains are there?", "How many planes are there?", "How many wings are on the plane?", "How many tails are there?", "What color is the smoke?", "What vehicle is in the photo?", "What are the organic structures in the background?", "What are the man made structure in front of the mountains?", "How many airplanes are in the sky?", "What color is the plane?"], "vqa": ["Is this an airport?", "Is the plane landing?", "Is there a bridge in the picture?", "Is the airplane taking off or landing?", "How many tires are on the plate?", "Is clouds covering the mountain top?", "Is this plane landing or taking off?", "What phase of flight is the airplane in?", "What is in the sky?", "What's closer to the mountains, the airplane or the buildings?"], "mscoco2": ["a passenger jet plane beginning its ascent over a city in the mountains"]}}, {"img_id": "COCO_val2014_000000371151", "labelf": {"visual7w": [{"Red.": 1.0}, {"Upright.": 1.0}, {"Fire.": 1.0}, {"Night.": 1.0}, {"In the living room.": 1.0}, {"In a house.": 1.0}, {"A framed photo.": 1.0}, {"On a clock.": 1.0}, {"On fireplace mantle.": 1.0}, {"Wall.": 1.0}, {"A photograph.": 1.0}, {"A clock.": 1.0}, {"Fire.": 1.0}], "vqa": [{"no": 1}, {"no": 1}, {"fireplace": 0.9, "house": 0.3, "living room": 1, "room": 0.3}, {"no": 1, "yes": 0.6}, {"0": 0.6, "1": 0.6, "12": 0.3, "7": 0.3, "can't see": 0.3, "not sure": 0.3, "nothing": 0.3}, {"drawing": 0.3, "photo": 0.3, "picture": 1}, {"0": 1}, {"10:05": 0.3, "1:45": 0.3, "1:50": 0.6, "2:50": 0.6, "3:00": 0.3}, {"no": 1, "yes": 0.3}, {"1": 1, "2": 0.3}, {"yes": 1}, {"10:10": 0.9, "1:50": 1, "2:10": 0.3, "2:50": 0.3, "can't see": 0.3}, {"can't tell": 0.3, "fireplace": 1, "mantle": 0.3, "no": 0.3}, {"no": 1, "yes": 0.6}]}, "sentf": {"visual7w": ["What color is the fire?", "How is the picture on the wall placed?", "What is beneath the chimney?", "When was the photo taken?", "Where was the photo taken?", "Where does the scene take place?", "What is hanging on the wall?", "Where are roman numerals?", "Where is the clock?", "What has been painted white?", "What has been framed?", "What is the object on the center of the mantle?", "What is the red object in the fireplace?"], "vqa": ["Could you use these items for a Business?", "Will the clock fall on someone?", "What kind of space is this?", "Is that a real fireplace?", "What no is written on top of the pic?", "What is on the wall above the fireplace?", "How many computers are visible?", "What time is on the clock?", "Is there a skull anywhere?", "How many clocks?", "Is this in a home?", "What time is it?", "What is the picture on the wall hanging over?", "Is there a religious statue?"], "mscoco2": ["a clock on a fire place with a picture above"]}}, {"img_id": "COCO_val2014_000000470623", "labelf": {"gqa": [{"green": 1.0}, {"road": 1.0}, {"cat": 1.0}, {"no": 1.0}], "visual7w": [{"One.": 1.0}, {"Orange.": 1.0}, {"Under the car.": 1.0}], "vqa": [{"car": 1}, {"brown": 0.6, "gold": 0.3, "orange": 1}, {"nissan": 1, "suv": 0.3, "tabby": 0.3, "toyota": 0.3}]}, "sentf": {"gqa": ["Is the grass tan or green?", "Which place is it?", "Which kind of animal is to the right of the fence?", "Is the fence to the right of the cat in the middle?"], "visual7w": ["How many cats under the car?", "What is the color of the cat?", "Where is the cat?"], "vqa": ["What is the cat hiding under?", "What color is the cat?", "What kind of car is that?"], "mscoco2": ["a cat sits down under neath a car "]}}, {"img_id": "COCO_val2014_000000378502", "labelf": {"vqa": [{"green": 1}, {"black": 1}, {"no": 1, "yes": 0.6}, {"motorcycle": 1}]}, "sentf": {"vqa": ["What color are the traffic lights?", "What color is the man's shirt?", "Is this man wearing a helmet?", "What is the man riding?"], "mscoco2": ["A man riding on the back of a motorcycle behind a red car."]}}, {"img_id": "COCO_val2014_000000335827", "labelf": {"vqa": [{"no": 0.3, "yes": 1}, {"3": 0.3, "5": 1, "6": 0.9, "7": 0.3}, {"1": 0.3, "10": 0.3, "3": 1, "5": 0.3, "6": 0.3}]}, "sentf": {"vqa": ["Is this a church?", "How many windows are there?", "How many rooms in this building?"], "mscoco2": ["Church tower, beige stone color under partly cloudy skies. "]}}, {"img_id": "COCO_val2014_000000213375", "labelf": {"vqa": [{"green": 1}, {"2": 1, "3": 1}, {"cameraman": 0.3, "man": 1, "someone": 0.3, "unknown": 0.3}, {"television": 0.6, "tv": 1}]}, "sentf": {"vqa": ["Color behind urinals?", "How many urinals are shown?", "Who is taking this photo?", "What is the entertainment?"], "mscoco2": ["A television on the wall above two urinals.  "]}}, {"img_id": "COCO_val2014_000000310611", "labelf": {"vqa": [{"giraffe": 1}, {"no": 1}, {"no": 1, "nothing": 0.3}, {"no": 1, "yes": 1}, {"giraffe": 1}, {"3": 1, "4": 0.6}]}, "sentf": {"vqa": ["What kind of animal is this?", "Is there other animals besides giraffes?", "Is the animal eating?", "Are these giraffes standing to full height?", "What animal is behind the fence?", "How many legs are visible on the giraffe?"], "mscoco2": ["a giraffe walking behind a fence near a building"]}}, {"img_id": "COCO_val2014_000000518262", "labelf": {"vqa": [{"cement": 0.3, "ground": 0.3, "pavement": 0.6, "sidewalk": 1}, {"2": 1}, {"jeans": 1, "tennis shoes": 0.3}]}, "sentf": {"vqa": ["What are the people standing on?", "How many animals are in this photo?", "What is that woman wearing?"], "mscoco2": ["a little dog standing behind a much bigger one "]}}, {"img_id": "COCO_val2014_000000257270", "labelf": {"gqa": [{"right": 1.0}, {"road": 1.0}, {"road": 1.0}, {"no": 1.0}, {"no": 1.0}, {"left": 1.0}], "visual7w": [{"One.": 1.0}, {"Across the white lines.": 1.0}, {"Green.": 1.0}, {"Daytime.": 1.0}, {"A truck.": 1.0}, {"Blue.": 1.0}, {"Brick.": 1.0}, {"Back of motorcycle.": 1.0}, {"Three stories.": 1.0}, {"In the truck.": 1.0}, {"USA.": 1.0}, {"Chrome.": 1.0}, {"Nothing.": 1.0}, {"Steering a motorcycle.": 1.0}, {"On back of the motorcycle.": 1.0}, {"Rectangular.": 1.0}, {"On the road.": 1.0}, {"Round.": 1.0}, {"On a building.": 1.0}, {"A motorcycle.": 1.0}], "vqa": [{"harley": 0.9, "harley davidson": 0.3, "modern": 0.3, "white": 0.3, "yamaha": 0.6}, {"no": 1, "yes": 1}, {"no": 1}, {"1": 1, "80": 0.3}, {"yes": 1}]}, "sentf": {"gqa": ["On which side is the can, the left or the right?", "What place could this be?", "Where is the bike?", "Is the truck on the left side?", "Is there a bus on the road?", "On which side of the photo is the car?"], "visual7w": ["How many motorcycles are there?", "Where is the motorcycle parked?", "What color is the truck?", "When was the picture taken?", "What is dark green?", "What is the license plate color?", "What is the building made of?", "Where are the pipes?", "How tall is the building?", "Where will leaves fall?", "What nation's flag is visible?", "What metal is the tailpipe?", "What is in the truck bed?", "What is the handle used for?", "Where is a license plate?", "What shape is the license plate?", "Where are the cars?", "What shape are the car's tires?", "Where are brown bricks?", "What has handlebars?"], "vqa": ["What kind of motorcycle sitting next to the road?", "Would a short person be able to ride this motorcycle?", "Is this motorcycle parked properly?", "What number of motorcycles are on the sidewalk?", "Is there a green truck parked by the curb?"], "mscoco2": ["A motorcycle parked behind a green truck near buildings.."]}}, {"img_id": "COCO_val2014_000000510230", "labelf": {"vqa": [{}, {"green and red": 0.9, "red and green": 0.9}, {"2": 0.3, "3": 1}]}, "sentf": {"vqa": ["What is the name on the Avenue sign?", "What are the color of the signs?", "How many signs are on the pole?"], "mscoco2": ["a street sign with a stop sign below it "]}}, {"img_id": "COCO_val2014_000000234938", "labelf": {"gqa": [{"no": 1.0}, {"blue": 1.0}], "vqa": [{"yes": 1}, {"yes": 1}, {"closed": 0.6, "i don't know": 0.3}, {"100": 0.9, "1000": 0.3, "200": 0.3, "38": 0.3, "50": 0.3, "many": 0.3}]}, "sentf": {"gqa": ["Is the umbrella open and white?", "What color is the umbrella?"], "vqa": ["Are there any trees visible?", "Is this a restaurant?", "Why are there no people on the deck?", "How many boards make up the deck?"], "mscoco2": ["A bench table is under a white umbrella on the outside of a restaurant. "]}}, {"img_id": "COCO_val2014_000000539226", "labelf": {"vqa": [{"light": 1}, {"no": 1}, {"1": 1}, {"no": 0.3, "yes": 1}, {"no": 1}, {"blue": 1, "bright": 0.3}, {"silver": 0.3, "white": 1}, {"no": 1, "yes": 1}, {"bird": 1}, {"no": 1}, {"no": 1}, {"don't know": 0.3, "no": 1}, {"lamp": 0.3, "light": 0.3, "pole": 0.3, "street light": 0.3}, {"blue": 1}, {"no": 1, "yes": 0.6}, {"airplane": 1, "plane": 1, "street light": 0.3}]}, "sentf": {"vqa": ["Is it light or dark outside?", "Are there clouds in the sky?", "How many lights are pictured?", "Is the area where this was taken well lit?", "Is this a car?", "What color is this picture?", "What color is the nose of the plane?", "Is this a new plane?", "What is sitting on the lamp post?", "Is the sky cloudy?", "Are there clouds?", "Will that airplane crash?", "What else is in the picture beside the airplane?", "What color is the background?", "Is there a camera on the pole?", "What is this?"], "mscoco2": ["An airplane flying a in clear sky above a light."]}}, {"img_id": "COCO_val2014_000000281827", "labelf": {"gqa": [{"top": 1.0}], "visual7w": [{"Airplane.": 1.0}, {"Bird.": 1.0}, {"Two.": 1.0}, {"Left side.": 1.0}, {"Daytime.": 1.0}, {"Blue.": 1.0}, {"Black.": 1.0}, {"Airplane.": 1.0}, {"A bird.": 1.0}, {"A plane.": 1.0}, {"Solar.": 1.0}, {"Buildings.": 1.0}, {"Clear.": 1.0}, {"Grey.": 1.0}, {"2.": 1.0}, {"Blue.": 1.0}, {"Round.": 1.0}, {"In the sky.": 1.0}, {"The sky.": 1.0}, {"The plane.": 1.0}, {"Cloudy.": 1.0}, {"Clouds.": 1.0}, {"Away from the building.": 1.0}, {"The plane.": 1.0}, {"Bird.": 1.0}, {"Gray.": 1.0}, {"Brown.": 1.0}, {"Airplane.": 1.0}, {"Sky.": 1.0}, {"Near plane.": 1.0}, {"Tall.": 1.0}, {"Gray.": 1.0}, {"Windows.": 1.0}, {"Towers.": 1.0}], "vqa": [{"in sky": 1, "sky": 1}, {"airplane": 1, "plane": 0.9}, {"no": 1, "yes": 0.6}, {"1": 0.6, "2": 1, "5": 0.3}, {"no": 0.6, "yes": 1}, {"no": 0.3, "yes": 1}, {"no": 1, "yes": 0.6}, {"1": 0.3, "2": 1}]}, "sentf": {"gqa": ["In which part of the image is the airplane, the top or the bottom?"], "visual7w": ["What is in the sky?", "What is next to the plane in the sky?", "How many buildings are there?", "What side are the cylinders?", "When was the picture taken?", "What color is the sky?", "What color is the bird?", "What mode of transportation is in the air?", "What animal is in the sky?", "What machine is in the sky?", "What type of panels providing electricity are shown?", "What are the grey structures in the background?", "How is the weather?", "What shade are the buildings?", "How many engines on the plane?", "What coloring is the label on the water tower?", "What is the shape of the towers?", "Where is the plane?", "Where is the bird?", "What is the bird flying next to?", "How is the weather?", "Why is the sky grey?", "What direction is the plane flying?", "What is flying higher?", "What is flying lower?", "What shade is the sky?", "What is the shade of the building?", "What is flying near the building?", "Where is the plane?", "Where is the building?", "What length is the building?", "What shade is the building?", "What does the building have on it?", "What is there a group of?"], "vqa": ["Where is the plane?", "What is flying in the sky?", "Would the air smell salty here?", "How many skyscrapers are there?", "Is the plane going fast?", "Is there a big bird next to the plane?", "Is this a factory?", "How many building's are next to the plane?"], "mscoco2": ["The airplane and bird are flying above the skyscraper ", "a big plane flying through the air over some building"]}}, {"img_id": "COCO_val2014_000000484986", "labelf": {"vqa": [{"12": 0.3, "2": 0.6, "3": 0.6, "4": 1, "5": 0.3}, {"no": 1, "yes": 0.6}, {"no": 1}, {"no": 1, "yes": 0.3}]}, "sentf": {"vqa": ["How many mountains are in the image?", "Is this the Sahara Desert?", "Is there snow on the mountains in the picture?", "Are the mountains covered in trees?"], "mscoco2": ["Overhead view of various mountain tops from above. ", "A plane flys over a range of mountains"]}}, {"img_id": "COCO_val2014_000000504827", "labelf": {"vqa": [{"clear": 1, "gray": 0.3, "silver": 0.6, "white": 0.3}, {"no": 1}, {"bathroom": 1, "toilet": 0.3}, {"1": 1}, {"clear": 1, "white": 0.6, "yes": 0.3}, {"no": 1}, {"1": 1, "2": 0.3}, {"0": 0.3, "1": 1}, {"yes": 1}, {"above toilet": 1, "by window": 0.3, "cabinet": 0.3, "on wall": 0.3, "wall": 0.6}]}, "sentf": {"vqa": ["What color is the soap in the dispenser?", "Is this a hotel bathroom?", "What kind of room is this?", "How many towels?", "What color is the soap pictured?", "Is this a living room?", "How many windows can be seen in this picture?", "How many mirrors?", "Would you consider this bathroom modern?", "Where is the mirror?"], "mscoco2": ["A bathroom that has a medicine cabinet over the toilet. "]}}, {"img_id": "COCO_val2014_000000315501", "labelf": {"vqa": [{"nothing": 1, "surfboard": 0.3, "surfboards": 0.3, "wood": 0.9}, {"black": 1, "red": 1}, {"20": 0.3, "don't know": 0.3, "large": 0.3, "medium": 0.3, "small": 0.3}, {"0": 0.6, "not possible": 0.3, "unknown": 0.3}, {"yes": 1}]}, "sentf": {"vqa": ["What is on the hood of the car?", "What color car is in the picture on the wall?", "What size are the rims?", "What is the license plate number?", "Is the car driveable?"], "mscoco2": ["There is a classic, black automobile sitting in a showroom. There are people looking at it in the background. "]}}, {"img_id": "COCO_val2014_000000081103", "labelf": {"visual7w": [{"The brand is Suzuki.": 1.0}, {"The man in the black shirt.": 1.0}, {"The motorcycle seat is black.": 1.0}, {"The motorcycle has two tires.": 1.0}, {"A turn signal lamp is located just above the silver fender.": 1.0}, {"It is down to keep it from falling.": 1.0}, {"It is placed on the seat.": 1.0}, {"It has a silver fender over it.": 1.0}, {"Red.": 1.0}, {"A man.": 1.0}, {"Oil.": 1.0}, {"Tee shirt.": 1.0}, {"Exhaust pipe.": 1.0}, {"Suzuki.": 1.0}, {"Leather seat.": 1.0}, {"Cruiser motorcycle style.": 1.0}, {"Kickstand.": 1.0}, {"By holding onto the bike.": 1.0}, {"On top of the motorcycle seat.": 1.0}, {"Motorcycle suspension.": 1.0}, {"Right foot brake.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"fast": 0.3, "very fast": 0.6}, {"suzuki": 1}]}, "sentf": {"visual7w": ["What is the brand of the motorcycle?", "Who is touching the motorcycle?", "What color is the motorcycle seat?", "How man tires does the motorcycle have?", "What is located just above the rear silver fender?", "Why is the kickstand down on the motorcycle?", "Where is the man's right hand placed on the motorcycle?", "What does the motorcycle front tire have over it?", "How is the motorcycle painted?", "Who is in the photo?", "What bottles are visible behind the motorcycle?", "What type of shirt is the man wearing?", "What kind of pipe is near the wheel?", "What brand is this bike?", "What kind of seat is on the motorcycle?", "What kind of style is this motorcycle?", "What is keeping this motorcycle upright?", "How is the man bending over?", "Where is the man's hand located?", "What is above the exhaust pipe?", "What object is to the right of the exhaust pipe?"], "vqa": ["Are the tires wet?", "How fast can this bike go?", "What brand motorcycle is this?"], "mscoco2": ["The man is bent over and looking at something on the bike"]}}, {"img_id": "COCO_val2014_000000446113", "labelf": {"vqa": [{"no": 1, "yes": 0.6}, {"no": 0.6, "yes": 1}, {"yes": 1}, {"4": 1, "5": 0.6}, {"no": 1}, {"2": 0.3, "6": 0.6, "7": 1}, {"no": 1, "yes": 1}, {"no": 1, "yes": 0.3}, {"2": 0.3, "7": 1, "8": 0.3}]}, "sentf": {"vqa": ["Is the plane in the center of the runway?", "Are weather conditions suitable to fly this plane?", "Is there a train?", "How many utility poles do you see in this picture?", "Is the plane landing?", "How many train cars can you see in this picture?", "Is this a good area to fly kites?", "Is the plane on a runway?", "How many train cars are there?"], "mscoco2": ["a small air plane in a field with a train in the background "]}}, {"img_id": "COCO_val2014_000000128461", "labelf": {"visual7w": [{"Plane.": 1.0}, {"The plane.": 1.0}, {"In the sky.": 1.0}, {"Airplane.": 1.0}, {"Daytime.": 1.0}, {"To fly.": 1.0}, {"On the plane.": 1.0}, {"One.": 1.0}, {"Underside of the plane.": 1.0}, {"In the sky.": 1.0}, {"Flying.": 1.0}, {"With wings and engines.": 1.0}, {"With a grey stripe.": 1.0}, {"Clear.": 1.0}, {"On the wings.": 1.0}, {"Small.": 1.0}, {"The tail.": 1.0}, {"Passengers.": 1.0}, {"An airplane.": 1.0}, {"Wings.": 1.0}, {"Clear and blue.": 1.0}, {"The belly.": 1.0}, {"The sky.": 1.0}, {"Windows.": 1.0}], "vqa": [{"no": 1, "yes": 1}, {"no": 1, "yes": 0.3}, {"no": 1}, {"no": 0.9, "yes": 1}]}, "sentf": {"visual7w": ["What is in the sky?", "What is white?", "Where is an airplane?", "What has wings?", "When was the picture taken?", "Why does the plane have wings?", "Where are windows?", "How many planes are in the picture?", "What side of the plane is shown?", "Where is the plane?", "What is the plane doing?", "How does the plane fly?", "How is the plane decorated?", "How is the weather?", "Where are the plane's engines?", "What size are the plane's windows?", "What is on the rear of the plane?", "Who rides in the plane?", "What is taking off in the sky?", "What is sticking out of the sides?", "How is the sky?", "What is on the bottom of the plane?", "What is vibrant?", "What is aligned all along the length of the plane?"], "vqa": ["Is this the perspective of  a passenger?", "Is there any clouds in the sky?", "Do soldiers parachute from these planes?", "Is this a commercial jet?"], "mscoco2": ["the plane has a white bottom and  is flying over head "]}}, {"img_id": "COCO_val2014_000000287190", "labelf": {"visual7w": [{"One.": 1.0}, {"A nightgown.": 1.0}, {"Black and red.": 1.0}, {"In a bedroom.": 1.0}], "vqa": [{"no": 1}, {"no": 1}, {"black": 1, "black and orange": 0.3, "black and red": 0.6}, {"blonde": 0.3, "brown": 1, "red": 1}]}, "sentf": {"visual7w": ["How many people are in the picture?", "What is the woman wearing?", "What color is the the women's night gown?", "Where was the picture taken?"], "vqa": ["Is she wearing long sleeves?", "Can her eyes be seen?", "What color is this wife beater?", "What color is her hair?"], "mscoco2": ["A woman with a purple cloth over her eyes and head. "]}}, {"img_id": "COCO_val2014_000000374017", "labelf": {"gqa": [{"no": 1.0}, {"bed": 1.0}, {"no": 1.0}, {"woman": 1.0}, {"bed": 1.0}, {"floor": 1.0}, {"bed": 1.0}, {"bed": 1.0}, {"bed": 1.0}, {"no": 1.0}, {"sculpture": 1.0}, {"sculpture": 1.0}, {"wall": 1.0}, {"pillow": 1.0}, {"no": 1.0}, {"woman": 1.0}], "visual7w": [{"Blurry.": 1.0}, {"A woman.": 1.0}, {"White.": 1.0}, {"A lady.": 1.0}, {"Relaxing.": 1.0}, {"In a bedroom.": 1.0}], "vqa": [{"hardwood": 0.3, "wood": 1}, {"no": 1, "yes": 1}, {"no": 1, "yes": 0.3}, {"clothes": 0.3, "laying down": 0.3, "nothing": 0.3, "pajamas": 0.9, "sheet": 0.3}]}, "sentf": {"gqa": ["Is the wall behind a couch?", "What is the woman in?", "Is the woman resting on a towel?", "Who is in the bed on the floor?", "What piece of furniture is the same color as the wall behind the sculpture?", "Where is the bed?", "What is the piece of furniture on the floor?", "Which kind of furniture is on the floor?", "What is on the floor?", "Do you see chairs on the floor that is below the woman?", "What is before the wall?", "What is in front of the wall?", "What is the sculpture in front of?", "What is the woman resting on?", "Are there toilets above the hardwood floor?", "Who is in the bed?"], "visual7w": ["How is the photo?", "What is in the photo?", "What color is dominant in the photo?", "Who is present?", "What is the lady doing?", "Where was this photo taken?"], "vqa": ["What is the floor made of?", "Is the woman real?", "Is she praying?", "What is the woman wearing?"], "mscoco2": ["A woman sits under the sheet on a mattress on the floor."]}}, {"img_id": "COCO_val2014_000000574357", "labelf": {"gqa": [{"biker": 1.0}, {"biker": 1.0}, {"bike": 1.0}, {"jacket": 1.0}, {"no": 1.0}, {"trees": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"no": 1.0}], "visual7w": [{"One.": 1.0}, {"Green.": 1.0}, {"Red.": 1.0}], "vqa": [{"red": 1}, {"helmet": 1}, {"bike": 0.6, "moped": 0.3, "motorcycle": 1}]}, "sentf": {"gqa": ["Who is wearing a jacket?", "Who is wearing the jacket?", "What is the bag on?", "What is the biker wearing?", "Are there boats or tools?", "What is the water surrounded by?", "Is the water surrounded by the green trees?", "Are the trees surrounding the water?", "Is the jacket white?"], "visual7w": ["How many people are in the picture?", "What color is the trees?", "What color is the duffle bag on the motorcycle?"], "vqa": ["What color is the bag?", "What is the person wearing on their head?", "What type of vehicle is the person riding?"], "mscoco2": ["The motorcyclist in a helmet is looking over the side of a bridge. ", "Woman with a motorcycle staring over a bridge at a wetlands. "]}}, {"img_id": "COCO_val2014_000000035313", "labelf": {"gqa": [{"woman": 1.0}, {"bench": 1.0}, {"car": 1.0}, {"woman": 1.0}, {"no": 1.0}, {"car": 1.0}, {"car": 1.0}, {"shirt": 1.0}, {"shirt": 1.0}, {"shirt": 1.0}, {"skirt": 1.0}, {"no": 1.0}, {"woman": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"car": 1.0}, {"left": 1.0}, {"black": 1.0}, {"walkway": 1.0}, {"walkway": 1.0}, {"no": 1.0}, {"woman": 1.0}], "visual7w": [{"One.": 1.0}, {"Near a parking lot.": 1.0}, {"On a bench.": 1.0}, {"None.": 1.0}, {"A wooden bench.": 1.0}, {"Three.": 1.0}, {"Two.": 1.0}, {"Glasses.": 1.0}, {"Black.": 1.0}, {"A bench.": 1.0}, {"Glasses.": 1.0}, {"Stern.": 1.0}, {"Three.": 1.0}, {"Black and white.": 1.0}, {"CC-338XL.": 1.0}, {"Sun's reflecting on it.": 1.0}, {"Two.": 1.0}, {"A bench.": 1.0}, {"A woman.": 1.0}, {"Next to building.": 1.0}, {"Behind the bench.": 1.0}, {"On bench.": 1.0}, {"Under the lady.": 1.0}, {"On the cars.": 1.0}, {"`cars.": 1.0}, {"A lady.": 1.0}], "vqa": [{"no": 1}, {"60": 0.3, "65": 0.3, "70": 0.3, "75": 0.6, "80": 0.9, "90": 0.3}, {"3": 1}]}, "sentf": {"gqa": ["Who is sitting on the bench that is made of wood?", "What is the woman sitting on?", "Which kind of vehicle is the bench in front of?", "Who is sitting?", "Is there a woman in the scene that is not old?", "What kind of vehicle is behind the bench?", "What kind of vehicle is behind the wood bench?", "What kind of clothing is black, the shirt or the woman's skirt?", "Which kind of clothing is black?", "How is the clothing item that is black called?", "Which kind of clothing is not black?", "Is the mirror on the left of the picture?", "Who do you think is wearing a shirt?", "Are the glasses to the left of a car?", "Does she appear to be standing?", "Are there cars to the right of the mirror that is on the right side?", "What is the vehicle that is to the left of the mirror in the top part?", "Are the glasses to the right or to the left of the car that the bench is in front of?", "What color do you think the shirt that she is wearing is?", "What is the image showing?", "Which place is it?", "Is she sitting on a chair?", "Who is wearing the shirt?"], "visual7w": ["How many people are in this picture?", "Where was this photo taken?", "Where is this person sitting?", "How many people are sitting on the bench further away?", "What kind of bench is in this photo?", "How many cars are in this picture?", "How many benches are visible?", "What is this person wearing on their face?", "How is the old woman's shirt colored?", "What is the woman sitting down on?", "What is on the woman's eyes?", "What is the old woman's facial expression?", "What is the number of cars that are in the picture?", "How is the picture colored?", "What is the license plate number of the first car?", "Why is there a shadow on the other bench?", "What is the number of legs that are present in the picture?", "Where is the elderly woman?", "Who is wearing a black sweater?", "Where is the white car?", "Where is the gray van parked?", "Where is the lady sitting?", "Where is the wooden bench?", "Where is the plate with numbers?", "What is behind bench?", "Who is on the bench?"], "vqa": ["Does this woman look happy?", "Approximately what age is the woman in the photo?", "How many vehicles are in the scene?"], "mscoco2": ["A woman sitting on a bench with cars behind her."]}}, {"img_id": "COCO_val2014_000000543686", "labelf": {"gqa": [{"white": 1.0}, {"left": 1.0}, {"cat": 1.0}, {"cat": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"mat": 1.0}, {"no": 1.0}, {"mat": 1.0}, {"bowl": 1.0}, {"bowl": 1.0}, {"shelf": 1.0}, {"shelf": 1.0}, {"cat": 1.0}, {"yes": 1.0}, {"carpet": 1.0}, {"carpet": 1.0}, {"left": 1.0}, {"black": 1.0}, {"yes": 1.0}, {"empty": 1.0}, {"mat": 1.0}, {"no": 1.0}], "visual7w": [{"Now.": 1.0}, {"One.": 1.0}, {"In the kitchen.": 1.0}, {"He is thirsty.": 1.0}, {"Green.": 1.0}, {"Cokes.": 1.0}, {"A rug.": 1.0}], "vqa": [{"drinking": 1, "drinking water": 0.6, "eating": 0.6}, {"white": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"gqa": ["What color is the tail?", "Is the mat on the right or on the left side?", "On which kind of animal is the collar?", "What animal is the collar on?", "Is the bowl white?", "Are there napkins below the bowl on the left side?", "Are there any mats under the bowl?", "What is under the bowl?", "Is the bowl on a countertop?", "That bowl is on what?", "What is on the mat?", "What is on the mat on the left of the picture?", "How is this item of furniture called?", "How is the item of furniture to the left of the cat that the collar is on called?", "Is this a cat or a dog?", "Is the black mat on the carpet?", "The mat is on what?", "What's the mat on?", "Is the empty bowl on the right side or on the left?", "Does the mat look black or yellow?", "Is the bowl both green and empty?", "Does the bowl look empty or full?", "What is the bowl on?", "Is that shelf to the left of a book?"], "visual7w": ["When is the cat eating?", "How many cats?", "Where is the cat?", "Why is the cat drinking water?", "What is the color of the bowl?", "What is in the box?", "What is under the bowl?"], "vqa": ["What is the cat doing?", "What color is the cat?", "Is the cat full grown?"], "mscoco2": ["A cat that is standing over a bowl."]}}, {"img_id": "COCO_val2014_000000369482", "labelf": {"gqa": [{"white": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"red": 1.0}, {"ground": 1.0}], "visual7w": [{"No left.": 1.0}, {"Highway.": 1.0}, {"Overcast.": 1.0}, {"Stop.": 1.0}, {"Wire.": 1.0}, {"Leaves.": 1.0}, {"Railroad crossing.": 1.0}, {"94.": 1.0}, {"Left.": 1.0}, {"Arrow.": 1.0}, {"West.": 1.0}, {"Red.": 1.0}, {"Railroad crossing.": 1.0}, {"Left.": 1.0}, {"A railroad crossing.": 1.0}, {"I 94.": 1.0}, {"Snow.": 1.0}], "vqa": [{"railroad crossing": 0.6, "stop": 1}, {"red": 1}, {"winter": 1}, {"cloudy": 0.6, "cold": 0.9, "gray": 0.3, "overcast": 0.3}, {"yes": 1}, {"left": 1}, {"yes": 1}]}, "sentf": {"gqa": ["The sky is what color?", "Are there any mirrors or traffic lights?", "Are there either waste baskets or planters in this picture?", "What is the color of the signal light on the right side?", "The snow is where?"], "visual7w": ["What is red and white sign?", "What is ninety four?", "What is the weather like?", "What do the red lights mean?", "What are the lights hanging from?", "What is missing from the tree on the right?", "What does the white X say?", "What number is on the blue sign?", "What direction does the street light say?", "What symbol is below the 94 sign?", "What word is above the 94 sign?", "What colour is the light for left?", "What crossing is visible in the picture?", "What does the left signal say?", "What is under the traffic signals?", "What interstate is to the right?", "What is on the ground?"], "vqa": ["What does the crosswalk signal mean?", "What is the color of the lights?", "What season is it?", "What is the weather like?", "Is the light red?", "What word is above the traffic signal?", "Are all the lights red?"], "mscoco2": ["a traffic light hanging over a city street ", "a street light sitting above some train tracks "]}}, {"img_id": "COCO_val2014_000000461775", "labelf": {"gqa": [{"cat": 1.0}, {"yes": 1.0}, {"car": 1.0}, {"car": 1.0}, {"yes": 1.0}, {"cat": 1.0}, {"no": 1.0}, {"top": 1.0}, {"cat": 1.0}, {"cat": 1.0}, {"black": 1.0}], "visual7w": [{"Black.": 1.0}, {"Grey.": 1.0}, {"Grey.": 1.0}, {"One.": 1.0}, {"One.": 1.0}, {"Daytime.": 1.0}, {"White.": 1.0}, {"One.": 1.0}, {"Car.": 1.0}, {"Ground.": 1.0}, {"Sleeping.": 1.0}, {"Lying down.": 1.0}, {"Sleeping.": 1.0}, {"Pavement.": 1.0}, {"Underneath the cat.": 1.0}, {"A tire.": 1.0}, {"Ground.": 1.0}, {"A car.": 1.0}, {"Tire.": 1.0}, {"Below the cat's face.": 1.0}, {"Sleeping.": 1.0}, {"Cat.": 1.0}, {"Rubber.": 1.0}, {"Paw.": 1.0}, {"The car.": 1.0}, {"Dirt splatters.": 1.0}, {"A silver car.": 1.0}, {"Sleeping under car.": 1.0}, {"The cat.": 1.0}, {"A black and white one.": 1.0}, {"A cat.": 1.0}, {"Feline.": 1.0}, {"Car.": 1.0}], "vqa": [{"yes": 1}, {"asphalt": 1, "cement": 0.3, "concrete": 0.6, "pavement": 0.3}, {"cat": 1}]}, "sentf": {"gqa": ["What animal is under the vehicle that looks gray?", "Is the gray car above the animal that looks black and white?", "What vehicle is above the animal that looks white and black?", "What is the name of the gray vehicle?", "Is the animal under the car black and curly?", "What kind of animal is curly?", "Is the cat under an umbrella?", "In which part of the image is the car, the bottom or the top?", "What kind of animal is resting?", "What animal is it?", "What color does the animal which is under the car have?"], "visual7w": ["What color is the cat?", "What color is the pavement in this picture?", "What color is the car in this photograph?", "How many cats are in this picture?", "How many cars are in this photograph?", "When was this picture taken?", "What color is this cat's paws in this image?", "How many tires are readily visible?", "What is the cat under?", "What is the cat on?", "What is the cat doing?", "How is the cat positioned under the car?", "Why is the cat under the automobile?", "Where is the cat lying down?", "Where are the cat's paws?", "What is under the car besides the black cat?", "Where is the cat lying?", "What is above the cat?", "What black rubber car component is by the cat?", "Where is the paw of the cat?", "What is the cat doing on the ground?", "Who is relaxing under a car?", "What is the tire by the cat made of?", "What part of the cat is visibly white?", "What is giving a shadow under the car?", "What is on the car?", "What is beneath the car?", "Where is the cat?", "What is black and white?", "What kind of cat is there?", "What is taking a nap?", "What kind of animal is there?", "What is the cat under?"], "vqa": ["Is this cat sleep?", "What is the surface?", "What type of pet is shown?"], "mscoco2": ["The cat is laying under a vehicle on the pavement. "]}}, {"img_id": "COCO_val2014_000000219657", "labelf": {"vqa": [{"no": 1, "yes": 0.6}, {"no": 1}, {"yes": 1}]}, "sentf": {"vqa": ["Is the floor dry?", "Is the bathroom door closed?", "Is the toilet seat up?"], "mscoco2": ["A bathroom that has over flooded with water. "]}}, {"img_id": "COCO_val2014_000000122166", "labelf": {"gqa": [{"no": 1.0}, {"left": 1.0}, {"pedestrian": 1.0}, {"yes": 1.0}, {"woman": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"left": 1.0}, {"no": 1.0}, {"no": 1.0}, {"bicycle": 1.0}, {"no": 1.0}, {"no": 1.0}, {"car": 1.0}, {"white": 1.0}, {"pedestrian": 1.0}, {"woman": 1.0}, {"glasses": 1.0}, {"glasses": 1.0}, {"car": 1.0}, {"no": 1.0}, {"pedestrian": 1.0}, {"car": 1.0}, {"yes": 1.0}, {"woman": 1.0}], "visual7w": [{"A bike.": 1.0}, {"The woman in black.": 1.0}, {"Daytime.": 1.0}, {"Lower right corner.": 1.0}, {"White.": 1.0}, {"Green.": 1.0}], "vqa": [{"1": 1}, {"bicycle": 0.3, "bike": 1, "car": 0.6, "walking": 0.3}, {"no": 1, "yes": 0.3}, {"left": 0.3, "right": 1}]}, "sentf": {"gqa": ["Is the motorcycle to the right of the car the kiosk is behind of?", "Is the motorcycle to the right or to the left of the car that is in front of the kiosk?", "Who is walking?", "Is the person to the right of the pedestrian riding the bicycle?", "Who do you think is riding the bicycle?", "Are there skateboards in front of the sidewalk?", "Does the car in front of the kiosk have red color?", "Are there cars in front of the kiosk?", "Is the woman on the left of the picture?", "On which side of the picture is the bicycle?", "Is the motorbike to the left or to the right of the woman that is wearing glasses?", "Are there full motorcycles in the image?", "Are there any cars to the left of the woman that is on the left?", "What is the woman on?", "Do you see dogs near the man that is crossing the street?", "Do you see any motorcycles to the right of the woman that is wearing glasses?", "What is the vehicle in the street that the tree is on the side of?", "Which color is the car on the street?", "Who is wearing the clothes?", "Who is wearing the glasses?", "What's the woman wearing?", "What is the person on the bicycle wearing?", "What is the name of the vehicle that is on the street?", "Is there any bus on the street?", "Who is wearing clothes?", "What kind of vehicle is the kiosk behind of?", "Is the female person on the left?", "Who is on the bicycle?"], "visual7w": ["What is the woman riding?", "Who is in the background?", "When was the picture taken?", "Where is the photographer's logo?", "What color is the truck parked behind the woman on the bike?", "What color are the trees?"], "vqa": ["How many people are on bikes?", "What is the man riding?", "Is this scene in an American city?", "On what side of the road do they drive in this photo?"], "mscoco2": ["The cars are travelling behind the guy on the bicycle"]}}, {"img_id": "COCO_val2014_000000153803", "labelf": {"vqa": [{"both": 0.9, "standing": 0.6, "yes": 0.3}, {"gray": 0.3, "silver": 1, "white": 1}, {"yes": 1}]}, "sentf": {"vqa": ["Are people, in the background, standing and/or sitting?", "What color is the open laptop?", "Is this man working?"], "mscoco2": ["A man sitting behind a table with speakers and computers"]}}, {"img_id": "COCO_val2014_000000029594", "labelf": {"vqa": [{"no parking": 1}, {"no": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What does the white and red sign say?", "Can you park along this street?", "Do the words on the wall and the image on the sign convey the same meaning?"], "mscoco2": ["Parking sign sitting in front of huge no parking sign on the wall behind it. "]}}, {"img_id": "COCO_val2014_000000492562", "labelf": {"vqa": [{"freight": 1}, {"13": 1, "14": 1, "18": 0.3}, {"no": 1}, {"fall": 0.6, "spring": 1, "winter": 1}, {"yes": 1}, {"no": 1}]}, "sentf": {"vqa": ["Is this a passenger or freight train?", "How many train cars are in this picture?", "Is the train going to fall off the bridge?", "What season is it?", "Is there snow on the mountain?", "Is the sky gray?"], "mscoco2": ["A train crossing a bridge over water next to some hills. ", "A train goes over a bridge in a mountainous area. "]}}, {"img_id": "COCO_val2014_000000353898", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"bird": 1, "birds": 0.3, "human": 0.3, "pigeon": 0.3, "pigeons": 0.3}, {"white": 1}, {"bench": 0.3, "yes": 1}, {"orange": 1, "white": 1, "yellow": 0.3}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["Is it possibly fall season?", "What animal is this?", "What color birds are there?", "Is the man sitting down?", "What color are the bird's feet?", "Are these pigeons?"], "mscoco2": ["Birds stand on a side walk under the large trees. "]}}, {"img_id": "COCO_val2014_000000088462", "labelf": {"vqa": [{"1": 1, "2": 1, "3": 0.3}, {"school": 1, "students": 0.6}, {"clouds": 1, "power lines": 0.3, "wires": 0.6}, {"above": 0.3, "in air": 0.3, "in sky": 0.3, "side of road": 0.3, "sky": 0.6}]}, "sentf": {"vqa": ["How many cars face the bus?", "What is the large bus used for?", "What can be seen in the air?", "Where are the power lines?"], "mscoco2": ["A school bus waits in traffic behind a car. "]}}, {"img_id": "COCO_val2014_000000080725", "labelf": {"gqa": [{"sticker": 1.0}, {"sticker": 1.0}, {"people": 1.0}, {"bike": 1.0}, {"tree": 1.0}, {"tree": 1.0}], "visual7w": [{"In the woods.": 1.0}, {"Timex.": 1.0}, {"Blue.": 1.0}, {"Leaning against a tree.": 1.0}, {"2 more bikers.": 1.0}, {"A watch with a timer.": 1.0}, {"A man's arm.": 1.0}, {"Watch.": 1.0}, {"Stop.": 1.0}, {"Octagon.": 1.0}, {"32.30.": 1.0}, {"Wood.": 1.0}, {"Octagon.": 1.0}, {"Wristwatch.": 1.0}, {"A bicycle.": 1.0}, {"Trees.": 1.0}, {"Behind the bicycle.": 1.0}, {"A sports watch.": 1.0}, {"The stop sign.": 1.0}, {"Stop.": 1.0}, {"A bike cycle parked.": 1.0}, {"A watch.": 1.0}, {"An octagon.": 1.0}, {"32.30.": 1.0}, {"A bikecycle seat.": 1.0}, {"A bike cycle.": 1.0}, {"A wooden post.": 1.0}, {"A red and white stop sign.": 1.0}, {"Deep blue.": 1.0}], "vqa": [{"no": 1, "yes": 1}, {"left": 1, "right": 1}, {"octagon": 1}]}, "sentf": {"gqa": ["What is on the white sign by the bike?", "What is on the sign?", "Who is walking?", "What's in front of the tree?", "What is the bike in front of?", "The bike is in front of what?"], "visual7w": ["Where are the men biking?", "What brand of watch is man wearing?", "What color is the man's bike?", "Where is the man's bike?", "Who do you see in the background of the picture?", "What is on the man's wrist?", "What is in the forefront in the picture?", "What is on the man's wrist?", "What is on the sign?", "What shape is the sign?", "What does the timer say?", "What is the sign post made of?", "What shape is the stop sign?", "What timepiece is on the arm?", "What is leaning on the stop sign?", "What plant matter is behind the stop sign?", "Where is the stop sign relative to the blue bicycle?", "What has a time reading on it?", "What is the bicycle leaning against?", "What word is on the octagonal sign?", "What is below the stop sign?", "What is on the man's wrist?", "What is the shape of the sign?", "What are the numbers on the watch?", "What is behind the man's wrist?", "What is leaning against the post?", "What is the behind the bike?", "What is on the wooden pole?", "What is the hue of the bike?"], "vqa": ["Does the watch monitor heart rate?", "Which arm is the watch on?", "What shape is the sign?"], "mscoco2": ["A stopwatch wristwatch reads 32.30 in the foreground, while a bike and a stop sign is in the background. "]}}, {"img_id": "COCO_val2014_000000145700", "labelf": {"vqa": [{"go": 1}, {"green": 1}, {"yes": 1}]}, "sentf": {"vqa": ["What does the green traffic light mean?", "What color is the street light showing?", "Is the road clear?"], "mscoco2": ["a view of a city street with stop lights above"]}}, {"img_id": "COCO_val2014_000000351938", "labelf": {"gqa": [{"yes": 1.0}, {"yellow": 1.0}, {"fire hydrant": 1.0}, {"closed": 1.0}, {"yes": 1.0}, {"yard": 1.0}, {"yard": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"mailbox": 1.0}, {"mailbox": 1.0}, {"yes": 1.0}, {"brown": 1.0}, {"no": 1.0}, {"stone": 1.0}, {"stone": 1.0}, {"rocks": 1.0}, {"flowers": 1.0}, {"no": 1.0}, {"yard": 1.0}, {"yard": 1.0}, {"yes": 1.0}, {"black": 1.0}], "visual7w": [{"Gray.": 1.0}, {"Red.": 1.0}, {"Sparse.": 1.0}, {"Daytime.": 1.0}, {"Bars.": 1.0}, {"Yellow.": 1.0}, {"Apartment building.": 1.0}, {"Flowers.": 1.0}, {"Grass.": 1.0}, {"Fire hydrant.": 1.0}, {"Flowers.": 1.0}, {"Purple, yellow and orange.": 1.0}, {"Rocks.": 1.0}, {"Grey stone building.": 1.0}, {"Power lines.": 1.0}, {"Security rails.": 1.0}, {"Rust.": 1.0}, {"Green and yellowed.": 1.0}, {"Flowers.": 1.0}, {"House.": 1.0}, {"Fire hydrant.": 1.0}, {"Across windows.": 1.0}, {"Inside window.": 1.0}, {"Around fire hydrant.": 1.0}, {"Around flowers.": 1.0}, {"Pink, yellow and orange.": 1.0}, {"House.": 1.0}, {"By purple door.": 1.0}, {"Fire hydrant.": 1.0}, {"Black metal grate.": 1.0}, {"Maroon.": 1.0}], "vqa": [{"no": 1, "yes": 1}, {"safety": 0.3, "security": 0.6, "yes": 0.6}, {"yellow": 1}]}, "sentf": {"gqa": ["Are the colorful curtains on the left side?", "What color is that fire hydrant?", "What is the garden around of?", "Is that door closed or open?", "Do you think the sky is cloudy?", "Where is the hydrant?", "Where is the fire hydrant?", "Is the door closed and maroon?", "Are there round windows or clocks?", "Is the stone behind the flowers that look yellow and orange?", "What is on the wall?", "What's on the wall?", "Do you see a fire hydrant there that is not gray?", "Of what color is the yard the hydrant is in?", "Is the garden around a street sign?", "What is the fire hydrant in front of?", "What is that fire hydrant in front of?", "What is in front of the flowers that are around the hydrant?", "What are the rocks in front of?", "Are there parking signs near the purple flowers?", "Which place is it?", "Where was the photo taken?", "Do you see any fire hydrants on the yard that looks brown and green?", "Which color do you think the mailbox is?"], "visual7w": ["What color is the building?", "What color is the door?", "How does the grass look?", "What time of day is it?", "What is on the windows?", "What color is the fire hydrant?", "Where is this photo taken?", "What is around the hydrant?", "What is green on the ground?", "What is the yellow object?", "What is surrounding the fire hydrant?", "What are the different shades of flowers around the fire hydrant?", "What is surrounding the flowers?", "What is the structure on the left?", "What are the black lines in the sky?", "What is the black metal object in front of the windows?", "What are the brown spots on the fire hydrant?", "What condition is the grass in?", "What is growing around the firehydrant?", "Where are the oval windows located?", "What is the metal yellow item?", "Where are there security bars?", "Where is the colorful blanket hanging?", "Where are the colorful flowers growing?", "Where is the circle of decorative rocks?", "What are the flower colors?", "Where is the purple door?", "Where is the mailbox?", "What is the yellow object?", "What is in front of the windows of the building?", "What shade of color is the door on the grey building?"], "vqa": ["Is the building a church?", "Why are there bars on the windows?", "What color is the hydrant?"], "mscoco2": ["A bright yellow fire hydrant has pretty flowers and decorative stones surrounding it; a cement building is in the background and one of the curtains is very colorful. "]}}, {"img_id": "COCO_val2014_000000186797", "labelf": {"gqa": [{"no": 1.0}, {"suv": 1.0}, {"yes": 1.0}, {"suv": 1.0}, {"suv": 1.0}, {"blue": 1.0}, {"light brown": 1.0}, {"right": 1.0}, {"white": 1.0}], "visual7w": [{"It is a one-way street.": 1.0}, {"To railway station.": 1.0}, {"A crown.": 1.0}, {"Green leaves.": 1.0}, {"A black SUV.": 1.0}, {"Queen St.": 1.0}, {"Queen st.": 1.0}, {"On the left?.": 1.0}, {"On the sidewalk.": 1.0}, {"The street sign.": 1.0}, {"A queen.": 1.0}, {"On a pole.": 1.0}, {"Black.": 1.0}, {"The tall, vertical one.": 1.0}, {"Gravel.": 1.0}, {"Next to the road.": 1.0}, {"On a sidewalk.": 1.0}], "vqa": [{"queen": 1}, {"yes": 1}, {"queen": 0.3}]}, "sentf": {"gqa": ["Are there buses or fences in the scene?", "What is the vehicle to the right of the car that is in the middle of the picture?", "Are there suvs on the sidewalk?", "What vehicle is on the sidewalk?", "What is the vehicle on the sidewalk?", "Which color is the street sign that the pole is with?", "Is the dirt black or light brown?", "On which side is the black vehicle?", "What is the color of the car on the road?"], "visual7w": ["Why are all the cars driving in the same direction?", "Where does Queen street take you?", "What is on the signs Queen head?", "What foliage is on the trees?", "Who is turning left?", "What does the drawing on the tree say?", "What does the white sign say?", "Where is the traffic?", "Where is the black car?", "What is blue in the photo?", "What is the drawing of?", "Where are the signs?", "What color is the SUV?", "What sign says queen?", "What is beside the queen sign?", "Where is the tree?", "Where is the black car?"], "vqa": ["What street is this photo depicting?", "Does the sign direct you to the railway station?", "What does the sign say?"], "mscoco2": ["A decorated street sign for Queen Street with two blue signs below. "]}}, {"img_id": "COCO_val2014_000000242139", "labelf": {"vqa": [{"yes": 1}, {"2": 1, "yes": 0.3}, {"yes": 1}]}, "sentf": {"vqa": ["Is the car on the left legally crossing the intersection?", "How many pedestrians are visible?", "Is the building shiny?"], "mscoco2": ["A street scene at an intersection with tall skyscrapers in the background. "]}}, {"img_id": "COCO_val2014_000000197774", "labelf": {"visual7w": [{"Outside it is getting dark.": 1.0}, {"One.": 1.0}, {"A tree.": 1.0}, {"Signs.": 1.0}, {"A person who loves sunsets and great landscapes.": 1.0}, {"Sunset.": 1.0}], "vqa": [{"0": 0.3, "1": 0.3, "3": 0.6, "4": 1, "5": 0.3, "7": 0.3}, {"can't see": 0.3, "no": 0.9, "yes": 1}, {"no": 0.9, "yes": 1}, {"nighttime": 0.3, "pole": 0.3, "street": 0.3, "street light": 0.3}]}, "sentf": {"visual7w": ["Where is this picture taken?", "How many lights are there?", "What is on top of the hill?", "What is to the left of the light post?", "Who will like this photo?", "When was this picture taken?"], "vqa": ["How many signs are posted?", "Is this in America?", "Is this lamp too yellow for the evening sky?", "What is this light for?"], "mscoco2": ["The sky is cloudy behind an illuminated street light. "]}}, {"img_id": "COCO_val2014_000000179151", "labelf": {"vqa": [{"yes": 1}, {"no": 0.3, "yes": 1}, {"no": 1}, {"2:00": 0.3, "afternoon": 0.3, "daytime": 0.3, "noon": 0.6}]}, "sentf": {"vqa": ["Is there a purple sign on this street?", "Are any of the signs in English?", "Is this likely the United States?", "What time of day is it?"], "mscoco2": ["A man on a yellow bike sits in the street under signs."]}}, {"img_id": "COCO_val2014_000000529083", "labelf": {"gqa": [{"no": 1.0}, {"no": 1.0}, {"calm": 1.0}, {"bus": 1.0}, {"yes": 1.0}, {"bus": 1.0}, {"yes": 1.0}, {"bridge": 1.0}, {"bridge": 1.0}, {"no": 1.0}, {"red": 1.0}, {"bus": 1.0}, {"bus": 1.0}, {"black": 1.0}, {"overcast": 1.0}], "visual7w": [{"The bridge.": 1.0}, {"The bus drivers.": 1.0}, {"Blue.": 1.0}, {"On the bridge.": 1.0}, {"Over the water.": 1.0}, {"Cloudy.": 1.0}], "vqa": [{"red": 1}, {"2": 1, "3": 0.3}, {"left": 0.3, "top": 0.3, "top left": 0.3}]}, "sentf": {"gqa": ["Is the water gray and calm?", "Is the water gray?", "How is the water in this picture?", "What vehicle is to the left of the van?", "Are there black bridges or lamps?", "What kind of vehicle is to the left of the vehicle on the right?", "Are there any red buses or cars?", "What is the light post on?", "What is the street light on?", "Does the bridge have large size and silver color?", "The bus on the bridge is what color?", "What vehicle is on the bridge?", "What vehicle is on the large bridge?", "Which color is the large bridge?", "Is it cloudless or overcast?"], "visual7w": ["What are the buses driving on?", "Who is driving the buses?", "What color is the water?", "How do the buses cross the river?", "Where is the bridge?", "What is the weather like?"], "vqa": ["What color are the buses?", "How many buses are on the bridge?", "Where are the dark clouds?"], "mscoco2": ["Traffic passes over a bridge under a cloudy sky.  ", "a picture of vehicles going over a bridge during the day"]}}, {"img_id": "COCO_val2014_000000076261", "labelf": {"vqa": [{"yes": 1}, {"hilly": 0.6, "mountainous": 1, "mountains": 0.3, "yes": 0.6}, {"no": 1, "yes": 0.6}, {"birds": 1}, {"air": 0.3, "in air": 0.3, "in sky": 0.3, "sky": 1}, {"feathers": 0.3, "meat": 0.9, "tissue": 0.3, "wings": 0.3}, {"1": 0.3, "2": 1, "3": 0.3, "4": 0.3, "many": 0.3}, {"can't tell": 0.3, "crow": 0.3, "eagle": 0.6, "hawk": 1, "seagull": 0.3}, {"yes": 1}, {"2": 1}, {"birds": 1}, {"no": 1}, {"no": 1, "yes": 1}, {"0": 1, "2": 0.9}, {"2": 1}, {"birds": 1}, {"no": 1, "yes": 0.3}, {"bird": 0.3, "birds": 1}, {"no": 1}, {"0": 1, "2": 0.6}, {"bird": 1, "birds": 0.3, "eagle": 0.6, "hawk": 0.3}, {"2": 1}, {"2": 1}, {"crows": 0.3, "eagle": 0.6, "geese": 0.3, "pigeon": 0.3, "seagull": 1}]}, "sentf": {"vqa": ["Is this bird large?", "Is this a hilly or mountainous area?", "Are there trees in the background?", "What are flying?", "Where is the bird?", "What are the animals made of?", "How many mountain peaks are there?", "What type of bird is this?", "Is the bird flying?", "How many birds are there?", "What is in the air?", "Is the bird sitting in a tree?", "Is this bird from the mountains?", "How many planes?", "How many birds?", "Are these birds or planes?", "Is this an altered image?", "What is flying?", "Is there a fighter jet on the right?", "How many animals on the tree?", "What is this animal?", "How many birds are in flight?", "How many birds are in the sky?", "What kind of bird is that?"], "mscoco2": ["two birds fly in the sky over mountains"]}}, {"img_id": "COCO_val2014_000000081264", "labelf": {"gqa": [{"train": 1.0}, {"gray": 1.0}, {"brown": 1.0}, {"white": 1.0}, {"boats": 1.0}, {"boats": 1.0}, {"left": 1.0}], "visual7w": [{"No one.": 1.0}, {"Train.": 1.0}, {"A bridge.": 1.0}, {"One.": 1.0}, {"In water.": 1.0}, {"Daytime.": 1.0}, {"Water.": 1.0}, {"Choppy.": 1.0}, {"A bridge.": 1.0}, {"Calm.": 1.0}, {"Above the water.": 1.0}, {"In the water.": 1.0}, {"On the other side of the tracks.": 1.0}, {"Cloudy.": 1.0}, {"On the bridge.": 1.0}, {"On sailboat.": 1.0}, {"Box cars.": 1.0}, {"Train.": 1.0}, {"Trestles.": 1.0}, {"Tracks.": 1.0}, {"Water.": 1.0}, {"In water.": 1.0}, {"Over water.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"yes": 1}, {"no": 1}, {"no": 1}, {"bridge": 0.9, "train": 1}, {"train": 1}, {"blue": 0.9, "brown": 0.6, "clear": 0.3, "gray": 0.9, "green": 0.3}, {"no": 1, "yes": 0.3}, {"yes": 1}, {"bridge": 1, "train": 0.9}]}, "sentf": {"gqa": ["What is the vehicle to the right of the boats?", "Of what color is the sky?", "What color is the car to the right of the other car?", "Is the car to the left of the other car white or orange?", "What type of watercraft is to the left of the blue vehicle?", "Which kind of watercraft is to the left of the train?", "On which side of the image are the boats?"], "visual7w": ["Who is fishing in the picture?", "What form of transportation in the picture?", "What is the train tracks sitting on?", "How many trains are in the picture?", "Where is the bridge located in the picture?", "When is this picture taken?", "What is under the bridge?", "How is the water?", "What is the train on?", "How does the water look?", "Where is the train?", "Where is the bridge anchored?", "Where is the sailboat mast?", "How is the sky?", "How does the train travel across the water?", "Where are the masts?", "What type of cars?", "What is pulling the car?", "What are tracks on?", "What are trestles supporting?", "What is train going over?", "Where are the trestles?", "Where is the bridge?"], "vqa": ["Is the train moving?", "Is it cloudy?", "Is this a city?", "Is there a boat in the water?", "How can one cross the river?", "What is crossing the bridge?", "What color is the water?", "Is this a high bridge?", "Is the train crossing over a body of water?", "What is on the water?"], "mscoco2": ["very long train going across a bridge over water"]}}, {"img_id": "COCO_val2014_000000060456", "labelf": {"vqa": [{"no": 1}, {"no": 1}, {"no": 1}, {"1": 1}, {"no": 1}, {"beach": 0.3, "sand": 0.6, "yes": 0.3}, {"no": 1, "yes": 0.6}, {"bird": 1, "pelican": 1, "sand": 0.3}, {"yes": 1}, {"beach": 0.3, "pelican": 0.3, "sand": 1}, {"hat": 0.6, "shirt": 1}, {"bird": 1, "pelican": 0.3, "stork": 0.3}]}, "sentf": {"vqa": ["Is the man on the left trying to kill the bird?", "IS he wet?", "Is the beach crowded?", "How many people are wearing hats?", "Are these people playing frisbee?", "Why is the man holding his shoes?", "Is this beach hard on heels?", "What animal is the man looking at?", "Does he have a hat on?", "What is the man standing on?", "What is the man with the board wearing on top?", "What type of animals are shown?"], "mscoco2": ["A man sneaks up behind a pelican on a sandy beach. ", "A man wearing a cap walking behind a bird."]}}, {"img_id": "COCO_val2014_000000310906", "labelf": {"gqa": [{"buoy": 1.0}, {"no": 1.0}], "visual7w": [{"Houses.": 1.0}, {"No one.": 1.0}, {"A train.": 1.0}, {"2.": 1.0}, {"Daytime.": 1.0}, {"Near the water.": 1.0}, {"Near the train overpass.": 1.0}], "vqa": [{"yes": 1}, {"train": 1}, {"yes": 1}]}, "sentf": {"gqa": ["What is in the water?", "Does the train look yellow?"], "visual7w": ["What is in the background of the photo?", "Who is in the photo?", "What is on top of the bridge?", "How many carriages does the train have?", "When was the photo taken?", "Where is the scene?", "Where is the scene?"], "vqa": ["Is there a dock beyond the bridge?", "What vehicle is going over the bridge?", "Is there a bridge?"], "mscoco2": ["A train is traveling across a bridge over a lake. ", "A view of a train traveling over a bridge.", "The train is going over the bridge by the water. "]}}, {"img_id": "COCO_val2014_000000281455", "labelf": {"vqa": [{"crane": 0.3, "duck": 0.3, "seagull": 1, "unknown": 0.3}, {"no": 0.3, "yes": 1}, {"bird": 0.6, "birds": 0.9, "seagull": 0.3}, {"pigeons": 0.3, "seagull": 0.6, "seagulls": 1}, {"birds": 1, "geese": 0.3, "gray": 0.6}, {"afternoon": 0.3, "dawn": 0.3, "dusk": 0.6, "evening": 0.9, "sunset": 0.6}, {"no": 1, "yes": 1}, {"birds": 1, "sky": 0.3, "water": 0.3}, {"blue": 0.3, "gray": 1, "white": 0.3}, {"cloudy": 1, "fair": 0.3, "overcast": 0.6, "partly cloudy": 0.3}, {"no": 1, "yes": 0.6}, {"4": 1}, {"goose": 0.3, "seagull": 1}, {"yes": 1}, {"no": 1, "yes": 1}, {"landing": 0.6, "taking off": 1}, {"4": 1, "7": 0.3}, {"no": 0.3, "yes": 1}, {"4": 1, "6": 0.3}, {"no": 1}, {"5": 0.3, "afternoon": 0.9, "day time": 0.3, "evening": 0.6, "morning": 0.6}, {"no": 0.6, "yes": 1}, {"no": 0.9, "yes": 1}, {"yes": 1}, {"4": 0.3, "crows": 0.3, "geese": 0.3, "pelicans": 0.3, "seagull": 0.3, "seagulls": 0.9}, {"bird": 1, "birds": 0.6, "seagull": 0.6}, {"birds": 1, "pacific": 0.3, "unknown": 0.3}, {"lake": 1, "ocean": 1, "river": 0.3}, {"yes": 1}, {"field": 0.3, "water": 1}, {"flying": 1}, {"air": 0.3, "flying": 0.6, "ocean": 0.6, "pelicans": 0.3, "seagulls": 0.3, "water": 0.3}, {"no": 1}, {"black": 1, "dark": 0.3, "gray and white": 0.3, "white": 0.6}, {"birds": 1}, {"geese": 0.3, "pelican": 0.3, "seagull": 0.6, "seagulls": 0.9}, {"model": 0.3, "neither": 0.3, "real": 0.9}, {"no": 1}, {"no": 1}, {"yes": 1}]}, "sentf": {"vqa": ["What kind of bird is in the picture?", "Is this picture taken from a boat?", "What marine animal do the two kites on the lower right look like?", "What kind of birds are pictured?", "What is in the sky?", "What time of day is it?", "Does this picture have shallow depth of field?", "What is the reflection of in the mirror?", "What is the color of the sky?", "What is the weather like in the picture?", "Is it at night?", "How many birds are there?", "What kind of bird is this?", "Is the bird flying?", "Is it sunny?", "Is the bird landing or taking off?", "How many birds?", "Is this animal in it's natural environment?", "How many birds are visible?", "Is the animal lost?", "What time of day is it likely to be?", "Is this a large bird?", "Is this photo oriented so that its horizon and the real horizon are parallel?", "Is this a seabird?", "What kind of birds are flying in the sky?", "What animal is this?", "This image evokes a specific film, what is it?", "What type of water formation is the plane flying over?", "Is the water real?", "What is shown at bottom of photo?", "What is the bird doing?", "What are the birds swimming?", "Does this animal have a long neck?", "What color is the bird?", "What is in the air?", "What kind of birds are these?", "Is this ship real or a model?", "Is this inside?", "Is this a mountainous area?", "Are all the birds flying?"], "mscoco2": ["A group of birds flying over the water"]}}, {"img_id": "COCO_val2014_000000052726", "labelf": {"vqa": [{"no": 1}, {}, {"cross": 1}]}, "sentf": {"vqa": ["Is the building seen residential?", "What does the sign say?", "What is on top of the building?"], "mscoco2": ["A Wrong Way sign in the foreground of a church steeple. "]}}, {"img_id": "COCO_val2014_000000302160", "labelf": {"visual7w": [{"Daytime.": 1.0}, {"Zoo.": 1.0}, {"4.": 1.0}, {"Black.": 1.0}, {"Giraffe.": 1.0}, {"Hanging over the fence.": 1.0}, {"Near fence.": 1.0}, {"Black hair.": 1.0}, {"On fence.": 1.0}, {"Under the fence.": 1.0}, {"Behind the fence.": 1.0}, {"The giraffe.": 1.0}, {"Along neckline.": 1.0}, {"Along the legs.": 1.0}, {"The fence.": 1.0}, {"The wall.": 1.0}, {"Giraffe looks outside the fence.": 1.0}, {"Giraffe.": 1.0}, {"Neck.": 1.0}, {"Fence.": 1.0}], "vqa": [{"yes": 1}, {"yes": 1}, {"no": 1}]}, "sentf": {"visual7w": ["When was the photo taken?", "Where is the photo likely taken at?", "How many feet are there?", "What color is the tip of the tail?", "What type of animal is this?", "Where is the giraffe's mouth?", "Where is the giraffe?", "What is on the tip of giraffe's tail?", "Where are the metal post?", "Where is the cement wall?", "Where are the tree limbs?", "What has brown and beige spots?", "Where is the strip of hair?", "Where are the smaller spots?", "Where is the giraffe leaning towards?", "What looks stained?", "When is the image taken?", "What is in the photo?", "What is long in giraffe?", "What is next to giraffe?"], "vqa": ["Can the giraffe see over the fence?", "Is the tail hairy?", "Is this giraffe in the wild?"], "mscoco2": ["a giraffe is looking over the fence in its pen", "The giraffe is looking over the wall for some food. "]}}, {"img_id": "COCO_val2014_000000210501", "labelf": {"gqa": [{"no": 1.0}, {"no": 1.0}, {"left": 1.0}, {"red": 1.0}, {"gravel": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"no": 1.0}], "visual7w": [{"A train.": 1.0}, {"On the tracks.": 1.0}, {"Trees.": 1.0}, {"Grey.": 1.0}, {"Daytime.": 1.0}, {"Red.": 1.0}, {"Yellow.": 1.0}, {"Metal.": 1.0}], "vqa": [{"no": 1}, {"no": 1, "yes": 0.9}, {"100 feet": 0.6, "long": 0.3}, {"on track": 0.6, "on tracks": 0.9, "track": 0.6, "train tracks": 0.3}, {"brown": 0.3, "red": 1, "tan": 0.3}, {"no": 1}, {"no": 1, "yes": 1}, {"1": 1}, {"red": 0.6, "red and yellow": 0.6}]}, "sentf": {"gqa": ["Do you see both a door and a window?", "Is the horn black?", "On which side of the image is the red fence?", "Does the fence look black or red?", "What is the train on?", "On which side is the man?", "Does the shirt look orange?", "Are there any fences?", "Is there a fence that is not red?"], "visual7w": ["What is on the tracks?", "Where is the train?", "What is in the background?", "What color are the rocks?", "When was this photo taken?", "What color is the train primarily?", "What color is the stripe on the train?", "What are the tracks made of?"], "vqa": ["Is the train new?", "Is the weather forecast?", "How long is this train?", "Where is the train?", "What color is the train's engine?", "Are any people looking out of the windows?", "Is the train full sized?", "How many sets of tracks are on this side of the fence?", "What colors are the train?"], "mscoco2": ["a man in an orange standing behind an old train"]}}, {"img_id": "COCO_val2014_000000550084", "labelf": {"vqa": [{"no": 0.3, "yes": 1}, {}, {"no": 1, "yes": 0.9}, {}, {"blue": 1}, {"1": 0.6, "2": 1}]}, "sentf": {"vqa": ["Is there an excavator in the picture?", "What is the number posted on the sign?", "Does this city have a mass transit system?", "How far to thruway?", "What color is the sky?", "How many signs can you count?"], "mscoco2": ["a street sign below a bunch of power lines "]}}, {"img_id": "COCO_val2014_000000539302", "labelf": {"visual7w": [{"Animals.": 1.0}, {"Daytime.": 1.0}, {"Clear.": 1.0}, {"Giraffes.": 1.0}, {"Green.": 1.0}, {"In Africa.": 1.0}, {"Two giraffes and one deer.": 1.0}, {"The giraffes are walking on grassy land.": 1.0}, {"This is an Impala deer.": 1.0}, {"Covered with shrubs, grass and small trees.": 1.0}, {"Long and curved.": 1.0}, {"Grey and cloudy.": 1.0}], "vqa": [{"no": 1, "yes": 0.3}, {"antelope": 0.9, "deer": 1}, {"background": 0.3, "in background": 0.3, "in grass": 0.3, "middle": 0.3, "outside": 0.3, "wild": 0.3}]}, "sentf": {"visual7w": ["What is in the photo?", "When was this?", "How is the photo?", "What animal is in the photo?", "What color are the trees?", "Where was this photo taken?", "What animals are seen in the picture?", "Where are the giraffes?", "What type is the antelope?", "How is the ground?", "How are the horns on the Impala's head?", "How is the sky?"], "vqa": ["Is this taken at a zoo?", "What kind of animal is in the bottom left corner of the photo?", "Where are the giraffes?"], "mscoco2": ["Two giraffes tower over the deer in the jungle like setting."]}}, {"img_id": "COCO_val2014_000000137677", "labelf": {"visual7w": [{"Blue.": 1.0}, {"A bird.": 1.0}, {"One.": 1.0}, {"Daytime.": 1.0}], "vqa": [{"cloudy": 1, "foggy": 0.6}, {"mountain": 0.9, "mountains": 1, "rocks": 0.3, "sky": 0.3}, {"no": 0.3, "yes": 1}, {"no": 1}, {"no": 0.3, "yes": 1}, {"forest": 0.6, "mountain": 0.3, "mountains": 0.6, "outdoors": 0.3, "outside": 0.6}, {"no": 1, "yes": 0.9}, {"bird": 1, "hawk": 0.9}, {"no": 1}]}, "sentf": {"visual7w": ["What color is the sky?", "What is flying?", "How many birds are there?", "When was the picture taken?"], "vqa": ["How is the weather?", "What is the background of this photo?", "Can you see clouds?", "Does this animal have a long tongue?", "Is this type of bird currently endangered?", "Where was this photo taken?", "Are the wings up?", "What type of animal is this?", "Is this an airplane?"], "mscoco2": ["a bird with a large sing span flying over trees"]}}, {"img_id": "COCO_val2014_000000069944", "labelf": {"gqa": [{"right": 1.0}, {"right": 1.0}, {"man": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"purple": 1.0}, {"bus": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"right": 1.0}, {"cars": 1.0}, {"no": 1.0}, {"bus": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"right": 1.0}, {"no": 1.0}], "visual7w": [{"On edge.": 1.0}, {"Touring.": 1.0}, {"Autobuses.": 1.0}, {"Relaxing.": 1.0}, {"Tourists.": 1.0}, {"City street.": 1.0}, {"Stone.": 1.0}], "vqa": [{"no": 1}, {"2": 0.3, "3": 0.3, "4": 1}, {"2": 1}, {"bus": 0.6, "bus station": 0.3, "public": 0.3, "road": 0.3, "travel": 0.3}]}, "sentf": {"gqa": ["Is the man to the left or to the right of the bus the woman is to the left of?", "Is the blue bus to the left or to the right of the woman that is wearing a sweater?", "Who is wearing a shirt?", "Is the blue bus to the left or to the right of the woman that is wearing a shirt?", "Do you see people to the right of the woman that is wearing a shirt?", "Which color do you think is the shirt that the woman is wearing?", "What vehicle is to the left of the lamp?", "Are there both a door and a window in this picture?", "Is the man to the right or to the left of the bus that is to the right of the cars?", "On which side of the image is the man?", "What kind of vehicle is on the parking lot?", "Do you see any people to the right of the blue bus?", "What vehicle is to the right of the lamp?", "Is the blue bus to the left or to the right of the man?", "Does the bus that is to the right of the person look blue?", "In which part of the photo are the cars?", "Are there both a window and a door in the image?", "On which side of the photo is the lamp?", "Is the blue bus to the right or to the left of the person that is sitting on the wall?", "Are there buses to the right of the man that is wearing a shirt?"], "visual7w": ["How are they sitting?", "Why are they there?", "What is parked next to the edge?", "What are they doing?", "Who is there?", "Where is this scene?", "What is the wall made of?"], "vqa": ["Is the bus moving?", "How many bus cars can you see?", "How many colors are the busses?", "What kind of yard would this be considered?"], "mscoco2": ["A group of red and blue tourist buses going over a bridge."]}}, {"img_id": "COCO_val2014_000000192062", "labelf": {"gqa": [{"yes": 1.0}, {"white": 1.0}, {"word": 1.0}, {"sign": 1.0}, {"sign": 1.0}, {"word": 1.0}], "visual7w": [{"Orange.": 1.0}, {"Under a tree.": 1.0}, {"Fall.": 1.0}, {"None.": 1.0}, {"Clayallee.": 1.0}, {"None.": 1.0}, {"10 and 2.": 1.0}, {"Brown.": 1.0}, {"Clayallee.": 1.0}, {"Fall.": 1.0}, {"Against the trees.": 1.0}, {"Words.": 1.0}, {"Leaves.": 1.0}, {"Leaves.": 1.0}, {"Black branches.": 1.0}, {"The sky.": 1.0}, {"The sky.": 1.0}, {"Black.": 1.0}, {"A smaller sign.": 1.0}, {"Under the tree.": 1.0}, {"White and black.": 1.0}, {"Black.": 1.0}, {"Clayallee.": 1.0}, {"Sunlight.": 1.0}, {"Clayallee.": 1.0}, {"The leaves.": 1.0}, {"The branches.": 1.0}, {"The leaves.": 1.0}, {"The leaves.": 1.0}, {"Dirty.": 1.0}, {"Sun light.": 1.0}], "vqa": [{"10": 0.3, "fall": 1}, {}, {}]}, "sentf": {"gqa": ["Is the bright sky both white and clear?", "That sky has which color?", "What is on the sign?", "What is under the tree below the sky?", "What is under the tree?", "What is on the sign under the tree?"], "visual7w": ["What color are the leaves?", "Where was this picture taken?", "When was this picture taken?", "How many clouds are in the sky?", "What is the name on the sign?", "How many people are in this picture?", "What are the two numbers on the sign?", "What color is the sign?", "What does the sign say?", "What time of year was the picture taken?", "Where is the sign located?", "What is on the sign?", "What is on the trees?", "What is orange on the tree?", "Where are the leaves on the tree?", "What can be viewed between the branches?", "What can be viewed above the trees?", "What shade is the words on the sign?", "What is below the big sign?", "Where is the board at?", "What shade is the board?", "What shade is the writing?", "What was written on the board?", "What is passing through the leaves?", "What are the words on the sign?", "What is orange in this photo?", "What is brown in this photo?", "What is yellow in this photo?", "What is blocking the view of the sky?", "What condition is the sign in?", "What is coming through the leaves?"], "vqa": ["What time of year is it?", "What numbers are on the sign?", "What is the name of this street?"], "mscoco2": ["older street sign under a large tree during the fall"]}}, {"img_id": "COCO_val2014_000000428858", "labelf": {"gqa": [{"short": 1.0}, {"giraffe": 1.0}, {"gray": 1.0}, {"short": 1.0}], "visual7w": [{"At the forest.": 1.0}, {"Backlighting.": 1.0}, {"Giraffe.": 1.0}, {"To try to see something.": 1.0}, {"Morning.": 1.0}, {"One.": 1.0}, {"The giraffe.": 1.0}, {"Green.": 1.0}], "vqa": [{"1": 1}, {"no": 1, "yes": 0.3}, {"yes": 1}, {"1": 1}, {"giraffe": 1}, {"yes": 1}]}, "sentf": {"gqa": ["Is the hair long or short?", "What animal is it?", "What color is the sky, gray or orange?", "What is the height of the trees?"], "visual7w": ["Where is the giraffe?", "What kind of lighting is on the giraffe?", "What kind of animal is in the photo?", "Why is the giraffe bending its neck?", "When was this picture taken?", "How many giraffes are in the picture?", "Who is in the photo?", "What color is the vegetation?"], "vqa": ["How many giraffes are shown?", "Is the weather sunny?", "Is the giraffe looking at the camera?", "How many giraffes are there?", "What kind of animal is this?", "Do you see any clouds in the sky?"], "mscoco2": ["a giraffe craning its long neck above a green jungle"]}}, {"img_id": "COCO_val2014_000000069911", "labelf": {"vqa": [{"city": 0.3}, {}, {"green": 1, "green and white": 0.9}, {"10": 0.3, "20": 0.9, "24": 0.3, "25": 0.3, "28": 0.3, "many": 0.6, "no": 0.3}, {}, {}, {"shoes": 1, "sneakers": 0.6}, {"rectangle": 1}, {"12": 0.6, "13": 0.3, "6": 0.3, "7": 0.3, "8": 0.9, "9": 0.6}, {}, {"building": 0.9, "power lines": 0.9, "sky": 0.6, "wires": 0.3}]}, "sentf": {"vqa": ["Who is the street named after?", "What word is here that starts with a m?", "What color is the sign?", "How many windows?", "What is this intersection?", "What is the name of the Avenue?", "What is that on the wire?", "What shape are the street signs?", "How many power lines are above the sign pole?", "What is the name of this Avenue?", "What is behind the signs?"], "mscoco2": ["A Manila Av sign below a First St. sign. "]}}, {"img_id": "COCO_val2014_000000310622", "labelf": {"vqa": [{"broadway": 0.3}, {"no": 1}, {"4": 0.6, "5": 1}, {"no": 1, "yes": 1}, {"yes": 1}, {"2": 1, "3": 1}, {"4": 0.3, "5": 1}, {"3": 0.3, "32": 0.3, "4": 0.6, "5": 1}, {}, {"new york": 0.3}]}, "sentf": {"vqa": ["What is the street name at the right?", "Do you see a wheelchair sign?", "How many street and traffic signs are on the pole?", "Is this an intersection in New York?", "Are any of the streets one way?", "How many streets meet at this intersection?", "How many signs?", "How many numbers are on the signs?", "What are the cross streets?", "Where was this photo taken?"], "mscoco2": ["A West 32nd sign under a Korea Way road sign. "]}}, {"img_id": "COCO_val2014_000000453104", "labelf": {"vqa": [{"no": 1}, {"brown": 0.9, "brown and white": 1}, {"giraffe": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["Is the giraffe asleep?", "What color is the giraffe?", "What animal is in this photo?", "Is this a full grown giraffe?"], "mscoco2": ["Adult giraffe with a clear blue sky behind. "]}}, {"img_id": "COCO_val2014_000000011320", "labelf": {"vqa": [{"no": 0.6, "yes": 1}, {"black and white": 1}, {"5 feet": 0.3}, {"bridge": 1, "electricity": 0.3, "no": 0.3, "nothing": 0.3, "unknown": 0.3}, {"no": 1, "yes": 0.3}, {"london": 0.3, "new york": 1, "san francisco": 0.6}]}, "sentf": {"vqa": ["Was this taken in the USA?", "What color is the photo?", "What is the height of the arch over the street?", "What do the wires carry?", "Was this photo taken this century?", "What city is this in?"], "mscoco2": ["there is a old photo with many buildings and a bridge in the background "]}}, {"img_id": "COCO_val2014_000000351903", "labelf": {"vqa": [{"yes": 1}, {"2": 1}, {"giraffe": 1}]}, "sentf": {"vqa": ["Can wood be seen in this picture?", "How many giraffes are there?", "What is this animal?"], "mscoco2": ["A giraffe at the zoo looks right at the camera "]}}, {"img_id": "COCO_val2014_000000338948", "labelf": {"vqa": [{"skate": 0.3, "skateboard": 0.3, "skateboarding": 1}, {"sunny": 1, "yes": 0.3}, {"blonde": 1, "brown": 0.6}, {"fence": 0.3, "road": 0.3, "skateboard": 1}]}, "sentf": {"vqa": ["What game are they playing?", "Is it a sunny or cloudy day?", "What color is the man's hair?", "What is the man jumping on?"], "mscoco2": ["A boy is jumping over a hurdle on his skateboard. "]}}, {"img_id": "COCO_val2014_000000276707", "labelf": {"vqa": [{"air conditioner": 1, "sign": 0.3}, {"unsure": 0.3}, {"yes": 1}, {"skateboards": 0.3}, {"no": 1}]}, "sentf": {"vqa": ["What is sticking out of the top second window?", "What is the name of the jewelry store?", "Is this a shopping district?", "What instrument is on the sign?", "Are wheels allowed in this area?"], "mscoco2": ["A close-up of a street sign with small shops in the background. "]}}, {"img_id": "COCO_val2014_000000529777", "labelf": {"vqa": [{"no": 1}, {"red": 1, "red and white": 0.3}, {"hexagon": 0.3, "octagon": 1}, {"white": 1}]}, "sentf": {"vqa": ["Are children at play?", "What color is this sign?", "What shape is this sign in?", "What color are the flowers?"], "mscoco2": ["A stop sign sitting right in a flowering tree "]}}, {"img_id": "COCO_val2014_000000040894", "labelf": {"gqa": [{"green": 1.0}, {"no": 1.0}, {"no": 1.0}, {"green": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"Water.": 1.0}, {"Afternoon.": 1.0}, {"Blue.": 1.0}, {"Some people.": 1.0}, {"On the bridge.": 1.0}, {"White.": 1.0}], "vqa": [{"ball": 0.3, "big": 0.3, "bright": 0.3, "globe": 0.3, "street": 0.3}, {"boat": 1}, {"4th of july": 0.3, "easter": 0.3, "summer": 0.6, "wedding": 0.3}, {"yes": 1}, {"no": 1, "yes": 1}, {"american": 0.3, "no": 0.6, "yes": 1}]}, "sentf": {"gqa": ["Which color does the oar on the pier have?", "Are there either cages or cake slices?", "Are there any benches that are metallic?", "What color is that boat?"], "visual7w": ["What time is it?", "What is under the bridge?", "When was the photo taken?", "What color is the sky?", "Who is walking?", "Where are the people?", "What color are the clouds?"], "vqa": ["What kind of lights are on the bridge?", "What kind of vehicle is this?", "What holiday is this?", "Are there benches on the boat?", "Is this a busy area?", "Is there a flag in this photo?"], "mscoco2": ["People walk across a footbridge that stretches over a river. ", "a docked boat sits under neath a bridge "]}}, {"img_id": "COCO_val2014_000000092488", "labelf": {"gqa": [{"yes": 1.0}, {"no": 1.0}, {"city": 1.0}], "visual7w": [{"City.": 1.0}, {"One.": 1.0}, {"Green.": 1.0}, {"Morning.": 1.0}, {"Gold.": 1.0}], "vqa": [{"yes": 1}, {"12:45": 1, "1:45": 0.3}, {"go": 0.3, "green": 1, "traffic": 0.6, "traffic light": 0.6}, {"yes": 1}, {"go": 0.3}, {"12:45": 1, "1:45": 0.3}, {"10": 0.3, "15": 0.6, "18": 0.3, "20": 0.3, "200": 0.3, "3": 0.3, "5": 0.3, "50": 0.3, "many": 0.3}]}, "sentf": {"gqa": ["Is it outdoors?", "Are there either any cars or buses in the image?", "Which place is it?"], "visual7w": ["Where is this scene?", "How many clocks are in the photo?", "What color is the traffic light?", "What time of day is it?", "What color is the writing on the wall?"], "vqa": ["Is the light green?", "What time is it?", "What is the light on the left?", "Is the traffic light green?", "What is the sign saying?", "What time does the clock show?", "How many windows are on the building with the clock?"], "mscoco2": ["Many large buildings located behind a traffic light."]}}, {"img_id": "COCO_val2014_000000445014", "labelf": {"gqa": [{"pen": 1.0}, {"pen": 1.0}, {"right": 1.0}, {"no": 1.0}, {"left": 1.0}, {"giraffe": 1.0}, {"no": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"2.": 1.0}, {"A giraffe.": 1.0}, {"The man.": 1.0}, {"Orange t shirt.": 1.0}, {"Pink striped shirt.": 1.0}, {"In a zoo.": 1.0}, {"Giraffe.": 1.0}, {"A man.": 1.0}, {"Girls.": 1.0}, {"Leaves.": 1.0}, {"A hat.": 1.0}], "vqa": [{"fence": 1, "railing": 0.6}, {"yes": 1}, {"giraffe": 1}, {"no": 1}, {"forward": 1, "yes": 0.3}, {"no": 1, "yes": 0.3}]}, "sentf": {"gqa": ["What is the picture showing?", "Which place is it?", "Is the man on the left or on the right side of the photo?", "Is the tank top black?", "Which side is the giraffe on?", "What animal is to the left of the man on the right of the image?", "Is the giraffe on the right side?"], "visual7w": ["When was the picture taken?", "How many little girls are there?", "What is the man looking at?", "What is the giraffe looking at?", "What kind of tee shirt is the man wearing?", "What is the little girl wearing?", "Where was the picture taken?", "What kind of animal is in the picture?", "Who is feeding the giraffe?", "Who is beside the man?", "What is the giraffe eating?", "What is on the man's head?"], "vqa": ["What is separating the people from the giraffes?", "Are there children partially in this picture?", "What kind of animal is this?", "Is the giraffe this man's child?", "How does the boy wear his cap?", "Is the man and giraffe best friends?"], "mscoco2": ["a group of people look over a ledge at a giraffe "]}}, {"img_id": "COCO_val2014_000000391006", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"airport": 1.0}, {"airport": 1.0}, {"white": 1.0}, {"large": 1.0}, {"gray": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"metal": 1.0}, {"yes": 1.0}], "visual7w": [{"A pilot.": 1.0}, {"One.": 1.0}, {"Flying.": 1.0}, {"Cloudy day.": 1.0}, {"A fence.": 1.0}, {"An airplane.": 1.0}, {"One.": 1.0}, {"Four.": 1.0}, {"The airport.": 1.0}, {"Landing gear.": 1.0}, {"Metal.": 1.0}, {"White.": 1.0}, {"An airplane.": 1.0}, {"Grey.": 1.0}, {"Lights and grassy field.": 1.0}, {"Clouds.": 1.0}, {"Black and white.": 1.0}, {"During daylight.": 1.0}, {"White jet plane.": 1.0}, {"Metal fence.": 1.0}, {"Lights.": 1.0}, {"It's lit by lights.": 1.0}, {"Plane over runway.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"yes": 1}, {"blue": 0.6, "gray": 1}, {"airplane": 1, "plane": 0.9}, {"no": 1, "yes": 0.3}]}, "sentf": {"gqa": ["Does the fence near the runway look stone and long?", "Is the box wooden and white?", "Which side is the white box on?", "Which place is it?", "Is it an airport or a train station?", "The buildings are what color?", "How big is the plane?", "What color is the cloudy sky, gray or orange?", "Do the plane and the box have the same color?", "Is the fence near the runway made of wood?", "What's the fence made of?", "Does the airplane look large and white?"], "visual7w": ["Who is driving the plane?", "How many planes are there?", "What is the plane doing?", "Why is the sky dark?", "What is under the plane?", "What is flying in the air?", "How many airplanes in the sky?", "How many lights along the airstrip?", "What is the fence enclosing?", "What can be seen under the wings of the plane?", "What is the fence made of?", "What color are the buildings behind the landing strip?", "What is coming in for a landing?", "What color is the landing strip?", "What is the landing strip surrounded by?", "What is in the sky below the plane?", "What type of picture is this?", "When was this picture taken?", "What is landing at the airport?", "What is bounding the runway?", "What are the circular objects in the foreground?", "How is the pilate seeing the runway?", "What is this a picture of?"], "vqa": ["Is the plan landing?", "Is there a high fence around the airport?", "What color is the sky?", "What is flying in the sky?", "Is the plane on a runway?"], "mscoco2": ["A low-flying plane seen in the distance flies above a runway. "]}}, {"img_id": "COCO_val2014_000000090626", "labelf": {"vqa": [{"12": 0.3, "14": 0.3, "16": 0.6, "20": 0.3, "22": 0.3, "25": 0.3, "8": 0.9}, {"no": 1}, {}]}, "sentf": {"vqa": ["How many windows on the bus?", "Is the writing on the bus in English?", "What are the white objects on the roof of the bus for?"], "mscoco2": ["A red bus is behind a rail outside"]}}, {"img_id": "COCO_val2014_000000353180", "labelf": {"vqa": [{"bus": 1, "school bus": 0.3}, {"yes": 1}, {"10": 0.6, "15": 0.3, "7": 0.3, "8": 1, "9": 0.3}]}, "sentf": {"vqa": ["What are the people pushing?", "Did the school bus's engine stop?", "How many people are pushing?"], "mscoco2": ["A group of people that are behind a bus."]}}, {"img_id": "COCO_val2014_000000538255", "labelf": {"gqa": [{"left": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"porch": 1.0}, {"porch": 1.0}, {"chair": 1.0}, {"chair": 1.0}], "visual7w": [{"Yellow.": 1.0}, {"A neighborhood.": 1.0}, {"4067.": 1.0}, {"Clear.": 1.0}, {"Blue.": 1.0}, {"A school bus.": 1.0}, {"An electrical pole.": 1.0}, {"Daytime.": 1.0}, {"A school bus.": 1.0}, {"A yellow school bus.": 1.0}, {"A residential street.": 1.0}, {"4067.": 1.0}, {"Emergency Door.": 1.0}, {"Two.": 1.0}, {"Do not pass.": 1.0}, {"Electrical power lines.": 1.0}, {"Rows of houses.": 1.0}, {"A green padded seat.": 1.0}, {"Sunny.": 1.0}, {"A school bus.": 1.0}, {"A house.": 1.0}, {"The utility pole.": 1.0}], "vqa": [{"2": 1}, {"1": 1}, {"no": 1, "yes": 0.3}]}, "sentf": {"gqa": ["In which part of the picture is the chair?", "Are the boxes in the top of the photo?", "Does the chair have white color?", "Which side is the brick house on?", "On which side is the house?", "Are both the sign and the chair the same color?", "Is the color of the boxes different than that of the numbers?", "What does the white chair sit on?", "What does the chair sit on?", "What is the piece of furniture that sits on the porch?", "What kind of furniture sits on the porch?"], "visual7w": ["What color is the bus?", "Where is this picture taken?", "What number is the bus?", "How is the weather?", "What color is the sky?", "What kind of bus is shown?", "What is next to the bus?", "When was this picture taken?", "What is this vehicle?", "What vehicle is pictured?", "Where is this taken?", "What numerals identify the bus?", "What does the sign read?", "What is the number of back windows visible?", "What do the black letters read?", "What hangs over head?", "What is to the left in the photo?", "What can be seen through the window?", "What is the weather?", "What is this the back of?", "What is across the street?", "What has transformers on the side?"], "vqa": ["How many languages is on the white sign?", "How many buses?", "Does the neighborhood look affluent?"], "mscoco2": ["a yellow school bus show an emergency door behind"]}}, {"img_id": "COCO_val2014_000000326814", "labelf": {"vqa": [{"striped": 0.3, "white": 1, "white and black": 0.3}, {"1": 1}, {"cat": 1}, {"mirror": 1, "person": 0.6, "woman": 0.9}, {"no": 0.3, "yes": 1}, {"cream": 0.3, "unknown": 0.3, "white": 0.9, "white and gray": 0.9, "white and orange": 0.3}, {"can't tell": 0.3, "no": 1, "yes": 0.9}]}, "sentf": {"vqa": ["What color is the cat?", "How many people are in the picture?", "What type of animal is in the foreground of the photo?", "What is behind the cat?", "Is there a reflection in the picture?", "What is the color of the cat?", "Is the electricity in the room turned on?"], "mscoco2": ["A cat sitting on a dresser with a person in the mirror behind it ", "A cat looking in a mirror with a woman behind him. "]}}, {"img_id": "COCO_val2014_000000570088", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"yes": 1}, {"no": 1}, {"buildings": 0.3, "city": 1, "trees": 0.6}, {"giraffe": 1, "giraffes": 0.3}]}, "sentf": {"vqa": ["Is the giraffe in the middle of a city?", "Are the giraffes standing up straight?", "Is there more than 1 animal?", "What is in the background?", "What kind of animal is this?"], "mscoco2": ["a giraffe near trees and buildings in the background"]}}, {"img_id": "COCO_val2014_000000112770", "labelf": {"vqa": [{"2": 1}, {"no": 1, "yes": 0.3}, {"cat": 1, "cats": 1}]}, "sentf": {"vqa": ["How many animals?", "Are the cats the same color?", "What kind of animal is on the fence?"], "mscoco2": ["some cats laying on a dock with their chins laying over the end "]}}, {"img_id": "COCO_val2014_000000157430", "labelf": {"visual7w": [{"Three.": 1.0}, {"Three.": 1.0}, {"A concrete wall.": 1.0}, {"White.": 1.0}, {"Green.": 1.0}, {"To point a traveler in the right direction.": 1.0}, {"An arrow.": 1.0}, {"Five.": 1.0}, {"A3 SA-RC.": 1.0}, {"Right.": 1.0}, {"Green and white.": 1.0}, {"Blue.": 1.0}, {"White.": 1.0}, {"Left.": 1.0}, {"White.": 1.0}, {"Metal pole.": 1.0}, {"Stone.": 1.0}, {"Blue.": 1.0}, {"Black.": 1.0}, {"White.": 1.0}, {"Yellow and brown.": 1.0}, {"White.": 1.0}, {"Green.": 1.0}, {"Blue and white.": 1.0}, {"Four.": 1.0}, {"Brown.": 1.0}, {"One.": 1.0}, {"Greens.": 1.0}, {"A3 SA - RC.": 1.0}, {"White.": 1.0}, {"Blue.": 1.0}, {"Blue.": 1.0}, {"White.": 1.0}, {"Yellow.": 1.0}, {"The letters are black.": 1.0}, {"The wall is brownish.": 1.0}, {"The sign is rectangular.": 1.0}], "vqa": [{"yes": 1}, {"pointing": 1}, {"on building": 0.3, "on pole": 0.3, "pole": 0.9, "wall": 0.3}, {"french": 0.3, "italian": 1, "spanish": 0.6}]}, "sentf": {"visual7w": ["What is the only number in the picture?", "How many signs are in the picture?", "What is behind the signs?", "What color is the lettering on the green sign?", "What color is the arrow shaped sign?", "Why is the sign an arrow shape?", "What shape is the green sign?", "How many letters are on the green sign?", "What does the green and white sign say?", "What direction is the sign pointing?", "What color is the sign?", "What color is the sky?", "What color are the letters on the sign?", "Where is the tan building?", "What color is the sign above the green sign?", "What is the sign attached to?", "What is the white sign attached to?", "What color is underneath the green sign?", "What color is the lettering on the white sign?", "What color is the lettering on the green sign?", "What color is the building with the air conditioning unit?", "What color is the sign with black letters?", "What color is the sign with the white letters?", "What color is the item below the green sign?", "How many words are on the white sign?", "What color is the trim on the yellow building?", "How many air conditioning units are attached to the yellow building?", "What color is the sign with A3 on it?", "What is written on the green sign?", "What color is the sign on the building?", "What color is the sign under the green sign?", "What color is the sky?", "What color outlines the green sign?", "What color is the building across the road?", "What color are the letters in the sign?", "What color is the wall that the black and white sign is on?", "What shape is the sign?"], "vqa": ["Is one of the buildings air conditioned?", "What is the sign doing?", "Where is the street sign?", "What language is the sign in?"], "mscoco2": ["a green street sign is pointing towards the right"]}}, {"img_id": "COCO_val2014_000000474881", "labelf": {"vqa": [{"8": 1}, {"no": 1}, {"field": 0.3, "in snow": 0.3, "mountain": 1, "outside": 0.3}]}, "sentf": {"vqa": ["How many horns are there in the picture?", "Are these animals donkeys?", "Where was the picture taken of the Rams?"], "mscoco2": ["A white slope covers the background, while the foreground features a grassy slope with several rams grazing and one measly and underdeveloped evergreen in the foreground.  "]}}, {"img_id": "COCO_val2014_000000017095", "labelf": {"visual7w": [{"Daytime.": 1.0}, {"White.": 1.0}, {"A lady.": 1.0}, {"Clothes.": 1.0}, {"Clear.": 1.0}, {"Backyard.": 1.0}, {"Female.": 1.0}, {"Bench.": 1.0}, {"An older woman.": 1.0}, {"Looking at a big bird.": 1.0}, {"A turkey.": 1.0}, {"Leaves.": 1.0}, {"Sunny and warm.": 1.0}, {"The sun.": 1.0}, {"A friend.": 1.0}, {"Walking.": 1.0}, {"Trees.": 1.0}, {"The woman.": 1.0}, {"A bench.": 1.0}, {"A bird.": 1.0}, {"Wood.": 1.0}, {"Leaves.": 1.0}, {"Trees.": 1.0}, {"Vertical.": 1.0}, {"A bird.": 1.0}, {"Sun.": 1.0}, {"Shoes.": 1.0}, {"The bench.": 1.0}, {"Grass and leaves.": 1.0}, {"Bushes.": 1.0}, {"Pants and a jacket.": 1.0}, {"A peacock.": 1.0}, {"The tree.": 1.0}, {"Wood.": 1.0}, {"Peacock.": 1.0}, {"An elderly woman.": 1.0}, {"Bench.": 1.0}], "vqa": [{"no": 1}, {"yes": 1}, {"no": 1}, {"goose": 0.3, "peacock": 1, "turkey": 0.9}]}, "sentf": {"visual7w": ["When was the photo taken?", "What color is the ladies hair?", "Who is in the photo?", "What is the lady wearing?", "How is the photo?", "Where was the photo taken?", "What gender is the person shown?", "Where is the woman sitting?", "Who is sitting on the bench?", "What is the woman doing?", "What kind of bird is on the grass?", "What is on the grass?", "How's the weather?", "What is shining on the grass?", "Who is taking the picture?", "What is the bird doing?", "What is behind the woman?", "What is shaded?", "What is the lady sitting on?", "What is the lady watching?", "What type of material is the bench made of?", "What is brown all over the ground?", "What is shading the lady from the sun?", "What sort of lines are on the back of the bench?", "What is standing in the grass?", "What is supplying the light in the photo?", "What is the lady wearing for foot protection?", "What is the woman sitting on?", "What is on the ground?", "What is next to the grass?", "What is the woman wearing?", "What type of bird is in the yard?", "What is behind the bench?", "What is the bench made of?", "What is walking in front of the woman?", "Who is sitting on the bench?", "What is the elderly woman sitting on?"], "vqa": ["Is this woman doing something active?", "Is anyone sitting on the bench?", "Is this women young?", "Why kind of bird is walking in front of the woman?"], "mscoco2": ["A elderly lady watching a bird under a tree. "]}}, {"img_id": "COCO_val2014_000000192714", "labelf": {"vqa": [{"green": 1}, {"no": 1}, {"no": 1}, {"chevy": 0.3, "honda": 0.3, "sedan": 1, "toyota": 0.3}, {"no": 1, "yes": 0.9}, {"0": 0.9, "1": 1}, {"green": 1}, {"clear": 0.6, "cloudy": 0.9, "partly cloudy": 0.6, "sunny": 0.3}, {"no": 1}, {"yes": 1}, {"1": 1, "4": 0.3}, {"no": 1, "yes": 1}, {"blue": 1, "blue and white": 0.3}, {"no": 0.3, "yes": 1}, {"green": 1}, {"city": 1, "country": 0.3}]}, "sentf": {"vqa": ["What color is the light?", "Is the vehicle stopped?", "Is there a rainbow in the sky?", "What kind car?", "Should you stop at the intersection?", "How many traffic lights are horizontal?", "What color is the traffic light?", "What kind of weather is it?", "Are the car's brake lights on?", "Is the sky cloudy?", "How many lights are there?", "Is the stop light being obeyed?", "What color is the sky?", "Can you turn at the light?", "Is the light red or green?", "Is this the city or country?"], "mscoco2": ["A car turning right on a red light in front of the photographer"]}}, {"img_id": "COCO_val2014_000000137185", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"round": 1, "square": 0.3, "yes": 0.3}, {"no": 1, "yes": 0.9}, {"15 feet": 0.3, "20 ft": 0.3, "5 feet": 0.3, "50 feet": 0.3, "tall": 0.3}, {"no": 1, "yes": 1}]}, "sentf": {"vqa": ["Is this a professional photo?", "Is the door on the building square or round on top?", "Is it a sunny day in this photo?", "How tall is the tree?", "Is the scene charming?"], "mscoco2": ["A trailer that is near railing under a cloudy sky. "]}}, {"img_id": "COCO_val2014_000000431897", "labelf": {"gqa": [{"yes": 1.0}, {"right": 1.0}, {"giraffe": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"wood": 1.0}, {"giraffe": 1.0}, {"no": 1.0}, {"giraffe": 1.0}, {"giraffe": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"yes": 1.0}], "visual7w": [{"Zoo.": 1.0}, {"Zookeeper.": 1.0}, {"Brown.": 1.0}, {"Daytime.": 1.0}, {"Green.": 1.0}, {"One.": 1.0}, {"Giraffes.": 1.0}, {"Shadow.": 1.0}, {"Trees.": 1.0}, {"In the zoo.": 1.0}, {"On the tree.": 1.0}, {"Behind large wooden posts.": 1.0}, {"On the giraffes.": 1.0}, {"Giraffe.": 1.0}, {"At a zoo.": 1.0}, {"A fence.": 1.0}, {"Giraffes.": 1.0}, {"Behind the giraffe.": 1.0}, {"Wire.": 1.0}, {"Posts.": 1.0}, {"Wood.": 1.0}, {"On the tree.": 1.0}, {"Spotted.": 1.0}, {"Giraffe.": 1.0}, {"Long necks.": 1.0}, {"Knobs.": 1.0}, {"Watching the giraffes.": 1.0}, {"Wood.": 1.0}, {"Giraffe.": 1.0}], "vqa": [{"yes": 1}, {"23": 0.6, "25": 0.6, "35": 0.3, "40": 0.3, "lots": 0.6, "many": 0.3}, {"yes": 1}]}, "sentf": {"gqa": ["Is there a fence in this picture?", "Which side is the fence on?", "What animal is in front of the brush?", "Are these animals of different species?", "Do you see a cow?", "Does the giraffe's horn have dark color?", "Are there either any kites or zebras in the photo?", "What's the fence made of?", "What kind of animal is left of the fence?", "Are there pens or books?", "What animal is the brush behind of?", "What is the animal that the brush is behind of?", "Are there both fences and giraffes in this picture?", "Are there any snowboards or glasses?", "Is the man in the top part of the photo?"], "visual7w": ["Where was the photo taken?", "Who would take care of these animals?", "What color is the buidling in the background?", "When was the photo taken?", "What color are the trees in the top left corner?", "How many eyes of the animal nearest the camera are shown?", "What kind of animals are shown?", "Why is the giraffe's face darkened?", "How is the giraffe covered in shadow?", "Where do the giraffe's live?", "Where are the purple leaves?", "Where are the two giraffes in the background?", "Where are the brown spots?", "What animal is shown?", "Where is the giraffe?", "What is behind the giraffe?", "What is behind the fence?", "Where is the tree?", "What is the fence made of?", "How does the fence stay up?", "What are the fence posts made of?", "Where are the leaves?", "What pattern is the giraffe?", "What animal is present?", "How do giraffes reach high branches?", "What is on top of the giraffe's head?", "What is the person on the platform doing?", "What are the fence posts made of?", "What is right in front of the camera?"], "vqa": ["Is this animal in the shade?", "How many spots are visible?", "Was the photo taken at a zoo?"], "mscoco2": ["A giraffe stands in the foreground next to bushes. "]}}, {"img_id": "COCO_val2014_000000439516", "labelf": {"vqa": [{"black": 0.3, "head": 0.9}, {"giraffe": 1}, {"yes": 1}]}, "sentf": {"vqa": ["Where are the women's sunglasses?", "What is the woman feeding?", "Is there a fence in between the animal and female?"], "mscoco2": ["a giraffe leaning over a fence to eat out of a bowl that a woman is holding "]}}, {"img_id": "COCO_val2014_000000063397", "labelf": {"vqa": [{"african american": 0.3, "indian": 0.9}, {"15": 0.3, "4": 0.3, "5": 1, "6": 0.9, "7": 0.3}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What nationality are the men in the picture?", "How many buildings are in the background?", "Is this a water body area?"], "mscoco2": ["Pedestrians walk across a bridge over a river in a city.", "Several people walking across a bridge over the water."]}}, {"img_id": "COCO_val2014_000000290828", "labelf": {"vqa": [{"no": 1, "yes": 0.3}, {"no": 1, "yes": 0.6}, {"1": 1}]}, "sentf": {"vqa": ["Is this giraffe in a natural setting?", "Are those people able to reach the giraffe?", "How many giraffes are there?"], "mscoco2": ["A giraffe eating grass while people stand above him near a glass fence. "]}}, {"img_id": "COCO_val2014_000000441468", "labelf": {"vqa": [{"black and red": 0.3, "red": 1}, {"no": 1, "yes": 0.6}, {"red": 1}, {"white": 1}, {"in front": 0.3, "on sidewalk": 1, "sidewalk": 0.3, "street": 0.3}, {"black": 1, "black and white": 0.3, "gray": 0.9}]}, "sentf": {"vqa": ["What color is the hydrant?", "Does this hydrant look like it is in the wrong place?", "What color is the fire hydrant?", "What color are the stripes on the ground?", "Where is the fire hydrant?", "What color is the road?"], "mscoco2": ["A red fire hydrant on the right side of a road. "]}}, {"img_id": "COCO_val2014_000000008548", "labelf": {"gqa": [{"clouds": 1.0}, {"gray": 1.0}, {"yes": 1.0}], "visual7w": [{"Flying.": 1.0}, {"During the daytime.": 1.0}, {"Gray.": 1.0}, {"Flying.": 1.0}, {"In the sky.": 1.0}, {"The airplane.": 1.0}, {"Trees.": 1.0}, {"Below the airplane.": 1.0}, {"A plane.": 1.0}], "vqa": [{"bottom": 0.3, "branches": 0.3, "leaves": 0.3, "top": 0.9}, {"commuter": 0.3, "jet": 0.3, "military": 0.3, "passenger": 0.9, "propeller": 0.6}, {"air force": 0.3, "america": 0.3, "army": 0.3, "don't know": 0.3, "military": 0.3, "nobody": 0.3, "pilot": 0.3, "usa": 0.3}, {"yes": 1}, {"i don't know": 0.3, "no": 0.6, "yes": 1}]}, "sentf": {"gqa": ["What is in the sky?", "Is that plane red or gray?", "Is the plane above the tall post?"], "visual7w": ["What is the plane doing?", "When was this photo taken?", "What color is the plane?", "What is the plane doing?", "Where is the plane?", "What has a wing?", "What is below the airplane?", "Where are the buildings?", "What is in the air?"], "vqa": ["What part of the tree would you trim up?", "What kind of plane is this?", "Who owns this plane?", "Are there clouds in the sky?", "Does the plane have two engines?"], "mscoco2": ["a large air plane flying with trees in the background "]}}, {"img_id": "COCO_val2014_000000241559", "labelf": {"vqa": [{"red": 1}, {"2": 1, "3": 0.3}, {}, {"2": 0.3, "afternoon": 0.9, "morning": 0.9}]}, "sentf": {"vqa": ["What color is the first car in the photo?", "How many lanes are there?", "What does the green sign say?", "What time of day is it?"], "mscoco2": ["Large signs are suspended from the buildings above the city street. "]}}, {"img_id": "COCO_val2014_000000020796", "labelf": {"visual7w": [{"A bike.": 1.0}, {"Orange.": 1.0}, {"There are no cars.": 1.0}, {"Yellow.": 1.0}, {"The bicycle light.": 1.0}, {"The red bicycle light.": 1.0}, {"Below the light.": 1.0}, {"It looks yellow.": 1.0}, {"Red and white.": 1.0}, {"Triangle shaped.": 1.0}, {"Black and yellow.": 1.0}, {"Green.": 1.0}, {"Leaves.": 1.0}, {"Cloudy, overcast with no sun.": 1.0}, {"The bicycle lights.": 1.0}, {"Yellow.": 1.0}, {"The light.": 1.0}, {"Oval.": 1.0}, {"Background.": 1.0}, {"Upside down triangle.": 1.0}, {"Bricks.": 1.0}, {"Right.": 1.0}, {"Overcast.": 1.0}], "vqa": [{"bicycle": 0.3, "bike": 0.3, "stop": 0.3}, {"intersection": 0.3, "mirror": 0.3, "tree": 0.3, "trees": 1}, {"orange": 1, "red": 0.6, "yellow": 0.6}]}, "sentf": {"visual7w": ["What is pictured at the top of the light?", "What color is the lighted bike?", "Where are the cars?", "What color is painted around the outside of the traffic light?", "What light is lit up?", "What is turned on?", "Where is the reflector?", "What does the rim of the traffic light look like?", "What basic design is the sign?", "What is the shape of the triangle?", "What are the traffic lights?", "How do the tops of the shrubbery look in color?", "What do the trees lack?", "What is conditions of the sky?", "What is not on in the stop light?", "What is the stoplight painted?", "What bicycle is lit up?", "What shape is the light?", "Where are the trees at?", "What sign is under the light?", "What's the gate made of?", "Where's the poles at?", "What's the sky like?"], "vqa": ["What is the light indicating?", "What is behind the traffic sign?", "What color is the bike?"], "mscoco2": ["a close up of a traffic with trees in the background "]}}, {"img_id": "COCO_val2014_000000101180", "labelf": {"vqa": [{"red": 1}, {"clear": 0.9, "cloudy": 0.6, "partly cloudy": 0.6, "sunny": 0.3}, {"35": 1, "55": 0.3}, {}]}, "sentf": {"vqa": ["What color is the street light?", "What is the weather like?", "What is the speed limit?", "What are the street names?"], "mscoco2": ["A stoplight hangs over an intersection in the city.  "]}}, {"img_id": "COCO_val2014_000000388926", "labelf": {"gqa": [{"boy": 1.0}, {"left": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"bus": 1.0}, {"left": 1.0}, {"no": 1.0}, {"no": 1.0}, {"boy": 1.0}, {"dress": 1.0}, {"lady": 1.0}], "visual7w": [{"Metal.": 1.0}, {"Glass.": 1.0}, {"On a bus.": 1.0}, {"Black.": 1.0}, {"A bar.": 1.0}, {"Daytime.": 1.0}, {"Two.": 1.0}, {"On a bus or train.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"12": 0.6, "13": 0.6, "7": 0.3, "8": 0.3, "9": 0.3, "young": 0.3}, {"2": 0.9, "25": 0.3, "3": 0.3, "5": 0.3, "6": 0.3, "many": 0.3}, {"10 years": 0.3, "30": 0.3, "very": 0.3}]}, "sentf": {"gqa": ["Who is wearing a sweater?", "Which side of the picture is the boy on?", "Is the sweater different in color than the blouse?", "Is the lady to the right of the boy wearing a hat?", "Is the sweater different in color than the scarf?", "Are there both glasses and ties in this scene?", "What is this, a truck or a bus?", "On which side of the image is the boy?", "Are there white scarves or hats?", "Does the scarf have blue color?", "Who is wearing the sweater?", "What is the lady to the right of the boy wearing?", "Who is wearing a dress?"], "visual7w": ["What is the bar made of?", "What are the windows made of?", "Where are the people?", "What color is the bus?", "What are the people leaning on?", "When was the picture taken?", "How many windows are there?", "Where was the picture taken?"], "vqa": ["Are the two boys brothers?", "How old are the kids?", "How many people are standing around?", "How old is this picture?"], "mscoco2": ["A black and white shot show blinds that do not cover a pair of  facility-style windows , and right inside them, a horizontal rail, a pair of women, not facing outside, and a pair of small boys that are touching the rail and looking out.  "]}}, {"img_id": "COCO_val2014_000000012731", "labelf": {"vqa": [{"model": 1}, {"2": 1}, {"bridge": 0.3, "don't know": 0.3, "in air": 0.3, "in middle": 0.3, "on ground": 0.3, "platform": 0.6}]}, "sentf": {"vqa": ["Is this real or a model?", "How many trains appear in this picture?", "Where is the luggage barrow?"], "mscoco2": ["a big long bridge walkway over some green trains", "a bunch of stairs sit over a train "]}}, {"img_id": "COCO_val2014_000000124798", "labelf": {"vqa": [{"no": 0.3, "yes": 1}, {"blue and yellow": 1, "yellow and blue": 0.9}, {"no": 1}, {"19": 0.3, "43": 0.3, "45": 0.3, "49": 1}]}, "sentf": {"vqa": ["Is there construction going on?", "What colors are the bus?", "Is this a painting?", "What bus number?"], "mscoco2": ["Traffic moves on a busy urban street with a crane in the background. "]}}, {"img_id": "COCO_val2014_000000349310", "labelf": {"gqa": [{"yes": 1.0}, {"yes": 1.0}, {"bus": 1.0}], "visual7w": [{"Green.": 1.0}, {"Front.": 1.0}, {"One.": 1.0}, {"Yellow.": 1.0}, {"Zero.": 1.0}, {"Coca Cola.": 1.0}, {"White.": 1.0}, {"Zero.": 1.0}], "vqa": [{"no": 1, "yes": 0.6}, {"directions": 0.3, "nothing": 0.3, "parking": 1, "street sign": 0.3, "warning": 0.3}, {"27": 0.3}, {"no": 1}, {"white": 1}, {"arabic": 0.6, "asian": 0.3, "chinese": 0.3, "german": 0.6, "japanese": 0.6, "russian": 0.3}, {"silver": 0.3, "white": 1, "white and red": 0.3}, {"coca cola": 1, "coke": 0.6}, {"left": 0.3, "right": 1, "south": 0.3, "to right": 0.3, "up": 0.6}]}, "sentf": {"gqa": ["Are there both a bus and a mirror in this image?", "Is the bus both large and white?", "Is this a truck or a bus?"], "visual7w": ["What color are the trees?", "Where are the numbers on the bus visibly located?", "How many buses are on the road?", "What color is the big building in the background?", "How many people are visible on the street?", "What popular beverage is visible in the picture?", "What color are the painted lines on the road?", "How many animals are shown?"], "vqa": ["Is the destination of this bus written in English?", "What does the sign in the back mean?", "What is the bus number?", "Are there yellow lines on the road?", "What color are the road lines?", "What language is that?", "What color is the bus?", "What type of soda machine is on the left side?", "Which way is the arrow pointing?"], "mscoco2": ["A city bus with intersection with a crosswalk and hills behind "]}}, {"img_id": "COCO_val2014_000000373578", "labelf": {"gqa": [{"no": 1.0}, {"path": 1.0}, {"path": 1.0}], "visual7w": [{"Zoo.": 1.0}, {"No one.": 1.0}, {"Giraffe.": 1.0}, {"One.": 1.0}, {"Daytime.": 1.0}, {"Tan and white.": 1.0}], "vqa": [{"dirt": 0.6, "rocks": 1, "stones": 0.3}, {"no": 1, "yes": 1}, {"rocks": 1}, {"grass": 0.3, "leaves": 0.6, "nothing": 1}, {"1": 1}, {"0": 0.3, "100": 0.6, "150": 0.3, "30": 0.3, "50": 0.6, "lot": 0.3}, {"left": 1, "to left": 0.3}, {"100": 0.6, "150": 0.3, "200": 0.3, "many": 0.6}, {"no": 0.3, "yes": 1}, {"no": 1}, {"no": 1, "yes": 0.9}]}, "sentf": {"gqa": ["Are there alarm clocks or balls?", "Which place is it?", "What is the picture showing?"], "visual7w": ["Where is this picture taken?", "Who is in the picture?", "What is pictured?", "How many giraffes are pictured?", "What time of day is it?", "What color is the giraffe?"], "vqa": ["What is on the ground by the animals?", "Is the giraffes neck bent?", "What scenery is in the background?", "What are the giraffes eating?", "How many giraffes are there?", "How many rocks are there?", "Which way is the giraffe pointing?", "How many spots on the giraffe?", "Are rocks behind the giraffe?", "Is the animal eating?", "Were these giraffes photographed in the wild?"], "mscoco2": ["a giraffe walking along a barren path with rocks in background"]}}, {"img_id": "COCO_val2014_000000563067", "labelf": {"vqa": [{"yes": 1}, {"air": 0.6, "city": 0.3, "in air": 0.3, "ski": 0.3, "sky": 1}, {"no": 1}, {"across street": 0.3, "back": 0.3, "background": 0.3, "beach": 0.3, "behind bus": 0.3, "city": 0.3, "in background": 0.3, "outside": 0.3}, {"good": 0.3, "i don't know": 0.3}, {"1": 1}, {"no": 0.3, "photo": 0.3, "photograph": 1}, {"airplane": 1, "bus": 0.6, "plane": 0.3, "train": 0.3}, {"no": 1}, {"airport": 0.3, "bank": 0.3, "business": 0.6, "office": 0.3}, {"0": 1, "1": 0.9, "few": 0.3, "no": 0.3}, {"no": 0.3, "yes": 1}, {"no": 1}, {"2": 1, "3": 0.9, "4": 0.6}, {"yes": 1}, {"no": 1}]}, "sentf": {"vqa": ["Is this plane moving?", "Where is the plane located?", "Is the building shiny?", "Where are the buildings?", "What's the word on the building?", "How many planes are visible?", "Is this a drawling or a photograph?", "What mode of transport is being shown?", "Is there a fence next to the tracks?", "What building is this?", "How many clouds are in the sky?", "Is this a modern building?", "Is there a big bird next to the plane?", "How many modes of transportation are depicted?", "Are the streetlights on?", "Are the buses double deckers?"], "mscoco2": ["a large airplane flying over a building with people walking below", "A plane flying above a building in the city."]}}, {"img_id": "COCO_val2014_000000276024", "labelf": {"vqa": [{"1": 0.9, "2": 1, "3": 0.3}, {"horseback riding": 0.9, "riding": 0.3, "riding horses": 1}, {"yes": 1}, {"2": 1}, {"yes": 1}, {"cow": 1, "horse": 0.6}, {"1": 0.3, "2": 1, "7": 0.3, "horse": 0.3, "horses": 0.3}, {"yes": 1}, {"no": 0.9, "yes": 1}, {"no": 1}, {"horse": 0.3}, {"0": 1, "no": 0.3}]}, "sentf": {"vqa": ["How many black cows are in the image?", "What are the men doing?", "Is one man shirtless?", "How many people are there?", "Is the horse on a path?", "What's the small animal in the middle of this group?", "How many types of animals are pictured?", "Could bananas be growing somewhere nearby?", "Are people watching the animals?", "Will they get sunburned?", "What are the two types of animals in this picture?", "How many sheep are there?"], "mscoco2": ["Two men guiding cows while behind on horses. "]}}, {"img_id": "COCO_val2014_000000187241", "labelf": {"vqa": [{}, {"water": 1, "white": 0.3}, {"water": 1}, {"1": 1, "3": 0.3}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What does the podium say?", "What is in the colorless jug?", "What is the pitcher filled with?", "How many microphones are there?", "Is this man speaking?"], "mscoco2": ["Man sits behind a microphone at a news conference. "]}}, {"img_id": "COCO_val2014_000000492805", "labelf": {"gqa": [{"top": 1.0}, {"metal": 1.0}, {"metal": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"Freight.": 1.0}, {"By pushing.": 1.0}, {"A freight container.": 1.0}, {"Near an underpass.": 1.0}, {"So one train can pull off to let another pass.": 1.0}, {"Red.": 1.0}], "vqa": [{"cars": 0.3, "road": 0.3, "yes": 0.3}, {"black": 0.3, "black and yellow": 0.3, "blue": 0.3, "blue and red": 0.3, "blue and yellow": 0.3, "yellow": 0.3, "yellow and black": 0.3}, {"1": 0.3, "2": 1, "3": 1}]}, "sentf": {"gqa": ["Is the fence in the top part or in the bottom of the picture?", "What's the fence made of?", "Which material is the fence made of?", "Do the hillside and the bridge have a different colors?", "Is there a train in the image?", "Does the bridge have red color?", "Are there alarm clocks or life jackets?", "Are there both toolboxes and fences in the photo?"], "visual7w": ["When was this picture taken?", "What kind of train is this?", "How is the locomotive moving the freight?", "What is the locomotive pushing?", "Where is the train?", "Why is there a fork in the train tracks?", "What color is the freight container?"], "vqa": ["Why is there a bridge going over the railroad tracks?", "What color is the train?", "How many train cars do we see?"], "mscoco2": ["A train engine merging onto a track and passing under a bridge "]}}, {"img_id": "COCO_val2014_000000134346", "labelf": {"vqa": [{"1": 0.6, "2": 1}, {"yes": 1}, {"brown": 1, "grizzly": 1}]}, "sentf": {"vqa": ["How many bears are in the enclosure?", "Are these bears in captivity?", "What kind of bears are they?"], "mscoco2": ["A bear in a zoo looks over the safety fence. "]}}, {"img_id": "COCO_val2014_000000557190", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"blue": 1.0}], "visual7w": [{"Hillside.": 1.0}, {"Men.": 1.0}, {"2.": 1.0}, {"Autumn.": 1.0}, {"White.": 1.0}, {"Gray.": 1.0}, {"A mountainside.": 1.0}], "vqa": [{"both": 1, "right": 0.6}, {"no": 0.9, "yes": 1}, {"black": 0.6, "black and gray": 0.6, "gray": 1}, {"2": 1}, {"no": 1}, {"man on right": 0.9, "right": 0.6, "to right": 0.3}]}, "sentf": {"gqa": ["Are there both ties and glasses?", "Is the hair curly?", "What is the color of the sky?"], "visual7w": ["What is in the background?", "Who is in the picture?", "How many men in the pic?", "When is the picture taken?", "What color is the young man's tie?", "What color is the older mans suit?", "Where is the scene?"], "vqa": ["Which person is being nice?", "Are they likely related?", "What color are they both wearing?", "How many men are shown?", "Does the man have gloves on?", "Which man is taller?"], "mscoco2": ["Two men in suits pose for a photo in front of hilly background. "]}}, {"img_id": "COCO_val2014_000000043535", "labelf": {"vqa": [{"no": 1, "yes": 0.3}, {"no": 1}, {"12": 0.3, "2": 0.3, "20": 0.3, "3": 0.3, "30": 0.6, "50": 0.3, "unknown": 0.3, "young": 0.3}, {"wood": 1}, {"gray": 1, "green": 0.6, "tan": 0.3}, {"1": 1}, {"closed": 0.6, "open": 1}]}, "sentf": {"vqa": ["Is a human touching the elephants ears?", "Is the elephant getting a bath?", "How old is the little elephant?", "What are the bars behind the elephant made of?", "What color is the child's hat?", "How many elephants are shown?", "Are the elephant's eyes open or closed?"], "mscoco2": ["a person standing right next to an elephant whiile giving them a kiss "]}}, {"img_id": "COCO_val2014_000000222440", "labelf": {"gqa": [{"yes": 1.0}, {"right": 1.0}, {"no": 1.0}, {"no": 1.0}, {"people": 1.0}, {"people": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"zoo": 1.0}, {"right": 1.0}, {"wood": 1.0}, {"yes": 1.0}], "visual7w": [{"One.": 1.0}, {"The zoo.": 1.0}, {"Daytime.": 1.0}, {"Blue and white.": 1.0}, {"Trees.": 1.0}, {"Brown.": 1.0}], "vqa": [{"zoo": 1}, {"elephant": 0.9, "elephants": 1}, {"no": 1}, {"yes": 1}, {"yes": 1}, {"grass": 0.3, "trees": 0.3, "weeds": 0.3}]}, "sentf": {"gqa": ["Do you see any fences or benches that are made of wood?", "On which side of the photo is the man?", "Is the sky cloudless and blue?", "Do you see either benches or clocks there?", "Who is before the building?", "Who is in front of the building?", "Is the elephant on the left or on the right side?", "Is this an image of the zoo?", "Which place is it?", "Is the man to the right or to the left of the people that are in front of the building?", "What is the fence made of?", "Does the fence look wooden?"], "visual7w": ["How many elephants are there?", "Where was the picture taken?", "When was the picture taken?", "What color is the sky?", "What is behind the elephant?", "What color is the elephant?"], "vqa": ["What is the location?", "What animals are shown?", "Are there any baby giraffes in this photo?", "Are there animals?", "Are there people present?", "What type of plants are growing along the water?"], "mscoco2": ["A group of people behind a fence near an elephant."]}}, {"img_id": "COCO_val2014_000000044621", "labelf": {"gqa": [{"cow": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"man": 1.0}, {"left": 1.0}, {"frame": 1.0}, {"street": 1.0}, {"no": 1.0}, {"gate": 1.0}, {"gate": 1.0}, {"gray": 1.0}], "visual7w": [{"A man.": 1.0}, {"In front of the man.": 1.0}, {"Glasses.": 1.0}, {"Black.": 1.0}, {"Cow.": 1.0}, {"Eyeglass.": 1.0}, {"He is smiling.": 1.0}, {"A black cow.": 1.0}, {"A brick wall.": 1.0}, {"A blue t shirt.": 1.0}, {"Black rim glasses.": 1.0}, {"Walking beside the cow.": 1.0}, {"A brown brick building.": 1.0}, {"A blue t shirt.": 1.0}, {"There is writing on the shirt.": 1.0}], "vqa": [{"no": 1, "yes": 0.3}, {}, {"black": 1}, {"man": 1}]}, "sentf": {"gqa": ["How is the black animal called?", "Does the gate have a different color than the sock?", "Is the man wearing glasses?", "On which side of the image is the man?", "Do you see cows to the left of the person the person is to the right of?", "Who is wearing the glasses?", "On which side of the photo are the glasses?", "What is the person to the right of the woman leaving?", "Which place is it?", "Is the gate different in color than the cow?", "The sign is on what?", "What's the sign on?", "Is the tshirt gray or red?"], "visual7w": ["Who is smiling?", "Where is the cow?", "What is on the man's face?", "What color is the cow?", "What animal is this?", "What is the man wearing on face?", "What is the man doing?", "What is beside the man?", "What is behind the man?", "What does the man have on?", "What's on the eyes?", "What is the man doing?", "What is behind the man?", "What covers the man's upper body?", "What is on the t shirt?"], "vqa": ["Is this animal a carnivore?", "What is the capital of the state on man's shirt?", "What color are the tips of the cow's ears?", "Who is laughing?"], "mscoco2": ["A man standing behind a black cow in a street."]}}, {"img_id": "COCO_val2014_000000465601", "labelf": {"vqa": [{"umbrella": 1}, {"2": 0.3, "4": 0.6, "5": 1}, {"no": 0.6, "yes": 1}]}, "sentf": {"vqa": ["What is the woman holding?", "How many umbrellas are up?", "Is this a tourist attraction?"], "mscoco2": ["A woman is standing in the rain under a pink umbrella. "]}}, {"img_id": "COCO_val2014_000000008333", "labelf": {"gqa": [{"no": 1.0}, {"fence": 1.0}, {"tree": 1.0}, {"bottom": 1.0}, {"no": 1.0}, {"left": 1.0}, {"left": 1.0}, {"city": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"no": 1.0}, {"no": 1.0}, {"white": 1.0}], "visual7w": [{"Virgin.": 1.0}, {"Blue.": 1.0}, {"A large city.": 1.0}, {"One.": 1.0}, {"Passengers travelling.": 1.0}, {"On a bridge.": 1.0}, {"To stop traffic.": 1.0}, {"During the daytime.": 1.0}], "vqa": [{"virgin": 1}, {"red": 0.3, "red and silver": 0.3, "red and white": 0.9, "white": 0.3, "white and red": 0.3}, {"no": 1, "yes": 0.3}, {"virgin": 1}, {"directions": 0.3, "graffiti": 0.3, "phone": 0.3, "traffic": 0.3, "virgin": 0.9, "window": 0.3}, {"no": 0.3, "yes": 1}, {"virgin": 1}, {"us": 0.3, "virgin": 1}]}, "sentf": {"gqa": ["Does the car on the road have black color?", "What's in front of the tree?", "What is the fence in front of?", "Is the fence in the top part or in the bottom of the picture?", "Is there a bus next to the sidewalk?", "On which side is the car?", "On which side of the image is the car?", "Which place is it?", "Are there any white buses or trains?", "On which side of the photo is the small car?", "Are there white windows or doors?", "Is the tree in front of the fence which is next to the sidewalk?", "What is the color of the train?"], "visual7w": ["What is written on the train?", "What color is the garage door?", "What is the train running through?", "How many trains are there?", "Who rides this train?", "Where is the train?", "Why is the traffic light red?", "When was this photo taken?"], "vqa": ["What is the train's name?", "What color is the train?", "Did the train just stop?", "What is written on the speed train?", "What kind of sign is next to the train?", "Is this an urban area?", "What cell phone company is advertised on the front of the train?", "What show is this train from?"], "mscoco2": ["A passenger train that is going over a bridge."]}}, {"img_id": "COCO_val2014_000000373341", "labelf": {"gqa": [{"wide": 1.0}, {"right": 1.0}, {"right": 1.0}, {"silver": 1.0}, {"street": 1.0}, {"street": 1.0}, {"left": 1.0}, {"right": 1.0}, {"no": 1.0}, {"white": 1.0}, {"yes": 1.0}, {"blue": 1.0}, {"left": 1.0}], "visual7w": [{"FedEx.": 1.0}, {"Yellow.": 1.0}, {"One.": 1.0}, {"Black.": 1.0}, {"Green.": 1.0}, {"Stop.": 1.0}, {"Bottom of hill.": 1.0}], "vqa": [{"yes": 1}, {"no": 1}, {"yes": 1}]}, "sentf": {"gqa": ["What width is the street?", "On which side is the motorbike, the left or the right?", "On which side is the silver car, the right or the left?", "What color is the car by the street?", "What is the photo showing?", "Which place is it?", "Is the truck to the left or to the right of the SUV?", "Which side is the dark car on?", "Is there either any red bus or truck?", "What color does the truck have?", "Are there any motorcycles on the street?", "What color is the house?", "Is the truck to the left or to the right of the car in the bottom of the picture?"], "visual7w": ["What company is the truck with?", "What color are the dashes on the street?", "How many pickup trucks are in the picture?", "What color is the scooter?", "What color is the word EX?", "What word is painted on the street at the start of the hill?", "Where is the yellow color striped cross walk?"], "vqa": ["Are the truck's lights on?", "Is that a ups truck?", "Is this San Francisco?"], "mscoco2": ["Delivery truck waiting at traffic light behind car. "]}}, {"img_id": "COCO_val2014_000000298628", "labelf": {"gqa": [{"field": 1.0}, {"field": 1.0}, {"cow": 1.0}, {"cow": 1.0}, {"yes": 1.0}, {"cow": 1.0}, {"fence": 1.0}, {"black": 1.0}], "visual7w": [{"Green.": 1.0}, {"Wood.": 1.0}, {"Clear.": 1.0}, {"Daytime.": 1.0}, {"Cows.": 1.0}, {"Farm.": 1.0}, {"No one.": 1.0}, {"Outdoor.": 1.0}, {"Standing in a field.": 1.0}, {"Wooden and barbed wire.": 1.0}, {"Flower buds.": 1.0}, {"Blue sky.": 1.0}, {"Cows.": 1.0}, {"In a fenced field.": 1.0}, {"Wood and metal wires.": 1.0}, {"Lined up sideways.": 1.0}, {"Sunny, with blue sky.": 1.0}, {"The farmer who owns the cows.": 1.0}, {"Because it is the only black cow.": 1.0}, {"On green grass.": 1.0}, {"Cows.": 1.0}, {"Fence.": 1.0}, {"Wood.": 1.0}, {"Metal wire.": 1.0}, {"Metal.": 1.0}, {"Grass.": 1.0}, {"The one on the left.": 1.0}, {"Barbed wire.": 1.0}, {"In a field.": 1.0}, {"The one in the middle.": 1.0}, {"A farmer.": 1.0}, {"Standing around.": 1.0}, {"Green field.": 1.0}], "vqa": [{"no": 1}, {"black": 1}, {"barbed wire": 1, "wire": 0.6, "wires": 0.3}, {"2": 1, "3": 0.3, "6": 0.3}]}, "sentf": {"gqa": ["Where was the photo taken?", "Which place is it?", "What animal is standing in the green grass?", "What animal stands in the grass?", "Are there both cows and fences in this image?", "What type of animal is standing behind the fence?", "What is the black cow standing behind of?", "Of what color is the cow that is on the left side?"], "visual7w": ["What color is the grass?", "What is the fence made of?", "How is the photo?", "When was this?", "What animals are there?", "Where is this scene?", "Who is there?", "What type of scene is this?", "What are the cows doing?", "What type of gate is shown?", "What is in front of the gate?", "What is behind the cows in the picture?", "What are standing in the grass?", "Where are the cows?", "What is the fence made of?", "How are the cows positioned?", "How is the weather?", "Who will take the cows out of the field?", "Why is the cow on the left different from the other two?", "Where are the cows standing on?", "What are the animals?", "What encloses the field?", "What is the brown fence part made of?", "What is the grey fence part made of?", "What is the wire made of?", "What covers the ground here?", "What cow is black?", "What is attached to the wood?", "Where are the cows?", "What cow is looking at the camera?", "Who owns the cows?", "What are the cows doing?", "Where are the cows?"], "vqa": ["Is this at a beach?", "What color is the cow on the left?", "What is connected to the fence?", "How many brown cows are there?"], "mscoco2": ["Three cows stand behind a fence in a field."]}}, {"img_id": "COCO_val2014_000000114744", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"left": 1.0}, {"right": 1.0}, {"color": 1.0}, {"left": 1.0}, {"lady": 1.0}, {"sign": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"Rain.": 1.0}, {"One.": 1.0}, {"Black.": 1.0}, {"Two.": 1.0}, {"Motorcycle.": 1.0}, {"To avoid getting wet.": 1.0}, {"On the street corner.": 1.0}, {"It's raining.": 1.0}, {"The person wearing black.": 1.0}, {"On a sidewalk.": 1.0}, {"Busy.": 1.0}, {"An awning.": 1.0}, {"An umbrella.": 1.0}, {"The sidewalk.": 1.0}, {"A red scooter.": 1.0}, {"A black jacket.": 1.0}, {"The rain.": 1.0}, {"An umbrella.": 1.0}, {"A purse.": 1.0}, {"The top two.": 1.0}, {"Rain water.": 1.0}, {"White and black.": 1.0}, {"Walking in the rain.": 1.0}], "vqa": [{"yes": 1}, {"rain": 1}, {"helmet": 0.3, "hood": 0.3, "umbrella": 1}]}, "sentf": {"gqa": ["Are there umbrellas to the left of the car on the left?", "Is there an umbrella above the person the car is to the left of?", "Is the motorcycle yellow?", "Is the car on the left side or on the right?", "Is the lady to the left or to the right of the vehicle that is on the left side of the picture?", "What do the coat and the seat have in common?", "Is the lady to the right or to the left of the motorcycle?", "Who is under the umbrella that is in the middle of the image?", "What is on the pole?"], "visual7w": ["When is this taking place?", "What kind of weather is this?", "How many umbrellas are in the photo?", "What color is the umbrella?", "How many people are in the photo?", "What vehicle is in front of the person about to cross the street with the umbrella?", "Why is the person carrying an umbrella?", "Where is this taking place?", "Why is the man holding the umbrella?", "Who is holding the umbrella?", "Where are the people at?", "How is the traffic?", "What are the people under?", "What is the lady holding?", "What is in front of the lady?", "What is parked under the street sign?", "What is the person under the umbrella wearing?", "What are the people standing in?", "What is the woman holding?", "What is the woman holding?", "What signs face right?", "What is dripping from the eaves?", "What hue is the umbrella?", "What is the person in the hoodie doing?"], "vqa": ["Is it raining?", "What type of precipitation is in this image?", "What does the person have over their head?"], "mscoco2": ["People stand under umbrellas in the rain next to a motorcycle."]}}, {"img_id": "COCO_val2014_000000456239", "labelf": {"vqa": [{"for fun": 0.3, "fun": 0.6, "pictures": 0.3}, {"umbrella": 1}, {"no": 1, "yes": 0.6}]}, "sentf": {"vqa": ["Why is this girl walking on train tracks?", "What is she holding on her hand?", "Is the woman wearing pants?"], "mscoco2": ["A girl wearing white shorts walks across train tracks while holding an umbrella above herself"]}}, {"img_id": "COCO_val2014_000000440359", "labelf": {"gqa": [{"car": 1.0}, {"car": 1.0}, {"right": 1.0}, {"seat": 1.0}, {"seat": 1.0}, {"dog": 1.0}, {"dog": 1.0}, {"car": 1.0}, {"tall": 1.0}, {"collar": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"Front seat.": 1.0}, {"Dog.": 1.0}, {"Sitting.": 1.0}, {"Dark gray.": 1.0}, {"Waiting for owner.": 1.0}, {"Vehicle.": 1.0}], "vqa": [{"no": 1, "yes": 0.9}, {"dog": 1}, {"no": 0.6, "yes": 1}, {"mutt": 0.3, "terrier": 0.9}]}, "sentf": {"gqa": ["What kind of vehicle do you think is to the right of the fence that is on the left?", "Which kind of vehicle is to the right of the fence?", "Is the dog to the right or to the left of the box on the left of the picture?", "The dog to the right of the fence is sitting on what?", "What is the dog sitting on?", "What is that animal called?", "Is this a bird or a dog?", "Where is the dog?", "How tall is the fence?", "What's the dog wearing?"], "visual7w": ["When was this photo taken?", "Where is the animal?", "What type of animal is in the photo?", "How is the dog positioned?", "What color is the dog?", "Why might the animal be in vehicle?", "What can be seen immediately out window behind dog?"], "vqa": ["Is the truck moving?", "Who is sitting in the passenger seat?", "Is dog waiting for driver?", "What breed of dog is that?"], "mscoco2": ["a dog is sitting inside a vehicle right in the front seat. "]}}, {"img_id": "COCO_val2014_000000082576", "labelf": {"gqa": [{"yes": 1.0}, {"boat": 1.0}, {"no": 1.0}, {"no": 1.0}, {"cliff": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"small": 1.0}, {"boat": 1.0}, {"yes": 1.0}], "visual7w": [{"Afternoon.": 1.0}, {"Shallow ocean.": 1.0}, {"Clear.": 1.0}, {"Docked.": 1.0}, {"Tree.": 1.0}, {"Very bright.": 1.0}, {"Ocean.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"blue": 1, "clear": 0.3}, {"no": 1}]}, "sentf": {"gqa": ["Is the sky the same color as the flag?", "What is the watercraft that the cliff is behind of?", "Are there benches or knife blocks in the picture?", "Are there both grass and sand in the picture?", "What is this boat in front of?", "On which side of the photo is the rope?", "Is the water above the sand both calm and clear?", "Do you see either pliers or carts?", "How large do you think is this boat?", "What is the ladder on?", "Are there both boats and ropes in this picture?"], "visual7w": ["When in the day is this?", "Where is this scene?", "What is the sky like?", "Why is the canoe there?", "What is on the right?", "How bright is it?", "What is in the background?"], "vqa": ["Does the boat have a canopy?", "What is the color of the water?", "Is it snowy?"], "mscoco2": ["An empty boat is tied up over clear water. "]}}, {"img_id": "COCO_val2014_000000220722", "labelf": {"vqa": [{"green": 1}, {"yes": 1}, {"blue and green": 0.3, "multi colored": 0.6, "rainbow": 1}]}, "sentf": {"vqa": ["What is the color of the truck?", "Are the people in the back of the truck happy?", "What color is the umbrella?"], "mscoco2": ["People riding on the back of a truck under an umbrella. "]}}, {"img_id": "COCO_val2014_000000233994", "labelf": {"gqa": [{"calm": 1.0}], "visual7w": [{"In the water.": 1.0}, {"Daytime.": 1.0}, {"Wavey.": 1.0}, {"A mountain.": 1.0}, {"Blue.": 1.0}], "vqa": [{"sailboat": 0.6, "yes": 1}, {"blue": 1, "blue and white": 0.3}, {"no": 0.6, "yes": 1}, {"10": 0.3, "15": 0.6, "19": 0.3, "20": 0.6, "24": 0.3, "25": 0.6, "44": 0.3}, {"no": 1}, {"blue": 1}, {"boating": 0.3, "sailing": 1}, {"fish": 1, "raft": 0.6, "rocks": 0.3, "waves": 0.3}, {"no": 1}]}, "sentf": {"gqa": ["How is the water?"], "visual7w": ["Where are the boats?", "When was the picture taken?", "How is the water?", "What is behind the boats?", "What color is the water?"], "vqa": ["Is either boat a sailboat?", "What color is the sky?", "Is the water clear?", "How many boats are in the water?", "Can you see the bottom of the ocean?", "What color is the water?", "What sport is pictured?", "Besides the boats, what else is in the water?", "Is it a very cloudy day?"], "mscoco2": ["Sailboat regatta on water near mountain in background. "]}}, {"img_id": "COCO_val2014_000000079544", "labelf": {"gqa": [{"right": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"blue": 1.0}, {"yes": 1.0}, {"pants": 1.0}, {"left": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"table": 1.0}, {"right": 1.0}, {"pants": 1.0}, {"no": 1.0}, {"no": 1.0}, {"right": 1.0}, {"table": 1.0}, {"pants": 1.0}, {"yes": 1.0}], "visual7w": [{"Two.": 1.0}, {"White.": 1.0}, {"Top left.": 1.0}, {"The woman in the red tanktop.": 1.0}, {"Transfer.": 1.0}, {"Red.": 1.0}, {"Two.": 1.0}, {"Baby.": 1.0}, {"A woman and baby.": 1.0}, {"Red.": 1.0}, {"In the woman's arms.": 1.0}, {"Blue.": 1.0}, {"Two.": 1.0}, {"One.": 1.0}, {"Square.": 1.0}, {"Tan.": 1.0}, {"Red.": 1.0}, {"Three.": 1.0}, {"One.": 1.0}, {"Three.": 1.0}, {"Wood.": 1.0}, {"White.": 1.0}, {"Luggage.": 1.0}, {"Luggage.": 1.0}, {"Black.": 1.0}, {"Her baby.": 1.0}, {"A tag.": 1.0}, {"White.": 1.0}, {"Red.": 1.0}, {"A double sided mirror.": 1.0}, {"One.": 1.0}, {"Two.": 1.0}], "vqa": [{"yes": 1}, {"12": 0.3, "14": 0.3, "3": 0.9, "4": 0.3, "5": 0.9, "9": 0.3}, {"yes": 1}, {"no": 1, "yes": 0.6}]}, "sentf": {"gqa": ["Is the large mirror to the right or to the left of the blinds that are covering the window?", "Is there a motorcycle to the left of the mirror?", "Is there a chair to the right of the person with the baby?", "Are there cows or dogs?", "Does the table have a different color than the lamp?", "Does that lamp look white?", "On which side is the white lamp, the right or the left?", "Which color do you think are the trousers the baby is wearing?", "Is the chair on the right side?", "What does the woman wear?", "On which side of the picture is the clock?", "On which side are the blinds?", "Is the large mirror to the left of a lamp?", "Do you see any vases on the green table?", "Does the person with the baby look brunette?", "What is the purse on?", "On which side of the photo is the purse?", "What is the baby wearing?", "Do you see any table that is dark brown?", "Do you see either any blond women or men?", "Is the large mirror to the left or to the right of the clock on the wall?", "What is the dish on?", "What does the woman with the baby wear?", "Is the large mirror to the right of the baby that is wearing pants?"], "visual7w": ["How many windows are totally or partially visible?", "What color is the lampshade in the top right corner?", "What corner of the photo is the clock closest to?", "Who is holding the baby?", "What does the white tag on the red suitcase say?", "What color is the suitcase closest to the photographer?", "How many people are in the photo?", "What is the woman holding?", "Who is the the room?", "What color is the woman's top?", "Where is the baby?", "What color are the baby's pants?", "How many people are pictured here?", "How many red suitcases are pictured?", "What shape is the table on the right?", "What color are the walls?", "What color is the woman's shirt?", "How many suitcases are in the picture?", "How many blue suitcases are pictured?", "How many suitcases have tags attached?", "What material is the floor made from?", "What color is the blanket the woman is holding?", "What are the mom and baby looking at?", "What is on the floor?", "What color is the luggage bags?", "What is the mom holding?", "What is attached to the luggage?", "What color is the baby's shirt?", "What color is the mom's shirt?", "What is behind the woman and baby?", "How many red suitcases are pictured?", "How many people are pictured here?"], "vqa": ["Are they traveling somewhere?", "How many pieces of luggage are in the room?", "Is this room cluttered?", "Is the baby in this photo a toddler?"], "mscoco2": ["A room filled with suitcases, and a woman holding a baby behind the suitcases. "]}}, {"img_id": "COCO_val2014_000000487282", "labelf": {"vqa": [{"no": 1}, {"black": 1}, {"yes": 1}]}, "sentf": {"vqa": ["Is she unhappy?", "What color is the suitcase?", "Does she have a hat on?"], "mscoco2": ["A woman stands behind her luggage next to a building. "]}}, {"img_id": "COCO_val2014_000000296393", "labelf": {"gqa": [{"outdoors": 1.0}, {"umbrella": 1.0}, {"boy": 1.0}, {"no": 1.0}, {"left": 1.0}, {"cars": 1.0}, {"cars": 1.0}, {"girl": 1.0}, {"woman": 1.0}, {"no": 1.0}, {"cars": 1.0}, {"left": 1.0}, {"sidewalk": 1.0}, {"boy": 1.0}, {"no": 1.0}, {"little": 1.0}, {"shirt": 1.0}, {"yes": 1.0}, {"wire": 1.0}, {"girl": 1.0}, {"left": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}], "visual7w": [{"Blue.": 1.0}, {"Two.": 1.0}, {"A stone.": 1.0}, {"Its raining.": 1.0}, {"A girl.": 1.0}, {"In front of the green car.": 1.0}, {"Leaves.": 1.0}, {"The boy.": 1.0}, {"The boy.": 1.0}, {"The monument.": 1.0}, {"Cars.": 1.0}, {"Next to sidewalk.": 1.0}, {"A striped umbrella.": 1.0}, {"A dolphin.": 1.0}, {"Whale head.": 1.0}, {"In boy's hands.": 1.0}, {"Large.": 1.0}, {"A woman.": 1.0}, {"An umbrella.": 1.0}, {"A fish.": 1.0}], "vqa": [{"no": 1, "yes": 1}, {"yes": 1}, {"no": 1}, {"bird": 0.3, "stone": 0.3, "swan": 0.3, "whale": 1}, {"0": 1, "1": 0.3}]}, "sentf": {"gqa": ["Is it indoors or outdoors?", "What's the boy holding?", "Who is holding the striped umbrella?", "Is the boy to the left of the fence holding a cell phone?", "On which side are the cars?", "What are the vehicles on the street?", "Which kind of vehicle is on the street?", "Who is the person that is to the left of the bench walking with?", "Who is walking with the girl?", "Is the person that is to the left of the bench holding a phone?", "What vehicles are to the left of the umbrella that is held by the boy?", "Are the cars to the right or to the left of the person that is to the left of the bench?", "What place is shown?", "Who is younger, the boy or the woman?", "Does the fence look large and black?", "How old is the boy that is holding the umbrella?", "What is the person that is to the left of the fence wearing?", "Is the striped umbrella to the right of the cars on the left?", "What is on the pole?", "Who is the woman walking with?", "Are the cars to the right or to the left of the umbrella the boy is holding?", "Do you see bikes on the street?", "Is that fence large?", "Are there fences or umbrellas that are black?", "Are there either any umbrellas or books?"], "visual7w": ["What color is the boy shirt?", "How many umbrellas in picture?", "What is the kid standing next to?", "Why is the lady holding a umbrella?", "Who is with the woman?", "Where is the red truck?", "What is hanging from the trees?", "Who has on sandals?", "Who is holding an umbrella?", "What is made of stone?", "What are parked on street?", "Where are the trees located?", "What is the boy with blonde hair holding?", "What is carved into stone?", "What is carved into stone?", "Where is the striped umbrella?", "How big is the gray stone sculpture?", "Who is walking with little girl?", "What is the little boy holding?", "What is the carving of in a big rock?"], "vqa": ["Is this part of an exhibition?", "Is the boy standing on brick?", "Does this little boy have a toy in his hands?", "What kind of creature is carved in the stone next to the little boy?", "How many stormtroopers are there?"], "mscoco2": ["A little boy is standing in the rain under a blue umbrella. "]}}, {"img_id": "COCO_val2014_000000359164", "labelf": {"visual7w": [{"Dogs.": 1.0}, {"Black.": 1.0}, {"2.": 1.0}, {"Brown.": 1.0}, {"Back yard.": 1.0}, {"Owner.": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"grass": 0.3, "ground": 0.3, "on grass": 0.3, "on ground": 0.3, "outside": 0.3, "park": 0.9, "yard": 0.3}, {"pee": 0.3, "run": 0.3}]}, "sentf": {"visual7w": ["What type of animals are in the picture?", "What color is the chairs in the background?", "How many dogs are in the picture?", "What color is the dogs?", "Where was this picture taken?", "Who took this picture?"], "vqa": ["Does the brown puppy want to play?", "Where are the dogs?", "What is the retriever puppy about to do based on the body position?"], "mscoco2": ["two puppies play outside in the grass under a table"]}}, {"img_id": "COCO_val2014_000000521288", "labelf": {"gqa": [{"yes": 1.0}, {"gray": 1.0}, {"no": 1.0}, {"no": 1.0}], "visual7w": [{"Elephants.": 1.0}, {"Daytime.": 1.0}, {"In the wild.": 1.0}, {"3.": 1.0}, {"It's a baby.": 1.0}, {"Grey.": 1.0}, {"Green.": 1.0}, {"With her tail.": 1.0}], "vqa": [{"tail": 1}, {"2": 1, "3": 1}, {"no": 1}, {"tail": 1}, {"no": 1}, {"no": 0.6, "yes": 1}]}, "sentf": {"gqa": ["Is the tail long and gray?", "Is the tail yellow or gray?", "Is there either a penguin or a giraffe in the image?", "Is the ground grassy?"], "visual7w": ["What animals are in this picture?", "When was this picture taken?", "Where was this picture taken?", "How many elephants are in the picture?", "Why is one elephant smaller?", "What color are the elephants?", "What color are the leaves on the trees?", "How is the mother holding the baby?"], "vqa": ["What does the elephants trunk playing with?", "How many elephants are there?", "Is the left elephant the mother?", "What is touching the baby's trunk?", "Is the smaller elephant full grown?", "Is the elephant free?"], "mscoco2": ["A baby elephant is following behind an adult elephant. ", "A baby elephant is walking behind her mother. "]}}, {"img_id": "COCO_val2014_000000066800", "labelf": {"visual7w": [{"It is daytime.": 1.0}, {"Daytime.": 1.0}, {"To the right of the elephant.": 1.0}, {"1.": 1.0}, {"Grey.": 1.0}, {"1.": 1.0}, {"2.": 1.0}, {"The sky.": 1.0}, {"Near the mountains.": 1.0}, {"One.": 1.0}, {"One.": 1.0}, {"Brown.": 1.0}, {"Grey.": 1.0}, {"One.": 1.0}, {"On the left.": 1.0}, {"Two.": 1.0}, {"Open field.": 1.0}, {"Green.": 1.0}, {"Two.": 1.0}, {"One.": 1.0}, {"Brown.": 1.0}, {"Hills.": 1.0}], "vqa": [{"no": 1}, {"yes": 1}, {"1": 1}, {"no": 1}, {"1": 1, "2": 0.3}]}, "sentf": {"visual7w": ["Why is there a shadow?", "When was the picture taken?", "Where are the flowers?", "How many elephant?", "What is the color of the elephant?", "How many tusk are there?", "How many ears for elephant?", "What is above the mountains?", "Where is the river?", "How many tusks does the elephant have?", "How many mountains are there?", "What color is the land?", "What color is the elephant?", "How many elephants are there?", "Where is the remaining tusk?", "How many ears does the elephant have?", "Where is the elephant?", "What color is the grass?", "How many zebras are there?", "How many tusks does the elephant have?", "What color is the elephant?", "What type of terrain is in the background?"], "vqa": ["Is the elephant running away?", "Are there other animals?", "How many tusks does this elephant have?", "Is the elephant walking in a herd?", "How many tusks does the elephant have?"], "mscoco2": ["An elephant is facing forward with zebras in the background. "]}}, {"img_id": "COCO_val2014_000000306855", "labelf": {"gqa": [{"no": 1.0}, {"chair": 1.0}, {"chair": 1.0}, {"yes": 1.0}, {"window": 1.0}, {"window": 1.0}, {"cat": 1.0}, {"white": 1.0}, {"yes": 1.0}, {"chair": 1.0}, {"top": 1.0}, {"top": 1.0}, {"chair": 1.0}, {"yes": 1.0}, {"chair": 1.0}, {"chair": 1.0}, {"cat": 1.0}, {"chair": 1.0}, {"metal": 1.0}, {"metal": 1.0}, {"yes": 1.0}, {"no": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"Cat.": 1.0}, {"Chair.": 1.0}, {"Wood.": 1.0}, {"Black, gray, and white.": 1.0}, {"White.": 1.0}, {"Down.": 1.0}, {"Close to the chair.": 1.0}, {"On the window frame.": 1.0}, {"During daylight hours.": 1.0}, {"Cat.": 1.0}, {"A chair.": 1.0}, {"He is a kitten.": 1.0}, {"Window.": 1.0}, {"Down.": 1.0}, {"Wood.": 1.0}, {"White and gray.": 1.0}, {"On a chair.": 1.0}, {"Kitten.": 1.0}, {"Legs and stomach.": 1.0}, {"Kitten.": 1.0}, {"On the chair.": 1.0}, {"At the ground.": 1.0}, {"Under the window.": 1.0}, {"A chair.": 1.0}, {"The kitten.": 1.0}, {"Sitting on the chair.": 1.0}, {"Sun shining.": 1.0}, {"Sitting on a chair.": 1.0}, {"A kitten.": 1.0}, {"A kitten.": 1.0}, {"A kitten.": 1.0}, {"The kitten.": 1.0}, {"The wall.": 1.0}, {"The cat.": 1.0}, {"The cat.": 1.0}, {"The bottle.": 1.0}], "vqa": [{"house": 1, "kitchen": 0.3}, {"chair": 1, "on chair": 0.6}, {"no": 1}, {"gray and white": 1, "white and gray": 0.3}]}, "sentf": {"gqa": ["Is there a bird or a cat that is not white?", "What's the cat on?", "What is the cat on?", "Is the sun in the window?", "What is the sun in?", "The sun is in what?", "What animal is in front of the wall?", "What color is the cat?", "Are the wall and the cat the same color?", "What item of furniture is made of the same material as the frame that is shown in the picture?", "In which part of the image is the metal bottle, the top or the bottom?", "Is the can in the top or in the bottom part of the image?", "Which kind of furniture is wooden?", "Is the white cat on the chair that looks brown and white?", "What type of furniture is the cat on?", "Which kind of furniture is the cat on?", "What animal is in front of the white wall?", "How is the piece of furniture called?", "Which material was used to make the bottle?", "What is the bottle made of?", "Do you see any desk or chair in the picture?", "Are the frame and the bottle made of the same material?"], "visual7w": ["When was the photo taken?", "What type of animal is shown?", "What is the cat on?", "What is the chair made of?", "What color is the cat?", "What color is the wall?", "Where is the cat looking?", "Where was the photo taken?", "Where do you see wood trim?", "When do you think this picture was taken?", "What kind of animal is pictured?", "Where is the cat sitting?", "Why is this cat so small?", "Where is the light coming from?", "Where is the kitten looking?", "What is the chair made of?", "What is the fur like?", "Where is the cat sitting?", "How old is the cat?", "What part of the cat is white?", "What animal is black and white?", "Where is the cat?", "Where is the cat looking?", "Where is the chair?", "What is the cat on?", "What is grey and white?", "What is the cat doing?", "What is coming through the window?", "What is the cat doing?", "What is black and white?", "What is black and white?", "What is black and white?", "What is looking down?", "What is white and clean?", "What has 2 ears?", "What is on the chair?", "What is metal?"], "vqa": ["What type of building is this?", "Where is the cat sitting?", "Is it likely this cat might be pregnant?", "What color is the cat?"], "mscoco2": ["A kitten stands on a chair and looks over the edge. "]}}, {"img_id": "COCO_val2014_000000580418", "labelf": {"vqa": [{"4": 1, "5": 0.3}, {"beige": 0.3, "brown": 0.3, "tan": 0.3, "white": 1}, {"cows": 0.3}]}, "sentf": {"vqa": ["How many cows are there?", "What color are they?", "Why are the cows walking down the road?"], "mscoco2": ["Several cows walking in the street with cars behind them. "]}}, {"img_id": "COCO_val2014_000000511251", "labelf": {"vqa": [{}, {"don't know": 0.6, "no": 1, "yes": 0.9}, {"no": 1, "yes": 0.3}]}, "sentf": {"vqa": ["What initials are on the bag?", "Did someone lose their luggage?", "Is this in the shopping mall?"], "mscoco2": ["Luggage on a tiled ground and people sitting on rows of chairs in the background. "]}}, {"img_id": "COCO_val2014_000000133237", "labelf": {"vqa": [{"20 feet": 0.3, "huge": 0.3, "large": 0.6, "small": 0.6}, {"mother": 0.3, "yes": 1}, {"yes": 1}, {"2": 1}]}, "sentf": {"vqa": ["How big is the elephant?", "Is this a mother and child?", "Are they in their natural environment?", "How many elephants are there?"], "mscoco2": ["a very large elephant that has a small elephant below"]}}, {"img_id": "COCO_val2014_000000210789", "labelf": {"vqa": [{"yes": 1}, {"yes": 1}, {"in front": 0.3}]}, "sentf": {"vqa": ["Is the child happy?", "Is the umbrella big enough for both people?", "Where is the little kid?"], "mscoco2": ["A child and person stand under an umbrella. "]}}, {"img_id": "COCO_val2014_000000514607", "labelf": {"vqa": [{"no": 0.6, "yes": 1}, {"yes": 1}, {"yes": 1}]}, "sentf": {"vqa": ["IS this the beach?", "Is the sun shining?", "Is this low tide?"], "mscoco2": ["A view of the ocean and rocks on a sunny day under an umbrella. ", "a view from under an umbrella of a beach with a rocky  seashore and waves beyond"]}}, {"img_id": "COCO_val2014_000000219909", "labelf": {"vqa": [{"it's raining": 0.3, "rain": 1, "raining": 0.3, "shade": 0.3}, {"blue": 1}, {"yes": 1}]}, "sentf": {"vqa": ["Why are the women using an umbrella?", "What color purse does the blonde lady carry?", "Are the ladies friends?"], "mscoco2": ["Two people with their hands on each others' back walk under the same umbrella on a city sidewalk next to a man."]}}, {"img_id": "COCO_val2014_000000419228", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"no": 1}, {"right": 0.9}, {"concrete": 0.3, "ground": 0.3, "rock": 1, "rocks": 0.3}, {"no": 1, "yes": 1}, {"no": 1, "yes": 0.6}, {"white": 1}]}, "sentf": {"vqa": ["Does the bear have water to play in?", "Is the bear walking on the grass?", "Which of the bear's paws is raised off the ground?", "What does the bear have his front paws on?", "Is the bear wet?", "Has the bear been swimming?", "What color is the bear?"], "mscoco2": ["A polar bear paws over the ground of an enclosure. ", "A polar bear walks over the rocks in his zoo exhibit"]}}, {"img_id": "COCO_val2014_000000295016", "labelf": {"visual7w": [{"One.": 1.0}, {"White.": 1.0}, {"Two.": 1.0}, {"One.": 1.0}, {"Two.": 1.0}, {"In a cup.": 1.0}, {"Blue.": 1.0}, {"Brown.": 1.0}], "vqa": [{"no": 1}, {"looking": 0.3}, {"no": 1}]}, "sentf": {"visual7w": ["How many kittens are in the cup?", "What color is the cup?", "How many eyes does the kitten have?", "How many cups are on the table?", "How many ears are on the kitten's head?", "Where is the kitten sitting?", "What color are the kitten's eyes?", "What color are the stripes on the cup?"], "vqa": ["Has this cat been beheaded?", "What is the cat doing?", "Is the cat mature?"], "mscoco2": ["A small cat head peer out over a teacup, which is stuffed with the cat's body. "]}}, {"img_id": "COCO_val2014_000000230881", "labelf": {"visual7w": [{"Light tan.": 1.0}, {"1 cow.": 1.0}, {"A brick bridge.": 1.0}, {"Near cow.": 1.0}, {"Under the arch.": 1.0}, {"Green.": 1.0}, {"A bull.": 1.0}, {"One.": 1.0}, {"Bricks.": 1.0}, {"A fence.": 1.0}, {"On the arch.": 1.0}, {"Large cow.": 1.0}, {"Brick structure.": 1.0}, {"Plants.": 1.0}, {"Grass.": 1.0}, {"Bull is standing.": 1.0}, {"Green.": 1.0}, {"Stone.": 1.0}, {"Sharp.": 1.0}, {"2.": 1.0}, {"1.": 1.0}, {"1.": 1.0}, {"Behind the adult cow.": 1.0}, {"Black.": 1.0}, {"1.": 1.0}, {"Green.": 1.0}, {"Dirt.": 1.0}], "vqa": [{"no": 1}, {"arch": 0.3, "bridge": 1, "stone": 0.3}, {"1": 0.9, "2": 1}, {"green": 1}]}, "sentf": {"visual7w": ["What color is the cow?", "How many cows are out there?", "What is the cow under?", "Where was the picture taken?", "Where is the bull?", "What color is the grass?", "What is under the arch?", "How many horns are visible?", "What is the arch made of?", "What is behind the bull?", "Where is the green moss?", "What is under structure?", "What is over the cow?", "What is growing on brick structure?", "What is behind large cow?", "How is the bull in photo?", "What color is the grass?", "What is wall made of?", "How does horn feel?", "How many cows in total?", "How many cows are in the shade?", "How many cows are lying down?", "Where is the fence?", "What color is the adult cow's nose?", "How many horns are shown?", "What color is the grass?", "What is the adult cow standing on?"], "vqa": ["Is there a tree in this photo?", "What is the bull under?", "How many animals are in the photo?", "What color is the grass?"], "mscoco2": ["a bull standing under a stone cave by his self ", "A cattle is hiding under a bridge being alone. ", "A bull is under a archway near a dead animal. "]}}, {"img_id": "COCO_val2014_000000459396", "labelf": {"vqa": [{"no": 0.9, "yes": 1}, {"yes": 1}, {"black": 1}, {"2": 0.3, "3": 1}, {"yes": 1}, {"black": 1, "black and brown": 0.3}]}, "sentf": {"vqa": ["Are all the bulls adults?", "Is the black cow looking for food?", "What color is the closest animal?", "How many cows are there?", "Are these animals considered cattle?", "What is the color of the cow?"], "mscoco2": ["A cow is grazing while two cows in the background look on. "]}}, {"img_id": "COCO_val2014_000000401197", "labelf": {"vqa": [{"no": 1}, {"no": 1}, {"tent": 1}, {"6": 0.3, "7": 1}]}, "sentf": {"vqa": ["Is there an umbrella?", "Has this photo recently been taken?", "What is the structure the boys are using called?", "How many boys are in the photo?"], "mscoco2": ["A woman standing over a group of young boys outside a tent on a yard."]}}, {"img_id": "COCO_val2014_000000274126", "labelf": {"gqa": [{"yes": 1.0}, {"shore": 1.0}, {"shore": 1.0}, {"yes": 1.0}], "visual7w": [{"5.": 1.0}], "vqa": [{"ferry": 0.9, "people": 0.3}, {"no": 1, "yes": 1}, {"15 feet": 0.3, "2 feet": 0.3, "deep": 0.6, "very": 1, "very deep": 0.3}, {"yes": 1}, {"no": 1, "yes": 0.6}, {"4": 0.6, "5": 1, "7": 0.9, "8": 0.3}, {"black": 0.6, "green": 1}, {"yes": 1}, {"boat": 1, "ferry": 0.3}, {"0": 0.6, "1": 0.9, "15": 0.3, "4": 0.3, "50": 0.3, "60": 0.3, "many": 0.3}, {"no": 1, "yes": 0.9}]}, "sentf": {"gqa": ["Is it outdoors?", "Which place is it?", "Which place could this be?", "Do you see a boat on the shore?"], "visual7w": ["How many boats are there?"], "vqa": ["What type of boat is this?", "Is one of the houseboats a business?", "How deep is the water?", "Are there clouds in the sky?", "Does this bridge resemble an aqueduct?", "How many boats do you see?", "What color is the bridge?", "Does this look safe?", "What type of big vehicle is shown in this picture?", "How many trellises are there?", "Is the bridge new?"], "mscoco2": ["A picture of house boats and a long bridge over water on a cloudy day. "]}}, {"img_id": "COCO_val2014_000000135281", "labelf": {"vqa": [{"yes": 1}, {"building": 1, "cars": 0.3, "store": 0.3, "street": 0.3}, {"2": 1}]}, "sentf": {"vqa": ["Is it raining?", "What are the women walking beside?", "How many people are under the umbrella?"], "mscoco2": ["Two people walking down a street in the rain under a umbrella. "]}}, {"img_id": "COCO_val2014_000000083113", "labelf": {"vqa": [{"2": 1}, {"yes": 1}, {"2": 1}, {"no": 1, "yes": 0.9}]}, "sentf": {"vqa": ["How many elephants are in the picture?", "Do either of the elephants have tusk?", "How many animals are seen?", "Are these elephants wild?"], "mscoco2": ["Elephants with large tusks, standing around behind a fence. "]}}, {"img_id": "COCO_val2014_000000573935", "labelf": {"vqa": [{"black": 1}, {"box": 1}, {"donut": 1}]}, "sentf": {"vqa": ["What color is the dog?", "What is on the floor near the dog?", "What is on the dog's tail?"], "mscoco2": ["a  black dog with a donut behind at the tail"]}}, {"img_id": "COCO_val2014_000000526728", "labelf": {"vqa": [{"yes": 1}, {"can't see": 0.3}, {"luggage": 1, "suitcase": 0.3, "suitcases": 0.6}]}, "sentf": {"vqa": ["Are these people happy?", "What does the sign say?", "What is in front of the people?"], "mscoco2": ["Two people smile while posing behind luggage suitcases on the sidewalk. "]}}, {"img_id": "COCO_val2014_000000419386", "labelf": {"vqa": [{"blue": 1, "teal": 0.3}, {"green": 1}, {"cow": 0.3, "left": 0.3, "right": 1}]}, "sentf": {"vqa": ["What color is the child's sweater?", "What color is the gate?", "Which ear has a yellow tag?"], "mscoco2": ["Children are petting cows that are behind a gate. "]}}, {"img_id": "COCO_val2014_000000170700", "labelf": {"visual7w": [{"Two.": 1.0}, {"Daytime.": 1.0}, {"Blue.": 1.0}, {"No one.": 1.0}, {"Red.": 1.0}, {"Orange.": 1.0}, {"Green.": 1.0}, {"At a cafe.": 1.0}, {"Umbrellas.": 1.0}, {"Stone.": 1.0}, {"Flowers.": 1.0}, {"Sidewalk.": 1.0}, {"Across from the building.": 1.0}, {"Over the umbrellas.": 1.0}, {"Tables.": 1.0}, {"Brick.": 1.0}, {"On the patio.": 1.0}, {"In front of the building.": 1.0}, {"Plants.": 1.0}, {"Metal.": 1.0}, {"Leaning on the fence.": 1.0}, {"To protect from the weather.": 1.0}, {"Asphalt.": 1.0}, {"Plants.": 1.0}], "vqa": [{"yes": 1}, {"blue": 1}, {"nothing": 1, "pole": 1, "shirt": 0.3}, {"2": 1}, {"2": 1}, {"grass": 0.3, "no": 1, "yes": 0.6}, {"orange": 1}, {"green": 0.6, "multicolored": 0.3, "red": 1}, {"no": 1}, {"no": 1, "yes": 0.3}, {"no": 1}]}, "sentf": {"visual7w": ["How many umbrellas are visible?", "When was this photo taken?", "What color are the two umbrellas?", "Who is on top of the building?", "What color is the car on the right behind the flowers?", "What color are the flowers on the bottom left?", "What color are the trees?", "Where was this photo taken?", "What is under the second floor?", "What is the building on the left made of?", "What is in the foreground, in front of the car?", "What are the people standing on?", "Where is the red car?", "Where is the blue railing?", "What are the umbrellas attached to?", "What is the building made of?", "Where are the blue umbrellas?", "Where is the red car parked?", "What is used to decorate the outdoor balcony?", "What are the outdoor chairs made of?", "What is the man in blue doing?", "What are the umbrellas for?", "What material is the road made of?", "What is in front of the red car that is driving?"], "vqa": ["Is there a balcony?", "What is the color of the umbrellas?", "What is hanging from the umbrella?", "How many umbrellas?", "How many umbrellas are open?", "Is there anything hanging out of the windows?", "What color are the flowers to the left?", "What is the color of the plants?", "Is there a dome at the top of the building?", "Are there lots of green umbrellas?", "Is this a park?"], "mscoco2": ["a couple of blue umbrellas that are over some people"]}}, {"img_id": "COCO_val2014_000000234349", "labelf": {"vqa": [{"no": 1}, {"no": 1, "yes": 0.3}, {"no": 1, "yes": 1}]}, "sentf": {"vqa": ["Is it a rainy day?", "Are these jellyfish the women are holding?", "Are those women celebrating something?"], "mscoco2": ["some people sanding under some clear umbrellas "]}}, {"img_id": "COCO_val2014_000000265125", "labelf": {"visual7w": [{"Rain.": 1.0}, {"A woman.": 1.0}, {"Trunk.": 1.0}, {"Behind the car.": 1.0}, {"A coat.": 1.0}, {"Right.": 1.0}, {"In her hair.": 1.0}], "vqa": [{"umbrella": 1}, {"in car": 0.3, "outside": 0.3, "trunk": 1}, {"black": 1, "green": 0.6}, {"green": 0.3, "pole": 0.3, "round": 0.3, "straight": 0.9}]}, "sentf": {"visual7w": ["Why is the woman holding an umbrella?", "Who is holding an umbrella?", "What part of the car is open?", "Where is the woman?", "What is the woman wearing?", "What hand is the woman holding the umbrella?", "Where is the barrette?"], "vqa": ["What is the woman holding?", "Where is the woman putting her umbrella?", "What color is the umbrella?", "What shape is the umbrella's handle?"], "mscoco2": ["A woman holding a black umbrella as she stands behind a car."]}}, {"img_id": "COCO_val2014_000000406899", "labelf": {"gqa": [{"yes": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"no": 1.0}, {"cap": 1.0}, {"left": 1.0}, {"left": 1.0}, {"lady": 1.0}, {"bottom": 1.0}, {"yes": 1.0}, {"bottom": 1.0}, {"orange": 1.0}, {"bottom": 1.0}, {"blue": 1.0}, {"left": 1.0}, {"bucket": 1.0}, {"sand": 1.0}, {"lady": 1.0}, {"lady": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"people": 1.0}, {"cap": 1.0}, {"yes": 1.0}, {"green": 1.0}, {"yes": 1.0}, {"blanket": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}], "visual7w": [{"3.": 1.0}, {"Green and blue.": 1.0}, {"On the sand.": 1.0}, {"Hat.": 1.0}, {"Beach.": 1.0}, {"Sand.": 1.0}, {"Blue.": 1.0}, {"Daytime.": 1.0}], "vqa": [{"beach": 0.3, "blankets": 0.6, "sand": 0.6, "towel": 0.3, "towels": 1}, {"no": 1, "yes": 0.3}, {"blue and green": 0.6, "green": 0.3, "green and blue": 0.9}, {"beach": 1, "in front": 0.3, "on beach": 0.3}, {"3": 1, "5": 0.9, "6": 0.3, "8": 0.3}]}, "sentf": {"gqa": ["Is there an umbrella or a kite in the photograph?", "Is there any blanket in the picture?", "Is the green umbrella to the left or to the right of the lady?", "Is the person to the left of the person wearing a bikini?", "What is the lady wearing?", "Is the orange umbrella to the right or to the left of the people on the beach?", "Is the lady to the right or to the left of the towel?", "Who is older, the lady or the child?", "In which part of the picture is the black bag, the top or the bottom?", "Is the bucket in the bottom of the photo?", "In which part of the photo is the orange bag, the top or the bottom?", "What color do you think is the bag to the right of the other bag?", "Where are the toys, in the top or in the bottom part of the photo?", "What color is the beach chair?", "On which side is the lady?", "What is lying on the sand?", "The bucket to the right of the toys is lying on what?", "Who is wearing a cap?", "Who is wearing the cap?", "Is the beach chair on the right side of the image?", "Is the bucket to the right of the toys round and green?", "Are there any toys on the beach?", "Who is sitting on the blanket?", "What is the person to the left of the kid wearing?", "Is it an outdoors scene?", "The bucket is which color?", "Are there either any orange chairs or bags?", "What are the people that are to the right of the umbrella sitting on?", "Are the people to the right of the umbrella sitting on a bench?", "Are there any rackets or umbrellas that are orange?", "Are both the beach chair and the shirt the same color?"], "visual7w": ["How many umbrellas are there?", "What color is the umbrellas closest to the camera?", "Where are the sand toys?", "What does the woman on the left have on her head?", "Where was this taken?", "What is on the ground?", "What color is the sky?", "When was this taken?"], "vqa": ["What are the people sitting on?", "Are there any purple sand toys?", "What color is the umbrella?", "Where are people under the umbrellas?", "How many umbrellas are shown?"], "mscoco2": ["A group of people on a beach under umbrellas\n", "A group of people sitting on towels and under umbrellas at a beach."]}}, {"img_id": "COCO_val2014_000000391642", "labelf": {"vqa": [{"playing": 1, "yes": 0.6}, {"no": 1}, {"yes": 1}, {"blue": 1, "blue and white": 0.3}, {"blue": 1}, {"no": 1}]}, "sentf": {"vqa": ["Is the baby using or playing with the umbrella?", "Are there any leaves in the picture?", "Does the baby have socks on?", "What color is the girl's umbrella?", "What color is the umbrella?", "Is there a hole in the umbrella?"], "mscoco2": ["A young boy that is sitting under a blue umbrella. "]}}, {"img_id": "COCO_val2014_000000295478", "labelf": {"gqa": [{"yes": 1.0}, {"yes": 1.0}, {"headphones": 1.0}, {"yes": 1.0}, {"white": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"woman": 1.0}, {"no": 1.0}, {"headphones": 1.0}, {"no": 1.0}, {"left": 1.0}, {"wall": 1.0}, {"dark": 1.0}], "visual7w": [{"1.": 1.0}, {"A dog.": 1.0}, {"White.": 1.0}, {"Tattoos.": 1.0}, {"Yellow.": 1.0}, {"Headphones.": 1.0}, {"1.": 1.0}], "vqa": [{"brick": 1, "bricks": 0.9, "concrete": 0.3}, {"jeans": 0.6, "nothing": 0.3, "pants": 0.9, "shoes": 0.3, "socks": 0.3}, {"bag": 0.3, "bracelet": 0.3, "tattoo": 1, "tattoos": 0.9, "wristband": 0.3}, {"denim": 0.3, "jeans": 1}]}, "sentf": {"gqa": ["Does the dog to the left of her have small size and white color?", "Is the dog small?", "What device is the woman wearing?", "Do you see any headphones that are white?", "What is the color of the device the woman is wearing?", "Is the necklace silver?", "Is the dog different in color than the shoe?", "Who is wearing a shoe?", "Are there both women and drivers in the image?", "What device is the person in front of the wall wearing, Xbox controllers or headphones?", "Is the small dog on the right?", "Is the white animal to the left or to the right of the woman?", "What's the woman in front of?", "Is the door dark or white?"], "visual7w": ["How many dogs are shown?", "What animals is depicted?", "What color is the dog?", "What is on the woman's arm?", "What is the color of the woman's shoes?", "What is the woman wearing in her ears?", "How many woman are pictured?"], "vqa": ["What is the wall behind the woman made of?", "What is this woman wearing around her ankle?", "What is on the woman's arm?", "What type of pants is the girl wearing?"], "mscoco2": ["A woman is walking with a dog trailing behind her on a leash. ", "Woman walking a small white dog behind her. "]}}, {"img_id": "COCO_val2014_000000452300", "labelf": {"vqa": [{"golden retriever": 0.3, "pitbull": 0.3, "schnauzer": 0.3, "terrier": 0.3}, {"no": 1}, {"chair": 1}]}, "sentf": {"vqa": ["What kind of dog is in the picture?", "Is the dog laying directly on the floor?", "What piece of furniture is the dog under?"], "mscoco2": ["a close up of a dog sleeping under a chair ", "a dog that is laying under a chair"]}}, {"img_id": "COCO_val2014_000000277812", "labelf": {"vqa": [{"orange": 0.6, "pink": 1, "red": 0.6, "salmon": 0.3, "white": 0.3}, {"scarf": 0.3, "umbrella": 1}, {"yes": 1}, {"no": 1}]}, "sentf": {"vqa": ["What color is this ladies nail polish?", "What is covering the girls heads?", "Do any of these girls have a scarf on?", "Do these two women look like sisters?"], "mscoco2": ["a couple of girls that are under a umbrella"]}}, {"img_id": "COCO_val2014_000000575931", "labelf": {"visual7w": [{"Black.": 1.0}, {"One.": 1.0}, {"Rainy.": 1.0}, {"Under the umbrella.": 1.0}, {"White.": 1.0}, {"It's raining.": 1.0}, {"A man.": 1.0}, {"An umbrella.": 1.0}, {"City street.": 1.0}, {"Rainy.": 1.0}, {"A child.": 1.0}, {"A umbrella.": 1.0}, {"Spider-man.": 1.0}, {"Black.": 1.0}, {"Blue and red.": 1.0}, {"Black.": 1.0}, {"Baby boy.": 1.0}, {"It's raining.": 1.0}, {"A sign.": 1.0}, {"It is raining.": 1.0}, {"A bag.": 1.0}, {"A child.": 1.0}, {"An umbrella.": 1.0}, {"Rain boots.": 1.0}, {"A gray t shirt.": 1.0}, {"Trees.": 1.0}, {"Shorts.": 1.0}, {"The sign says walk.": 1.0}, {"A red hood and blue shirt.": 1.0}, {"Khaki shorts.": 1.0}, {"Rain boots.": 1.0}, {"An umbrella.": 1.0}, {"Painted white lines.": 1.0}, {"Cargo shorts.": 1.0}, {"Trees alongside the building.": 1.0}, {"A crosswalk light.": 1.0}, {"It is raining.": 1.0}, {"A bag.": 1.0}], "vqa": [{"yes": 1}, {"1": 1}, {"yes": 1}, {"behind": 0.3, "boots": 0.6, "boy": 0.3, "shoes": 0.6}]}, "sentf": {"visual7w": ["What color is the umbrella?", "How many people are walking in the photo?", "What is the weather like?", "Where is the child's head?", "What color are the lines in the road?", "Why is the child wearing galoshes?", "Who is carrying the child?", "What is protecting the people from the rain?", "Where is the photo taken?", "How is the weather?", "What is man holding?", "What is in man's hand?", "What character is on boys boots?", "What is the umbrella color?", "What is the boots color?", "What is the bag color?", "What does man have on his back?", "What is the weather outside?", "What is in front of the man?", "What is the weather like outside?", "What is the man carrying?", "What is on the back of the man?", "What is the man holding?", "What is on the feet of the child?", "What is the man wearing?", "What is on the sidewalk?", "What is the man wearing?", "What does the crosswalk sign indicate?", "What is the child wearing?", "What is the child wearing?", "What is the child wearing?", "What is the man holding?", "What is on the road?", "What is the boy wearing?", "What is in the background?", "What is in the frame?", "What type of weather is there?", "What is the man carrying?"], "vqa": ["Is it raining?", "How many kids are there?", "Is his kid wearing rain boots?", "Where is spiderman?"], "mscoco2": ["a child clings to his fathers back under an umbrella in a rain storm ", "A man crosses a street under an umbrella and carrying a little boy. "]}}, {"img_id": "COCO_val2014_000000061531", "labelf": {"vqa": [{"bridge": 0.3, "hill": 0.3, "ramp": 1}, {"no": 1, "yes": 1}, {"yes": 1}]}, "sentf": {"vqa": ["What is the object the skier is sliding over?", "Is there a red fence at the back?", "Is there snow on the ground?"], "mscoco2": ["A man skis over a plastic contraption on a ski slope. "]}}, {"img_id": "COCO_val2014_000000411871", "labelf": {"vqa": [{"1": 1}, {"bacon": 0.3, "carrot": 0.9, "chinese": 0.3, "lobster": 0.3, "salad": 0.3}, {"carrots": 0.3, "placemat": 0.3, "table": 1}, {"no": 1}, {"1": 0.6, "2": 1, "fork": 0.9, "fork and knife": 0.3}]}, "sentf": {"vqa": ["How many forks?", "What  food is that?", "What is the plate on?", "Is the plate covered in lot's of foods?", "How many utensil do you see on this plate?"], "mscoco2": ["A fork lying on a mostly empty plates with some shrimp shells left behind and a single pepper strip"]}}, {"img_id": "COCO_val2014_000000308026", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"beanie": 0.6, "cap": 0.3, "hair": 0.3, "hat": 1, "helmet": 0.3, "nothing": 0.3}, {"no": 1}, {"no": 0.9, "yes": 1}, {"chicago": 0.3, "new york": 1, "not sure": 0.3, "unknown": 0.3}, {"yes": 1}, {"yes": 1}, {"no": 1}, {"0": 1, "1": 0.3}]}, "sentf": {"vqa": ["Does the gentlemen in the white shirt be sweating?", "What does the man have on his head?", "Is this a church?", "Was this photo taken at night?", "What major city is this?", "Is there a boy in the picture?", "Is he being filmed?", "Is it cloudy?", "How many vehicles?"], "mscoco2": ["three buildings in the background and a skateboarder doing a trick"]}}, {"img_id": "COCO_val2014_000000277761", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"helmet": 1}, {"black": 0.6, "orange": 0.9, "red": 1, "white": 0.3}, {"base": 0.3, "field": 0.3, "first base": 1, "yes": 0.3}]}, "sentf": {"vqa": ["Will this be a fielder hit?", "What kind of protective gear is the batter wearing?", "What color is the trim on the catcher's uniform?", "Where does this man have to run if he hits the ball?"], "mscoco2": ["An umpire behind a batter hitting a ball at a baseball game. "]}}, {"img_id": "COCO_val2014_000000125100", "labelf": {"vqa": [{"outside": 1, "to right": 0.3, "window": 0.3}, {"chihuahua": 0.3, "collie": 0.3, "corgi": 0.3, "dachshund": 0.3, "girl": 0.3, "pomeranian": 0.9, "schnauzer": 0.3}, {"couch": 1, "sofa": 0.3}, {"no": 0.9, "yes": 1}]}, "sentf": {"vqa": ["Where is the reclining dog looking?", "What breed of dog is the tan puppy?", "What kind of furniture is the dog sitting on?", "Does the mounted board on the left serve a primarily esthetic function?"], "mscoco2": ["A dog coming out from behind a curtain while another lays on top of a couch. "]}}, {"img_id": "COCO_val2014_000000374266", "labelf": {"gqa": [{"horse": 1.0}, {"short": 1.0}], "visual7w": [{"A fence.": 1.0}, {"In a pen.": 1.0}, {"A mane.": 1.0}, {"The fence post.": 1.0}, {"Daytime.": 1.0}, {"Brown.": 1.0}, {"Green.": 1.0}], "vqa": [{"horse": 1}, {"10 feet": 0.3, "12 feet": 0.3, "3 feet": 0.3, "6 feet": 0.6, "tall": 0.6}, {"brown": 1, "tan": 0.3}]}, "sentf": {"gqa": ["What kind of animal is it?", "Is the grass short or tall?"], "visual7w": ["What is the in front of the horse?", "Where is the horse?", "What is on the horse's neck?", "What holds up the fence?", "When is the picture taken?", "What color is the horse?", "What color is the grass?"], "vqa": ["What animal is this?", "How tall is the fence?", "What color is the animal?"], "mscoco2": ["A horse behind a fence eating some grass. "]}}, {"img_id": "COCO_val2014_000000274091", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"horse": 1.0}, {"yes": 1.0}, {"horse": 1.0}, {"no": 1.0}, {"metal": 1.0}], "visual7w": [{"One.": 1.0}, {"Black.": 1.0}, {"Blue.": 1.0}, {"Inside of a building.": 1.0}, {"Clock.": 1.0}, {"British flags.": 1.0}, {"That is a British flag.": 1.0}, {"A clock.": 1.0}, {"An iron horse.": 1.0}, {"Black shirts.": 1.0}, {"Summer.": 1.0}, {"Zander anes.": 1.0}, {"United Kingdom.": 1.0}, {"Attached to the wall.": 1.0}, {"The ceiling is made of glass.": 1.0}, {"Shadow from the ceiling.": 1.0}, {"Blinders.": 1.0}, {"10:05.": 1.0}, {"1849.": 1.0}, {"Bricks.": 1.0}, {"Traffic light.": 1.0}], "vqa": [{"10:05": 1, "4:55": 0.3}, {"yes": 1}, {"no": 1, "yes": 0.9}]}, "sentf": {"gqa": ["Do you see either any armors or tennis balls?", "Is the fence to the left of a flag?", "What animal is made of metal?", "Are there both a fence and a horse in the picture?", "What animal is below the orange wall?", "Is there a sheep or a horse that is made of plastic?", "What is the horse made of?"], "visual7w": ["How many clocks are hanging in this picture?", "What color is the horse statue?", "What color is the sky?", "Where is this picture taken?", "What is hanging above alley?", "What is under the clock?", "What kind of flag is that?", "What kind of timepiece is that?", "What kind of a horse is that?", "What kind of shirts are those?", "What season is this?", "Who owns the rights?", "What flag is displayed on the banner?", "Where is the clock?", "How can you see the sky?", "What is the dark line on the brown wall?", "What is on the side of the horse statue's eyes?", "What is the time on the clock?", "What is the number on the black iron bar to the clock?", "What material is the wall on the left made of?", "What are the lights behind the horse's head?"], "vqa": ["What time does the clock say?", "Are these British flags?", "Is this photo taken inside?"], "mscoco2": ["A clock town looms above Union Jack flags in an alleyway. "]}}, {"img_id": "COCO_val2014_000000133042", "labelf": {"gqa": [{"yes": 1.0}, {"no": 1.0}, {"gray": 1.0}, {"left": 1.0}, {"right": 1.0}, {"boy": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"black": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"orange": 1.0}, {"left": 1.0}, {"large": 1.0}, {"no": 1.0}, {"large": 1.0}, {"yes": 1.0}, {"black": 1.0}], "visual7w": [{"Baseball.": 1.0}, {"Boys.": 1.0}, {"Two.": 1.0}, {"Baseball field.": 1.0}, {"Blue.": 1.0}, {"Four.": 1.0}, {"Black.": 1.0}, {"One.": 1.0}, {"Jersey.": 1.0}, {"3.": 1.0}, {"Chain link.": 1.0}, {"Baseball.": 1.0}, {"Baseball bat.": 1.0}, {"Field.": 1.0}, {"Mound.": 1.0}, {"Baseball.": 1.0}, {"Field.": 1.0}, {"3.": 1.0}, {"Fresh cut.": 1.0}, {"Fence.": 1.0}, {"Over the fence.": 1.0}], "vqa": [{"3": 1, "5": 0.9}, {"no": 1}, {"no": 1, "yes": 1}, {"white": 1}, {"5": 1}, {"no": 0.3, "yes": 1}, {"blue": 1, "blue and black": 0.3}, {"field": 0.6, "home": 0.3, "mound": 0.3}, {"pitcher": 0.3, "pitching": 0.6}, {"left": 1, "right": 0.9}, {"yes": 1}, {"pirates": 1}, {"catcher": 0.3, "kid": 0.3, "pitcher": 1}]}, "sentf": {"gqa": ["Is the uniform the same color as the jersey?", "Does the garbage can to the right of the people look small and blue?", "What color do the trousers of the boy have?", "Is the boy on the right or on the left of the photo?", "Which side of the photo is the black helmet on?", "Who is standing?", "Are there any people to the right of the helmet?", "Is the garbage bin to the right of the people that are to the right of the boy?", "What color is the shirt?", "Is there any helmet in the picture that is not black?", "Does the person to the left of the ball appear to be standing?", "Is the helmet to the right of the talking people that are to the right of the boy?", "What color is the belt?", "Is the boy to the left or to the right of the people that are talking?", "How big is the garbage bin to the right of the people?", "Is there a fence that is orange?", "What size is the dirt?", "Is the helmet the same color as the shirt?", "The hat has what color?"], "visual7w": ["What sport is being played?", "Who is playing the sport?", "How many boys on the field?", "Where is the sport being played?", "What color is the #3 shirt?", "How many people behind the fence?", "What color is the #5 shirt?", "How many mitts in the photo?", "What is the boy wearing?", "What number is on the boy's jersey?", "What is the fence made of?", "What sport is being played?", "What is the boy holding?", "Where is the game being played?", "Where is the pitcher standing?", "What sport is being played?", "Where are the players?", "What number is on the shirt?", "What is the grass's condition?", "What surrounds the field?", "Where are people watching the game?"], "vqa": ["What is the player's number?", "Is this a professional game?", "Does this seem to be an interesting game?", "What color is the ball?", "What is the pitchers number?", "Is this boy a good pitcher?", "What color are these guys shirts?", "Where is the man in blue and white uniform?", "Why are the players legs so far apart?", "Is the pitcher right or left handed?", "Is the pitcher wearing socks?", "What team does he play for?", "Who is the man in the black shirt?"], "mscoco2": ["some baseball players are playing baseball and people in the background"]}}, {"img_id": "COCO_val2014_000000448779", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"horse": 1.0}, {"horse": 1.0}, {"horses": 1.0}, {"horses": 1.0}, {"horses": 1.0}, {"yes": 1.0}, {"horses": 1.0}, {"horses": 1.0}, {"horses": 1.0}, {"horses": 1.0}, {"horses": 1.0}, {"white": 1.0}, {"horse": 1.0}, {"horse": 1.0}, {"right": 1.0}, {"horses": 1.0}, {"no": 1.0}], "visual7w": [{"The cowboy.": 1.0}, {"10.": 1.0}, {"In the field.": 1.0}, {"Brown and white.": 1.0}, {"Rounding up the horses.": 1.0}, {"Grass.": 1.0}, {"A horse.": 1.0}, {"Running.": 1.0}, {"A horse.": 1.0}, {"Running.": 1.0}, {"Horses.": 1.0}, {"Trees.": 1.0}, {"Running.": 1.0}, {"Horse.": 1.0}, {"A man.": 1.0}, {"Riding a horse.": 1.0}, {"Grass.": 1.0}, {"Field.": 1.0}, {"Running.": 1.0}, {"9.": 1.0}, {"Leaves.": 1.0}, {"Horses.": 1.0}, {"Horses.": 1.0}, {"Horses.": 1.0}], "vqa": [{"10": 0.9, "8": 0.3, "9": 1}, {"no": 1}, {"1": 1, "2": 0.6}, {"10": 0.6, "11": 0.3, "25": 0.3, "8": 0.6, "9": 0.9}]}, "sentf": {"gqa": ["Do the trees look brown?", "Is there a horse in the image?", "Are there both a duck and horse in this picture?", "What kind of animal is tan?", "What animal is the man on?", "Which kind of animal is in the field?", "What animals is that man leading, goats or horses?", "What animal is the man leading?", "Are there any horses in the field?", "What animal is running on the grass?", "What animals are running on the grass?", "What do you think are the animals that are running on the grass that is on the ground?", "What kind of animal is on the grass?", "What kind of animal is on the green grass which is on the ground?", "Which color does the shirt have?", "What is the name of the tan animal?", "What is the animal to the left of the person on the right side of the image?", "Is the man on the right side or on the left of the photo?", "What are the animals in the field?", "Is there a cow or a panda bear in the image?"], "visual7w": ["Who is getting the horses?", "How many horses are there?", "Where are the horses?", "What colors are the horses?", "What is the man doing?", "What is on the ground?", "What animal is shown?", "What are the animals doing?", "What animal is displayed?", "What are the horses doing?", "What animals are shown?", "What items are green and leaves?", "What are the horses doing?", "What animal is shown?", "Who is on the horse?", "What is in the man doing?", "What are the horses running on?", "Where are the horses?", "What are the horses doing?", "What number of horses are running?", "What do the trees have?", "Who is running in the field?", "Who is kicking up dust?", "Who is all running?"], "vqa": ["How many horses are in the picture?", "Are these animals standing still?", "How many men are in the picture?", "How many horses?"], "mscoco2": ["A herd of horses running in line behind a horse mounted with a man. "]}}, {"img_id": "COCO_val2014_000000400886", "labelf": {"gqa": [{"skier": 1.0}, {"skier": 1.0}, {"skier": 1.0}, {"skier": 1.0}, {"skier": 1.0}, {"mountain": 1.0}, {"no": 1.0}, {"skier": 1.0}, {"no": 1.0}, {"mountain": 1.0}, {"gray": 1.0}, {"no": 1.0}, {"backpack": 1.0}, {"skier": 1.0}, {"skier": 1.0}, {"skier": 1.0}, {"backpack": 1.0}], "visual7w": [{"Sun.": 1.0}, {"Grey.": 1.0}, {"White.": 1.0}, {"1.": 1.0}, {"Snow.": 1.0}, {"Skating.": 1.0}, {"Sunrise.": 1.0}, {"On a mountain.": 1.0}, {"In the mountains.": 1.0}, {"In mid air.": 1.0}, {"The skier.": 1.0}, {"To the skier's left.": 1.0}, {"Backpack.": 1.0}, {"Backpack.": 1.0}, {"Hill.": 1.0}, {"Hill.": 1.0}, {"Overhead.": 1.0}, {"Rock.": 1.0}, {"Jumping.": 1.0}, {"Sky.": 1.0}, {"Mountain.": 1.0}, {"Skis.": 1.0}, {"Snow.": 1.0}, {"Shadow.": 1.0}, {"Smaller mountains.": 1.0}, {"Backpack.": 1.0}, {"Sun.": 1.0}, {"Ski poles.": 1.0}, {"Sun.": 1.0}, {"Sky.": 1.0}, {"Winter.": 1.0}, {"Skiing.": 1.0}, {"A backpack.": 1.0}, {"Skis.": 1.0}, {"Ski poles.": 1.0}, {"A helmet.": 1.0}, {"The sun and clouds.": 1.0}, {"On a mountain.": 1.0}, {"On the person's feet.": 1.0}, {"Cold.": 1.0}, {"Skiing.": 1.0}], "vqa": [{"no": 0.6, "yes": 1}, {"yes": 1}, {"afternoon": 0.9, "dusk": 0.3, "evening": 0.9, "noon": 0.3, "sunset": 0.6}, {"skiing": 1}]}, "sentf": {"gqa": ["Who is wearing a ski?", "Who do you think is wearing a helmet?", "Who is skiing?", "Who is wearing the helmet?", "Who is jumping?", "What is in front of the skier?", "Do you see goggles in this photo?", "Who is wearing the ski?", "Is the skier that is jumping wearing a jacket?", "What is covered in snow?", "What is the color of the sky?", "Is the person behind the mountain wearing a jacket?", "What is the person behind the mountain carrying?", "Who is carrying the backpack?", "Who is wearing pants?", "Who is wearing the pants?", "Which kind of bag is to the right of the helmet?"], "visual7w": ["What is seen in the sky?", "What is the color of the sky?", "What is the color of the floor?", "How many people are there?", "What is in the ground?", "What is the man doing?", "When is the picture taken?", "Where is the picture taken?", "Where was the picture taken?", "Where is the skier?", "Who is wearing a backpack?", "Where is the skier's shadow?", "What is the skier wearing?", "What is the skier wearing?", "Where is the man skiing?", "Where is the man skiing?", "Where is the sun?", "Where is the shadow?", "What is the person doing?", "Where are the clouds?", "What is the person going down off?", "What is attached to the person's feet?", "What is covering the mountain?", "What is on the snow?", "What is under the mountain?", "What is on the person's back?", "What is shining on the person?", "What is in the person's hands?", "What makes the person's shadow?", "Where are the clouds?", "What time of year is it?", "What is the person doing?", "What is on the person's back?", "What is on the person's feet?", "What is the person holding?", "What is on the person's head?", "What is in the sky?", "Where is the skier?", "Where are the skis?", "What is the weather like?", "What is the person doing?"], "vqa": ["Is this person a professional skier?", "Is he going down  a mountain?", "What time of day is this?", "What is the person doing?"], "mscoco2": ["A person riding downhill on skis on a snowy hill, with large mountains in the background. "]}}, {"img_id": "COCO_val2014_000000155007", "labelf": {"vqa": [{"brown": 0.3, "brown and white": 0.3, "orange": 1, "orange and yellow": 0.3, "yellow": 0.6}, {"helmet": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What color is the skateboard?", "What does the man have on his head?", "Does this shot look as it was seen through a flashlight?"], "mscoco2": ["A man is jumping high on a skate board over a ramp "]}}, {"img_id": "COCO_val2014_000000270852", "labelf": {"vqa": [{"no": 0.3, "yes": 1}, {"man": 0.3, "ski pole": 0.6, "ski poles": 1, "skis": 0.3, "woman": 0.3}, {"yes": 1}, {"america": 0.6, "brazil": 0.3, "germany": 0.3, "russia": 0.3, "usa": 0.6}, {"no": 1, "yes": 0.6}]}, "sentf": {"vqa": ["Are these happy skiers?", "What is the woman holding?", "Are the man and the woman a couple?", "What country is the man's helmet designed to represent?", "Are they both wearing safety goggles?"], "mscoco2": ["two people posing for a photo with young people in the background wearing skis"]}}, {"img_id": "COCO_val2014_000000189368", "labelf": {"vqa": [{"cloudy": 1, "cold": 0.3, "snow": 0.9, "winter": 0.6}, {"backpack": 0.3, "poles": 0.3, "ski pole": 0.6, "ski poles": 0.9}, {"man": 0.3, "no": 1, "yes": 1}, {"backpack": 0.9, "bag": 1, "ski poles": 0.3, "skis": 0.3, "sled": 0.3}, {"sky": 0.3}, {"behind clouds": 1, "sky": 0.3, "up": 0.3}, {"bag": 0.3, "sled": 1}, {"no": 1}, {"cirrus": 0.6, "cumulus": 1, "fluffy": 0.3, "snow": 0.3, "white": 0.3}, {"no": 1}, {"no": 1}, {"no": 1}, {"no": 1}, {"2 feet": 0.3, "3 inches": 0.3, "6 inches": 0.3, "deep": 0.6, "very": 0.3, "very deep": 0.3}, {"snow": 1}, {"skis": 0.3, "snow": 1}, {"cloudy": 0.6, "cold": 0.6, "overcast": 0.3, "snow": 0.6, "sunny": 0.3, "winter": 0.3}]}, "sentf": {"vqa": ["What weather conditions appear in this scene?", "What is the man holding?", "Is there any signs of life here?", "What is the man carrying?", "What three things in the picture are blue?", "Where is the sun?", "What is the man dragging?", "Is it hot here during the day?", "What type of clouds are in the photo?", "Is the man going surfing?", "Is this what one means when one says \"he was so fast he was a blur?\"?", "Was the photo taken at night?", "Is this a sunny day?", "How deep is the snow?", "What is covering the ground?", "What is the man walking on?", "What is the weather?"], "mscoco2": ["A lone skier makes his way across the snow as he drags a backpack behind him. "]}}, {"img_id": "COCO_val2014_000000453321", "labelf": {"vqa": [{"zoo": 1}, {"black": 0.9, "black and white": 1}, {"no": 1}, {"1": 1}]}, "sentf": {"vqa": ["Where does the animal currently live?", "What color are the animal's stripes?", "Do you see the face?", "How many zebras are seen?"], "mscoco2": ["A zebra stands with its behind to a camera, looking towards a fence. "]}}, {"img_id": "COCO_val2014_000000084825", "labelf": {"visual7w": [{"Two Skies.": 1.0}, {"Some sort of Skiing.": 1.0}, {"Is says Dynastar.": 1.0}, {"It is blue.": 1.0}, {"On the ground.": 1.0}, {"During the winter.": 1.0}, {"Brown and white.": 1.0}, {"Skiing.": 1.0}, {"Blue and white.": 1.0}, {"Dynastar.": 1.0}, {"Burgundy and light blue.": 1.0}, {"Black.": 1.0}, {"Green.": 1.0}, {"Orange and red.": 1.0}, {"Winter.": 1.0}, {"Jumping in the air.": 1.0}], "vqa": [{"clear": 0.3, "cloudy": 0.6, "sunny": 1}, {"yes": 1}, {"ski": 0.3, "ski boots": 0.3, "skis": 1}]}, "sentf": {"visual7w": ["How many skies is he/she wearing?", "What is this person doing?", "What do the skis say on them?", "What is the color of the sky?", "Where is this skier doing to land?", "When is a good time to Ski?", "What color is the skier shirt?", "What is the person currently doing?", "How is the sky colored?", "What does the logo say on the back of the ski?", "How is the person outfit colored?", "How are the boots colored?", "How are the trees colored?", "How is the person's skis colored?", "What season is this picture most likely taking place in?", "What is the skier doing?"], "vqa": ["What is the weather like?", "Is she wearing a helmet?", "What is on the woman's feet?"], "mscoco2": ["a person jumping skis in the air with a sky background"]}}, {"img_id": "COCO_val2014_000000346717", "labelf": {"vqa": [{"in air": 0.6, "on skateboard": 0.3, "skate park": 0.6}, {"no": 1, "yes": 1}, {"yes": 1}]}, "sentf": {"vqa": ["Where is the person?", "Is this area meant for skateboarders?", "Is the skateboarder shirtless?"], "mscoco2": ["a skateboarder jumps over a stone dome with silver domes in front of it and bicycler behind him ."]}}, {"img_id": "COCO_val2014_000000516592", "labelf": {"gqa": [{"behind": 1.0}, {"fence": 1.0}, {"horse": 1.0}, {"no": 1.0}, {"material": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"papers": 1.0}, {"papers": 1.0}, {"left": 1.0}, {"horse": 1.0}, {"wood": 1.0}, {"horse": 1.0}, {"horse": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"White.": 1.0}, {"The sun.": 1.0}, {"Wood.": 1.0}, {"A horse.": 1.0}, {"White.": 1.0}], "vqa": [{"white": 1}, {"yes": 1}, {"afternoon": 0.6, "dusk": 0.6, "evening": 0.6, "morning": 0.6, "sunrise": 0.3, "sunset": 0.3}]}, "sentf": {"gqa": ["Is the horse behind or in front of the fence made of wood?", "What is the horse standing behind of?", "What animal is standing behind the fence?", "Are there elephants in the photo?", "What do both the fence and the wall have in common?", "Is the wood fence behind the animal that is to the right of the papers?", "Is the animal to the right of the papers standing behind a fence?", "Is there either a horse or a hippo in the scene?", "What is on the wood wall?", "What is on the wall?", "Which side are the papers on?", "What animal is the fence in front of?", "What is the fence made of?", "What animal is standing behind the fence that is made of wood?", "The fence is in front of what animal?"], "visual7w": ["When was the picture taken?", "What color is the sky?", "What is shining in the background?", "What is the fence made of?", "What kind of animal is on the right?", "What color is the horse on the right?"], "vqa": ["What color is the horse?", "Is a horse in a corral?", "What time of day is the photo taken?"], "mscoco2": ["a close up of a horse behind a fence", "an image of a white horse sticking its neck over the gate"]}}, {"img_id": "COCO_val2014_000000082052", "labelf": {"vqa": [{"no": 1}, {"no": 1, "yes": 1}, {"no": 1, "yes": 0.3}, {"no": 1}]}, "sentf": {"vqa": ["Is the skateboard rider on the sidewalk?", "Is the person wearing skating shoes?", "Is this a woman on a skateboard?", "Is the man wearing jeans?"], "mscoco2": ["Bottom half of a person on a skateboard with sky in background. "]}}, {"img_id": "COCO_val2014_000000517619", "labelf": {"vqa": [{"2": 1, "3": 0.6, "5": 0.3}, {"skateboard": 0.3, "skis": 0.3, "snowboard": 1}, {"inside": 1, "outside": 0.3}]}, "sentf": {"vqa": ["How many snowboards are in this scene?", "What is the young man riding on?", "Are these people inside or outside?"], "mscoco2": ["Several snowboarders do tricks indoors under a roof.  "]}}, {"img_id": "COCO_val2014_000000551739", "labelf": {"visual7w": [{"On all fours.": 1.0}, {"To keep the bear.": 1.0}, {"Brown.": 1.0}, {"One.": 1.0}, {"Brown.": 1.0}, {"A fence.": 1.0}, {"Nobody.": 1.0}, {"Green.": 1.0}, {"Right.": 1.0}, {"Bear and Wolf Museum.": 1.0}, {"Yellow.": 1.0}, {"Brown.": 1.0}, {"In the pen.": 1.0}, {"Gray.": 1.0}, {"Behind the bear.": 1.0}, {"Black.": 1.0}, {"Fur.": 1.0}, {"Light gray.": 1.0}, {"Next to the fence.": 1.0}, {"Green.": 1.0}, {"Brown.": 1.0}, {"Fence.": 1.0}, {"Bear and Wolf Museum.": 1.0}, {"Rock.": 1.0}, {"Green.": 1.0}, {"1.": 1.0}, {"None.": 1.0}, {"Black.": 1.0}, {"Green.": 1.0}, {"Bulky rock.": 1.0}, {"Under bear.": 1.0}, {"Rock.": 1.0}, {"Grey rock.": 1.0}, {"Brown.": 1.0}, {"Right.": 1.0}, {"Forward.": 1.0}, {"Front legs.": 1.0}], "vqa": [{"no": 1}, {"no": 1}, {"brown": 1}, {"bear": 0.3, "brown": 1, "grizzly": 0.3}, {"yes": 1}, {}]}, "sentf": {"visual7w": ["How many does the bear walk?", "Why is there a fence?", "What color is the bear?", "How many bears are there?", "What color is the bear?", "What is behind the bear?", "Who is with the bear?", "What color are the trees?", "What way is the bear facing?", "Where did this photo come from?", "What color is the word banner?", "What color is the bear?", "Where is the bear?", "What color is the fence?", "Where is the fence?", "What color is the bear's nose?", "What is the bear's coat made of?", "What color are the rocks?", "Where are the rocks?", "What color are the plants?", "What color is the bear's fur?", "What is behind the bear?", "What does the caption above the picture say?", "What is on the ground behind the bear?", "What color are the leaves on the trees?", "How many bears are in this photo?", "How many people are in this photo?", "What color is the bear's nose?", "What color is the grass in the background?", "What is under bear?", "Where is grey bulky rock?", "What is grey and under bear?", "What is bulky under bear?", "What color is bear fur?", "What leg is forward on bear?", "How is right leg of bear?", "What is forward under bear?"], "vqa": ["Is this in the wilderness?", "Is this a cub?", "What color is the bear?", "What kind of bear is this?", "Is there a fence?", "What museum is this?"], "mscoco2": ["a close up of a bear behind a fence"]}}, {"img_id": "COCO_val2014_000000131612", "labelf": {"gqa": [{"orange": 1.0}, {"horse": 1.0}, {"horse": 1.0}, {"left": 1.0}, {"no": 1.0}], "visual7w": [{"A woman.": 1.0}, {"A horse ride.": 1.0}, {"Flowers.": 1.0}, {"Yellow.": 1.0}, {"Daytime.": 1.0}, {"In a field.": 1.0}, {"1.": 1.0}, {"Brown.": 1.0}], "vqa": [{"jumping": 0.9, "riding": 1}, {"brown": 0.3, "gray": 0.3, "orange and white": 0.3, "red and white": 0.9, "white and brown": 0.3, "white and orange": 0.3}, {"no": 0.3, "yes": 1}]}, "sentf": {"gqa": ["Is the rope blue or orange?", "How is the animal that the man is on called?", "What do you think is the hairy animal in the image?", "Is the rope on the right or on the left?", "Is there a blanket on the animal that is on the grass?"], "visual7w": ["Who is riding the horse?", "Why is she on the horse?", "What is in the grass?", "What color are the flowers?", "When was this picture taken?", "Where is the horse running?", "How many horses are there?", "What color is the horse?"], "vqa": ["What is the man doing with the horse?", "What colors are the pole the horse is jumping over?", "Is there a pine tree?"], "mscoco2": ["The man is on the horse and is racing to jump over the barrier. ", "a person riding a horse jumping over a wooden obstacle "]}}, {"img_id": "COCO_val2014_000000129645", "labelf": {"vqa": [{"no": 1}, {"necklace": 1}, {"no": 1, "yes": 0.3}]}, "sentf": {"vqa": ["Is the man playing baseball?", "What kind of jewelry is he wearing?", "Is the man falling?"], "mscoco2": ["A man flying over a set of steps near a hill."]}}, {"img_id": "COCO_val2014_000000010644", "labelf": {"vqa": [{}, {}, {"scratching": 0.3, "standing": 0.3, "waiting": 0.3}, {"angels": 0.3, "not sure": 0.3}, {"air": 0.3, "glove": 0.9, "in his hand": 0.3, "mitt": 0.3}, {"no": 1, "yes": 0.3}, {"left": 1, "right": 0.3}, {"baseball": 1}]}, "sentf": {"vqa": ["Why would the pitcher be holding himself?", "What letter is on the pitchers head?", "What is the pitcher doing?", "What team is playing?", "Where is the ball?", "Is he hitting the ball?", "Which hand is the pitchers glove on?", "Which game is this?"], "mscoco2": ["A catcher is holding a particular area while player in the background look on. "]}}, {"img_id": "COCO_val2014_000000238573", "labelf": {"vqa": [{"1": 1}, {"horse": 1}, {"snow": 1}]}, "sentf": {"vqa": ["How many horses?", "What kind of animal is on the fence?", "What is on the ground?"], "mscoco2": ["A horse leans over a fence in a snowy pasture. "]}}, {"img_id": "COCO_val2014_000000070134", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"red": 1.0}, {"no": 1.0}, {"player": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}, {"player": 1.0}, {"no": 1.0}, {"no": 1.0}, {"field": 1.0}, {"no": 1.0}, {"player": 1.0}, {"player": 1.0}, {"player": 1.0}, {"yes": 1.0}, {"player": 1.0}, {"player": 1.0}, {"player": 1.0}, {"player": 1.0}, {"no": 1.0}, {"yes": 1.0}], "visual7w": [{"Baseball field.": 1.0}, {"One.": 1.0}, {"Sunglasses.": 1.0}, {"A baseball player.": 1.0}, {"3.": 1.0}, {"Red.": 1.0}, {"Daytime.": 1.0}], "vqa": [{"america": 0.6, "bank of america": 1}, {"cardinals": 1, "dodgers": 0.3}, {"nike": 1}, {"glove": 0.3, "no": 1}, {"no": 1, "yes": 0.3}, {"yes": 1}, {"cardinals": 1}, {"no": 0.9, "yes": 1}, {"3": 1}, {"outfield": 1}, {"hand": 1, "right hand": 0.3}, {"ball": 0.3, "bird": 1, "cardinal": 1}, {"cardinals": 1}]}, "sentf": {"gqa": ["Is the grass green and tall?", "Is there grass that is short in the scene?", "What color is the hat the player is wearing?", "Are there either any fire extinguishers or pillows?", "Who is wearing a wrist band?", "Is the person wearing a glove?", "Is the person wearing a helmet?", "Are there tennis balls or fences in this photo?", "Who is standing?", "Does the short grass have brown color?", "Does the green grass appear to be tall?", "Which place is it?", "Is the shirt long sleeved?", "Who is wearing the hat?", "Who is wearing trousers?", "Who is wearing the pants?", "Does the person seem to be standing?", "Who is wearing a shoe?", "Who is wearing a hat?", "Who is wearing a shirt?", "Who is wearing the shirt?", "Is the professional person wearing a helmet?", "Is this a baseball player?"], "visual7w": ["Where is this location?", "How many players can be seen?", "What is on the players face?", "Who is wearing a uniform?", "What is the number on the uniform?", "What color is the players cap?", "When was the picture taken?"], "vqa": ["What does the big red sign on the left say?", "What teams do these players represent?", "What brand of shoes does he have on?", "Is this baseball player holding a wooden bat?", "Is the batters left foot forward?", "Is there any padding on the fence?", "What is the mans shirt written?", "Has the game started yet?", "What number is on the man's jacket?", "What position does he play?", "What is the man holding up in the air?", "What is the mascot shaped as?", "What team does the he play for?"], "mscoco2": ["A baseball game is being played before a crowd."]}}, {"img_id": "COCO_val2014_000000072368", "labelf": {"gqa": [{"boy": 1.0}, {"boy": 1.0}, {"brown": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"house": 1.0}, {"house": 1.0}, {"no": 1.0}, {"pavement": 1.0}, {"boy": 1.0}, {"performing trick": 1.0}, {"pants": 1.0}, {"left": 1.0}, {"no": 1.0}, {"left": 1.0}, {"pavement": 1.0}, {"no": 1.0}], "visual7w": [{"1.": 1.0}, {"Daytime.": 1.0}, {"In the water.": 1.0}, {"One.": 1.0}, {"On a street.": 1.0}, {"Afternoon.": 1.0}, {"The line.": 1.0}, {"Blond.": 1.0}, {"Blond.": 1.0}, {"Blond.": 1.0}, {"Yellow.": 1.0}, {"Brown.": 1.0}, {"Tricks.": 1.0}, {"Curb.": 1.0}, {"Blue.": 1.0}, {"Ground.": 1.0}, {"Yellow.": 1.0}, {"Air.": 1.0}, {"Mid air.": 1.0}, {"Long.": 1.0}, {"Short sleeve.": 1.0}, {"House.": 1.0}, {"Shadow.": 1.0}, {"Yellow.": 1.0}, {"Brown.": 1.0}, {"A person.": 1.0}, {"Skateboarder.": 1.0}, {"On the road.": 1.0}, {"Skateboarder.": 1.0}, {"Road.": 1.0}, {"Skateboarder.": 1.0}, {"Along roadway.": 1.0}, {"Behind skateboarder.": 1.0}, {"Skateboarder.": 1.0}, {"Upside down.": 1.0}], "vqa": [{"no": 1, "yes": 0.3}, {"yes": 1}, {"skate": 0.3, "skateboard": 0.6, "skateboarding": 1}, {"on road": 0.3, "on street": 0.3, "road": 0.6, "street": 0.3}, {"no": 1, "yes": 0.3}]}, "sentf": {"gqa": ["Who is in front of the house on the right side?", "Who is in front of the house?", "Do the trousers look brown or white?", "Do the pants have long length and brown color?", "On which side of the picture is the house?", "What is the boy in front of?", "What do you think is the boy in front of?", "Is the white fence on the left?", "Which place is it?", "Who is jumping?", "What is he doing?", "Which kind of clothing is long?", "Is the boy to the right or to the left of the house on the right side?", "Is the shirt red and short sleeved?", "Is the boy to the right or to the left of the fence?", "What place is it?", "Does the fence have brown color?"], "visual7w": ["How many people are there?", "When is the picture taken?", "Where is the yellow line?", "How many skating board?", "Where is the picture taken?", "What time is it?", "What is yellow in color?", "What is the hair color?", "What is the hair color?", "What is the hair color?", "What is the stripe color?", "What are the pants color?", "What is the boy doing?", "What is behind the kid?", "What is the shirt color?", "Where is the shadow?", "What is the line color?", "Where is the skateboard?", "Where is the man?", "What kind of pants?", "What is the shirt?", "What is in the background?", "What is on the gruond?", "What is the line color?", "What is the pants color?", "Who is performing on skateboard?", "Who is wearing the brown pants?", "Where is the shadow?", "Who is casting a shadow?", "Where is the yellow line?", "Who is wearing black shoes?", "Where is the tree trunk?", "Where are the houses?", "Where is the navy shirt?", "How is the board positioned?"], "vqa": ["Is the child wearing shorts?", "Is the boy in the street?", "What sport is being played?", "Where is the yellow line?", "Could a dog do this trick?"], "mscoco2": ["A boy in midair above the skateboard on the street. "]}}, {"img_id": "COCO_val2014_000000015029", "labelf": {"vqa": [{"2": 1}, {"no": 1}, {"yes": 1}, {"no": 1}, {"frisbee": 1, "playing": 0.3, "playing frisbee": 1, "throwing frisbee": 0.3}, {"no": 1}, {"frisbee": 0.9, "playing frisbee": 1, "standing": 0.3}, {"gray": 1, "white": 1}, {"no": 1}, {"no": 1}, {"no": 1}, {"yes": 1}, {"collar": 0.6, "necklace": 0.3, "nothing": 0.6, "shirt": 0.6, "t shirt": 0.6}, {"frisbee": 1}, {"yes": 1}, {"frisbee": 1}, {"frisbee": 1, "laughing": 0.3, "playing frisbee": 0.9}, {"no": 1}, {"frisbee": 1}, {"no": 1, "yes": 0.3}, {"no": 1}, {"no": 1}, {"no": 1}]}, "sentf": {"vqa": ["How many hands?", "Is the man flying a kite?", "Is the man wearing a shirt?", "Is the person female?", "What is the boy doing?", "Is the man in the white shirt going to fall?", "What is the man doing?", "What color is the mans t-shirt?", "Is he going to fall?", "Are the men standing near the garage?", "Is the man wearing two shirts?", "Is there a tent?", "What is around the man's neck?", "What is the contraption in the man's hands?", "Are these people camping?", "What is the guy holding in his hand?", "What is this guy doing?", "Is the kid listening to music?", "What activity is the person engaged in?", "Is the person flying a kite a manchild?", "Is he wearing a snowsuit?", "Are these guys going in the water?", "Is the boy performing a trick?"], "mscoco2": ["Guy at the park holding a frisbee with people in the back under a tent"]}}, {"img_id": "COCO_val2014_000000417285", "labelf": {"vqa": [{"pie": 0.3, "yes": 1}, {"1": 0.3, "2": 1}, {"3": 1}]}, "sentf": {"vqa": ["Are these foods eaten half way?", "How many utensils are visible in this group?", "How many plates are shown?"], "mscoco2": ["A three frame photo combination showcases two types of pie on the right and left side with a coffee in the middle.  "]}}, {"img_id": "COCO_val2014_000000390147", "labelf": {"visual7w": [{"At a park.": 1.0}], "vqa": [{"no": 1, "yes": 0.3}, {"frisbee": 0.6, "playing frisbee": 1, "throwing": 0.3, "throwing frisbee": 0.9}, {"yes": 1}, {"0": 0.3, "2": 0.6, "3": 1}, {"frisbee": 1}, {"no": 1, "yes": 0.3}, {"pink": 0.6, "red": 1}, {"evening": 0.6, "morning": 1}, {"pink": 0.3, "red": 1}, {"asphalt": 0.6, "cement": 0.3, "concrete": 0.6, "road": 0.3, "sidewalk": 1}, {"3": 1, "4": 0.3}, {"2": 0.3, "3": 1}, {"no": 1, "yes": 0.6}, {"white": 1}, {"no": 1, "yes": 0.3}, {"sunny": 1}, {"cement": 0.3, "paved": 0.3, "sidewalk": 1}, {"no": 1}]}, "sentf": {"visual7w": ["Where is this picture?"], "vqa": ["Is there a bag in the trash can?", "What is the person doing?", "Does the ground appear dry?", "How many boys are in the picture?", "What game is the person on the right playing?", "IS there a man with a hat?", "What color is the disk?", "Is this morning or evening?", "What color is the round plate?", "What is the pavement called?", "How many people are in the picture?", "How many of the men have their feet on the ground?", "Are there rocks in the field?", "What color is this man's socks?", "Is the photo taken from  inside?", "What is the weather condition?", "What type of road is this?", "Is this a dangerous activity?"], "mscoco2": ["A man prepares to throw a frisbee over a hill."]}}, {"img_id": "COCO_val2014_000000136596", "labelf": {"gqa": [{"right": 1.0}, {"logo": 1.0}], "vqa": [{"no": 1, "yes": 0.6}, {"yes": 1}, {"no": 1, "yes": 0.6}, {"no": 1}, {}]}, "sentf": {"gqa": ["On which side is the boat?", "What is printed on the sign?"], "vqa": ["Is someone going to be hurt here?", "Is the boat in water?", "Are these skiers synchronized?", "Will the water skiers collide?", "What name is on the ramp?"], "mscoco2": ["People in air on waterboards over water with banner"]}}, {"img_id": "COCO_val2014_000000505163", "labelf": {"vqa": [{"cart": 1, "horse": 0.9, "wagon": 0.3}, {"yes": 1}, {"1": 1, "2": 0.9}]}, "sentf": {"vqa": ["What is the man riding?", "Does he look like he's concentrating?", "How many horses are being ridden?"], "mscoco2": ["A man driving a horse and cart with another riding a horse behind him.", "A man on a horse drawn wagon with another horse behind", "A man sitting a carriage while a horse pulls him and a boy riding on a horse behind him. "]}}, {"img_id": "COCO_val2014_000000212817", "labelf": {"gqa": [{"snow": 1.0}, {"boy": 1.0}, {"pants": 1.0}, {"boy": 1.0}, {"white": 1.0}, {"right": 1.0}, {"snowboarding": 1.0}, {"boy": 1.0}, {"snowboarding": 1.0}, {"white": 1.0}, {"boy": 1.0}, {"boy": 1.0}, {"boy": 1.0}, {"boy": 1.0}, {"blue": 1.0}, {"yes": 1.0}, {"girl": 1.0}, {"yes": 1.0}], "visual7w": [{"Snowboarding.": 1.0}, {"Winter.": 1.0}, {"Goggles.": 1.0}, {"Child.": 1.0}, {"Behind the child.": 1.0}, {"Gloves.": 1.0}, {"2.": 1.0}], "vqa": [{"no": 0.9, "yes": 1}, {"yes": 1}, {"no": 0.3, "yes": 1}, {"black": 0.3, "cream": 0.3, "silver": 0.3, "white": 1}, {"snow": 1, "snowboard": 0.3}]}, "sentf": {"gqa": ["What is the person in front of the building standing in?", "Who is wearing a jacket?", "What is the girl wearing?", "Who is wearing trousers?", "What color are the pants the boy is wearing?", "Where in the photo is the girl, on the right or on the left?", "What is the person on top of the snowboard doing?", "Who is snowboarding?", "What is the boy doing?", "The jacket the boy is wearing is what color?", "Who is on top of the snowboard that looks yellow?", "Who is in front of the person that is skiing?", "Who is on top of the snowboard?", "Who is wearing a glove?", "What is the color of the jacket the person is wearing?", "Do you see people behind the person on top of the snowboard?", "Who is wearing pants?", "Does the snow look white and bright?"], "visual7w": ["What sport is this child doing?", "When would this sport be popular?", "What is on the child's eyes?", "Who is wearing a red ski jacket?", "Where is the group of people standing?", "What is on the boy's hands?", "How many of the boy's arms are out to the side?"], "vqa": ["If a snowmobile comes down the mountain in the tracks, will the skier get hit?", "Is there an easy way for people to get up a a mountain in this picture?", "Is the sun out?", "What color is his goggles?", "What is the man on the snowboard sliding on?"], "mscoco2": ["The young child is posing for a picture before he snowboards down the hill. "]}}, {"img_id": "COCO_val2014_000000038828", "labelf": {"vqa": [{"yes": 1}, {"casual": 0.6, "large": 0.3}, {"horse": 1}, {"blanket": 1, "brown": 0.3, "leather": 0.6, "pillow": 0.3, "riding": 0.3}, {"blue": 0.3, "cowboy": 0.3, "rain": 0.3, "rubber": 0.6}]}, "sentf": {"vqa": ["Is the woman smiling?", "What type of horse riding is she doing?", "What is the woman on?", "What kind of saddle does the horse have on?", "What type of boots does this rider wear?"], "mscoco2": ["a person riding a horse near trees in the background"]}}, {"img_id": "COCO_val2014_000000563680", "labelf": {"vqa": [{"yes": 1}, {"building": 0.3, "man": 0.3, "tree": 1, "trees": 0.6}, {"0": 1}]}, "sentf": {"vqa": ["Is the skateboard upside down?", "What is creating the shadow?", "How many feet are on the skateboard?"], "mscoco2": ["A kid doing a kickflip over a manhole. "]}}, {"img_id": "COCO_val2014_000000571215", "labelf": {"vqa": [{"skateboard": 1}, {"on street": 0.3, "outside": 1, "sidewalk": 0.6}, {"black": 1, "black and white": 0.6}, {"graffiti": 0.6, "man": 0.6, "painting": 0.6}, {"black": 1, "gray": 0.3}, {"no": 1}]}, "sentf": {"vqa": ["What part of the art image makes it 3D?", "Where is this taken?", "What color are the skater's pants?", "What is on the wall?", "What color is on the bottom of the skaters sneakers?", "IS this a real person?"], "mscoco2": ["A painting of a person on a white wall and a skateboard placed under the wall painting. "]}}, {"img_id": "COCO_val2014_000000355276", "labelf": {"vqa": [{"yes": 1}, {"no": 1, "yes": 0.6}, {"yes": 1}]}, "sentf": {"vqa": ["Would this be a dangerous animal to encounter?", "Is this bear in its natural habitat?", "Is this bear tired?"], "mscoco2": ["A bear seems to be trying to hide under the log. ", "A bear laying behind a big tree trunk"]}}, {"img_id": "COCO_val2014_000000060262", "labelf": {"gqa": [{"no": 1.0}, {"black": 1.0}, {"horse": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"horses": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"brown": 1.0}, {"horse": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"Six.": 1.0}, {"White.": 1.0}, {"Light Blue.": 1.0}, {"Farm.": 1.0}, {"Eating.": 1.0}, {"A Horse.": 1.0}], "vqa": [{"5": 0.9, "6": 1, "7": 0.6}, {"no": 1, "yes": 1}, {"no": 1, "yes": 1}]}, "sentf": {"gqa": ["Does the brown hair have short length?", "What color does the horse in the bottom of the image have?", "What animal eats the grass?", "Does the blue sky appear to be cloudy?", "Is there a horse in the picture?", "Are these cows or horses?", "Is the sky both clear and blue?", "Is it outdoors?", "What color is the horse's hair?", "Which kind of animal is eating the grass?"], "visual7w": ["When was the photo taken?", "How many horses are there?", "What color is the grass?", "What color is the sky?", "Where was the photo taken?", "What is the horse doing?", "What animal is in the photo?"], "vqa": ["How many horses are in the field?", "Is this dapple-gray?", "Is the horse wild?"], "mscoco2": ["a number of horses in a field with a sky background"]}}, {"img_id": "COCO_val2014_000000149962", "labelf": {"vqa": [{"blue": 1}, {"no": 1, "yes": 0.9}, {"1": 0.6, "2": 1}]}, "sentf": {"vqa": ["What color are the skateboarders jean?", "Are there pine trees in the picture?", "How many hands are on the skateboard in the air?"], "mscoco2": ["The man is jumping over the skate board"]}}, {"img_id": "COCO_val2014_000000174123", "labelf": {"gqa": [{"top": 1.0}], "visual7w": [{"Pizza.": 1.0}, {"Table.": 1.0}, {"Daytime.": 1.0}, {"Fork and knife.": 1.0}, {"Silverware.": 1.0}, {"2.": 1.0}, {"1.": 1.0}, {"0.": 1.0}, {"Plate.": 1.0}, {"Fork.": 1.0}, {"Bits of food.": 1.0}, {"Right.": 1.0}, {"Burnt.": 1.0}, {"Part.": 1.0}, {"Cheese and bell pepper.": 1.0}, {"Thin.": 1.0}, {"Silver.": 1.0}, {"Circle.": 1.0}, {"Left.": 1.0}, {"Green peppers.": 1.0}, {"Pizza.": 1.0}, {"Cheese.": 1.0}, {"Plate.": 1.0}, {"White.": 1.0}, {"Tablecloth.": 1.0}, {"Red.": 1.0}, {"Lunch table.": 1.0}, {"Round.": 1.0}, {"Pizza.": 1.0}, {"Cheese.": 1.0}, {"Checkered.": 1.0}, {"Fork.": 1.0}, {"Knife.": 1.0}, {"Red.": 1.0}, {"It is burnt.": 1.0}, {"On a plate.": 1.0}, {"Person ate it.": 1.0}, {"On a plate.": 1.0}], "vqa": [{"fork": 1, "fork and knife": 0.6, "knife and fork": 0.3}, {"checkerboard": 0.6, "checkered": 0.6, "plaid": 0.3}, {"white": 1}]}, "sentf": {"gqa": ["Are the people in the bottom part or in the top of the picture?"], "visual7w": ["What is the focus?", "Where is this shot?", "When was this taken?", "What silverware is being used?", "What is the person holding?", "How many pieces of silverware are there?", "How many pizzas are shown?", "How many animals are in the photo?", "What is round and white?", "What has four prongs?", "What is on the fork?", "What hand is the knife in?", "What is the crust's condition?", "How much of a pizza is this?", "What kind of pizza is this?", "What size is the crust?", "What kind of fork?", "What shape plate?", "What hand is fork in?", "What vegetables are on pizza?", "What food is there?", "What is melted on the pizza?", "What is the pizza on?", "What main color is the plate?", "What is covering the table?", "What shade is the tablecloth?", "Where is this scene?", "What is the shape of the plate?", "What is on the plate?", "What is the white topping on the pizza?", "What is the pattern of the tablecloth?", "What is utensil on the left?", "What is the utensil on the right?", "What is the sauce color of the pizza?", "Why is the crust dark brown?", "Where is the pizza?", "Why is a piece of pizza missing?", "Where is the pizza?"], "vqa": ["What is been held?", "What is the pattern of the tablecloth?", "What color is the plate?"], "mscoco2": ["a person holding a knife and fork over a pizza"]}}, {"img_id": "COCO_val2014_000000010142", "labelf": {"visual7w": [{"Hats.": 1.0}, {"The man.": 1.0}, {"Snow.": 1.0}, {"Day time.": 1.0}, {"Sun light.": 1.0}, {"One.": 1.0}, {"The mountain.": 1.0}], "vqa": [{"blue": 1, "blue and gray": 0.3}, {"no": 1}, {"0": 0.3, "1": 1}, {"yes": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"visual7w": ["What is on the mans head?", "Who is standing up?", "What is white?", "When was the photo taken?", "Why is it so bright?", "How many people are there?", "Where is the man?"], "vqa": ["What color is the man's jacket?", "Is this man headed downhill?", "How many skiers can be seen?", "Is the cross country skiing?", "Is there any snow on the trees in the background?"], "mscoco2": ["A man smiles as he turns to look behind him while skiing."]}}, {"img_id": "COCO_val2014_000000505739", "labelf": {"vqa": [{"1": 1, "2": 0.3}, {"yes": 1}, {"moving": 0.3, "racing": 1, "running": 0.6, "walking": 0.3}, {"8": 1}, {"1": 0.3, "no": 0.3, "yes": 1}, {"dirt": 0.6, "ground": 0.6, "road": 0.3, "track": 0.9}, {"no": 1}, {"yes": 1}]}, "sentf": {"vqa": ["How many horses are in the picture?", "Is the horse running?", "What is this horse doing?", "What number is the horse?", "Are the horses about to race?", "What is the horse running on?", "Is this too much weight for the horse to pull?", "Are these racing horses?"], "mscoco2": ["A man rides behind a horse during a race."]}}, {"img_id": "COCO_val2014_000000382770", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"deep": 1}, {"skiing": 0.3, "surfing": 0.6, "water skiing": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["Could this be a slalom ski?", "Is this water deep or shallow?", "What type of sport is the man engaging in?", "Is this person safe?"], "mscoco2": ["A man skis behind a boat on the water"]}}, {"img_id": "COCO_val2014_000000308165", "labelf": {"vqa": [{"cone": 1}, {"palm": 0.9, "palm trees": 1}, {"behind": 0.3, "left": 0.3, "left side": 0.6, "on left": 0.3, "sky": 0.6, "to left": 0.3}, {"construction": 0.3, "safety": 0.6, "yes": 0.6}]}, "sentf": {"vqa": ["What is the kid jumping over?", "What are the name of the trees in the background?", "Where is the sun?", "Why is there sand around the orange object?"], "mscoco2": ["a man on a skateboard in mid air going over a cone in some dirt", "A kid on skateboard jumps over the cone"]}}, {"img_id": "COCO_val2014_000000553990", "labelf": {"gqa": [{"trees": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"horse": 1.0}, {"horse": 1.0}, {"no": 1.0}, {"horse": 1.0}, {"horse": 1.0}, {"horse": 1.0}, {"no": 1.0}, {"large": 1.0}, {"horse": 1.0}, {"girl": 1.0}, {"trees": 1.0}, {"girl": 1.0}], "visual7w": [{"A horse.": 1.0}, {"During the daytime.": 1.0}, {"To get over the gate.": 1.0}, {"One.": 1.0}, {"Brown.": 1.0}, {"On the horse.": 1.0}, {"Grass.": 1.0}, {"A horse.": 1.0}, {"The horse.": 1.0}, {"Over the white fence.": 1.0}, {"An equestrian event.": 1.0}, {"A female is riding the horse.": 1.0}, {"Jumping over poles.": 1.0}, {"A horse.": 1.0}, {"Riding a horse.": 1.0}, {"A woman.": 1.0}, {"Trees.": 1.0}, {"A helmet.": 1.0}, {"Trees.": 1.0}, {"A jockey.": 1.0}, {"A horse.": 1.0}, {"A long black tail.": 1.0}, {"A large area of grass.": 1.0}, {"A large brown horse.": 1.0}], "vqa": [{"yes": 1}, {"yes": 1}, {"brown": 1}]}, "sentf": {"gqa": ["What is the horse in front of?", "Is the tail long and white?", "Does the horse's tail look black?", "Do you see either a plate or a fork?", "Are there fences or helmets?", "Are there white lambs or horses?", "What animal do you think is above the green grass?", "What animal is above the grass?", "Is the animal above the grass small and brown?", "What is the name of the large animal?", "Which kind of animal is large?", "Which kind of animal is brown?", "Is there either any brown grass or mud?", "What size is the brown animal?", "What animal is it?", "Who is riding the horse?", "The girl is in front of what?", "Who is riding a horse?"], "visual7w": ["What animal is photographed?", "When was this photo taken?", "Why is this horse jumping?", "How many horses are photographed?", "What color is the horse?", "Where is the jockey?", "What is the surface of the ground?", "What animal is photographed?", "Who does the tail belong to?", "Where does the horse jump?", "What is happening in the photo?", "Who rides the horse?", "What is the horse doing?", "What animal is the woman riding?", "What is the woman doing?", "Who is riding a horse?", "What is behind the blue and white fence?", "What is on the woman's head?", "What is located in the background?", "What is the rider called?", "What does the tail belong to?", "What is extended from the horses rear?", "What is the horse running on?", "What is the person riding?"], "vqa": ["Is this an obstacle course?", "Is the horse jumping?", "What color is the horse?"], "mscoco2": ["A man riding on a horse as it jumps over a pole. ", "A woman is riding a horse as it jumps over a bar.", "there is a woman jockey riding a hose over the hurdle"]}}, {"img_id": "COCO_val2014_000000281331", "labelf": {"vqa": [{"yes": 1}, {}, {"skirt": 0.9}, {"striped": 1, "stripes": 0.9}]}, "sentf": {"vqa": ["Is the dog peeking out?", "Where is the dog in the bedroom?", "What is the name of the bed garment the dog is looking through?", "What pattern is the bed skirt?"], "mscoco2": ["A puppy is peeking out from under a table cloth"]}}, {"img_id": "COCO_val2014_000000455345", "labelf": {"gqa": [{"bananas": 1.0}, {"bananas": 1.0}, {"bananas": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"bananas": 1.0}, {"bananas": 1.0}], "visual7w": [{"Zero.": 1.0}, {"Apples.": 1.0}, {"Red.": 1.0}, {"Yellow.": 1.0}, {"Clear.": 1.0}, {"Nine.": 1.0}, {"Glass.": 1.0}, {"Red.": 1.0}, {"Stems.": 1.0}, {"Bowl.": 1.0}, {"Stem.": 1.0}, {"Behind bowl.": 1.0}, {"Green.": 1.0}, {"Light.": 1.0}, {"Bowl.": 1.0}, {"Apples.": 1.0}, {"Apple.": 1.0}, {"Bananas.": 1.0}, {"Bowl.": 1.0}, {"Stem.": 1.0}, {"Light.": 1.0}, {"Blue.": 1.0}, {"Apples.": 1.0}, {"By the stem.": 1.0}, {"Oval.": 1.0}, {"Circle.": 1.0}, {"On the sides of the bowl.": 1.0}, {"The bananas are ripening.": 1.0}, {"Apples.": 1.0}, {"Bananas.": 1.0}, {"Fruit.": 1.0}, {"A bunch.": 1.0}, {"The bananas.": 1.0}, {"Apples, bananas.": 1.0}, {"Light.": 1.0}], "vqa": [{"apple": 0.3, "apple and banana": 0.3, "apples": 0.6}, {"1": 1}, {"yes": 1}, {"no": 1, "yes": 0.3}, {"6": 1, "7": 0.9}, {"6": 1, "7": 1}, {"2": 1}]}, "sentf": {"gqa": ["What are the fruits that the spots are on?", "What fruits are the spots on?", "What are the spots on?", "Are the spots on the bananas?", "Is there any green apple in the scene?", "Which fruits are not red, the bananas or the apples?", "What fruits are not red?"], "visual7w": ["How many people are in this photo?", "What fruit is on the bottom of the photo?", "What color are the apples?", "What color are the bananas?", "What color is the bowl the apples are in?", "How many bananas are there?", "What material is the bowl made from?", "What is the predominant color of the fruit in the bowl?", "What are the brown items on top of the red fruit?", "What type of tableware is the fruit in?", "What is holding the bananas together?", "Where are the bananas?", "What is the other color than red on the fruit in the bowl?", "What is reflected on the apples?", "Where are the apples?", "What type of fruit is in the bowl?", "What is the red fruit?", "What is the yellow fruit?", "Where are the apples?", "What is on the top of the apple at the top center of the photo?", "What is reflecting off the apples?", "What is the tint of the bowl?", "What is in the bowl?", "How are the bananas connected?", "What is the shape of the apples?", "What shape is the bowl?", "Where are the bowl's handles?", "Why are there brown spots on the bananas?", "What are the red fruits called?", "What are the yellow fruits called?", "What are these two types of food called?", "What are a group of bananas called?", "What fruit has a peel?", "What fruit is this?", "What reflects off the apple?"], "vqa": ["What kind of fruit is this?", "How many varieties of apples are there?", "Is the picture in color?", "Is all the fruit in the bowl?", "How many red apples are in this bowl?", "How many apples are in this picture?", "How many different types of fruit are shown?"], "mscoco2": ["This is a bowl of apples with bananas in the background. "]}}, {"img_id": "COCO_val2014_000000443053", "labelf": {"vqa": [{"black": 1}, {"no": 1, "yes": 0.9}, {"asian": 1, "black": 0.3, "hawaiian": 0.3, "hispanic": 0.3}]}, "sentf": {"vqa": ["The little boy in the front has on what color shirt?", "Is there someone riding a scooter on the water?", "What ethnicity is the boy?"], "mscoco2": ["A young Asian kid surfing over a splash of wave. "]}}, {"img_id": "COCO_val2014_000000050672", "labelf": {"gqa": [{"no": 1.0}, {"beach": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"beach": 1.0}], "visual7w": [{"2.": 1.0}, {"Pointed.": 1.0}, {"Rocks.": 1.0}, {"To not lose it.": 1.0}, {"White.": 1.0}, {"Both people.": 1.0}, {"When surfing.": 1.0}, {"Scuba suit.": 1.0}, {"Walking on beach.": 1.0}, {"A surfboard.": 1.0}, {"Black.": 1.0}, {"Wetsuit.": 1.0}, {"Shoreline.": 1.0}, {"Black.": 1.0}, {"2.": 1.0}, {"2.": 1.0}, {"Ocean.": 1.0}, {"White.": 1.0}, {"Red.": 1.0}, {"Black.": 1.0}, {"Sand.": 1.0}, {"White.": 1.0}, {"White.": 1.0}, {"Surfing.": 1.0}, {"Surfboard.": 1.0}, {"Wetsuit.": 1.0}, {"Black.": 1.0}, {"On surfboard.": 1.0}, {"On shore.": 1.0}, {"Surfers.": 1.0}, {"A man.": 1.0}, {"On surfboard.": 1.0}, {"Black.": 1.0}, {"A surfboard.": 1.0}, {"A wetsuit.": 1.0}, {"The beach.": 1.0}, {"White.": 1.0}], "vqa": [{"black": 1}, {"yes": 1}, {"white": 1}]}, "sentf": {"gqa": ["Are there any American flags or ropes in the photo?", "Which place is it?", "Does the beach look smooth and sandy?", "Is the color of the surfboard different than the wire?", "Is it an outdoors scene?", "Where was the image taken, the harbor or the beach?"], "visual7w": ["How many surf boards are there?", "What shape is the tip of the surfboard?", "What hard things are in the water?", "Why is there a red rope attached to surfboard?", "What color is the surfboard?", "Who is wearing wet suits?", "When will the rope be used thats on the surf board?", "What is the man wearing?", "What is the man doing?", "What is the man holding?", "What color is the surfer dressed in?", "What is the other surfer wearing?", "Where is the surfer walking at?", "What color is the man's suit?", "How many people are shown?", "How many rocks are seen in the ocean?", "What body of water is shown?", "What color is the surfboard in the front?", "What color is the front surfboard's leash?", "What color are the wetsuits?", "Where are the men standing?", "What color are the waves?", "What color is the patch on the wetsuit?", "What sport is represented?", "What is man holding?", "What is man wearing?", "What color is wetsuit?", "Where are designs?", "Where are surfers?", "Who is walking?", "Who is in wetsuit?", "Where are fins?", "What color is the wetsuit?", "What is the man holding?", "What is the man wearing?", "Where is the photo taken?", "What is the primary color of the surfboard?"], "vqa": ["What color is the man's bodysuit?", "Is this a full bodysuit?", "What color is the surfboard?"], "mscoco2": ["A person wearing a wetsuit with a surfboard under one arm."]}}, {"img_id": "COCO_val2014_000000570242", "labelf": {"vqa": [{"blurry": 0.3, "cnn": 0.3, "news": 0.6, "tv": 0.3}, {"numbers": 0.3, "phone": 0.9, "remote": 1, "remote control": 0.3}, {"remote": 1, "remote control": 1, "television": 0.3, "tv": 0.3}, {"yes": 1}, {"can't tell": 0.3, "comcast": 0.3, "samsung": 0.9, "sony": 1}, {"no": 1}, {"can't tell": 0.3, "off": 1, "on": 0.3}]}, "sentf": {"vqa": ["What program is on the TV screen?", "What is this a zoomed-in picture of?", "What is the device in the foreground?", "Is there a TV in the background?", "What is the parent company that made this remote?", "Is that a computer keyboard?", "Is the mobile phone on or off?"], "mscoco2": ["A television remote with several buttons and a blurry background. "]}}, {"img_id": "COCO_val2014_000000399605", "labelf": {"vqa": [{"surfer": 1}, {"surfing": 1}, {"white": 1}]}, "sentf": {"vqa": ["Which is closer to shore, the surfer or boat?", "What is the person doing?", "What color is the boat?"], "mscoco2": ["Person on a surfboard in the water with a boat in the background. "]}}, {"img_id": "COCO_val2014_000000296460", "labelf": {"vqa": [{"fries": 0.6, "hands": 0.3, "nothing": 1, "sauerkraut": 0.3}, {"no": 1, "yes": 0.3}, {"girl": 0.3, "woman": 1}, {"sandwich": 1}, {"bacon": 0.3, "chicken": 0.3, "deli": 0.3, "lunch": 0.3, "turkey": 0.3}, {"no": 1}, {"sandwich": 1}, {"0": 1, "1": 0.3}, {"sandwich": 1}, {"girl": 0.9, "lady": 0.9, "woman": 0.6}, {"no": 1, "yes": 0.3}, {"bench": 1, "chair": 1, "stool": 0.3}, {"white": 1}, {"2": 1}]}, "sentf": {"vqa": ["What is she eating with her sandwich?", "Does this girl have light eyes?", "Who is smiling?", "What this person is eating?", "What type of sandwich is the man eating?", "Is the sandwich on a plate?", "What is she eating?", "Who many donuts have they eaten?", "What is served on the plate?", "Who does the sandwich belong to?", "Is her hair in a ponytail?", "What is this lady sitting on?", "What color is the top the lady is wearing?", "How many pieces is the sandwich cut in to?"], "mscoco2": ["A woman standing over a table in front of a sandwich."]}}, {"img_id": "COCO_val2014_000000278172", "labelf": {"vqa": [{"beer": 1, "coke": 0.3, "soda": 0.3}, {"candle": 1, "drink": 0.3, "glass": 0.3, "mug": 0.3, "table": 0.3}, {"no": 1}]}, "sentf": {"vqa": ["What is the guy drinking?", "What is the guy looking at?", "Is the man lighting a campfire?"], "mscoco2": ["The woman is lighting a candle before eating her meal. ", "A young lady is lighting the candle before eating her meal. "]}}, {"img_id": "COCO_val2014_000000288765", "labelf": {"vqa": [{"wicker": 1}, {"no": 1}, {"yes": 1}]}, "sentf": {"vqa": ["What material is the basket made out of?", "Does he have a plate?", "Is there a lot of lettuce on this burger?"], "mscoco2": ["Person holding up a sandwich they're about to eat over the table"]}}, {"img_id": "COCO_val2014_000000310059", "labelf": {"vqa": [{"bowl": 0.6, "glass": 0.9, "laptop": 0.3, "speaker": 0.3, "trash": 0.3, "wine": 0.3}, {"nobody": 0.3, "owner": 0.3}, {}, {"pizza": 1}]}, "sentf": {"vqa": ["What is on the floor beside the plate?", "Who needs to sign in?", "What does the TV screen read?", "What is on the plate?"], "mscoco2": ["Food sitting on a white plate below a television with video game. "]}}, {"img_id": "COCO_val2014_000000441861", "labelf": {"vqa": [{"field": 1, "goalie": 0.3, "in field": 0.3, "soccer field": 0.6}, {"soccer": 1}, {"soccer": 1}, {"field": 0.3, "goal": 1}, {}]}, "sentf": {"vqa": ["Where are the players?", "What sport are they playing?", "What game is being played?", "Where is the soccer player?", "What is the goalie about to do?"], "mscoco2": ["A soccer catcher behind the fence is trying to catch the ball. "]}}, {"img_id": "COCO_val2014_000000131276", "labelf": {"gqa": [{"donuts": 1.0}, {"no": 1.0}, {"donuts": 1.0}, {"display": 1.0}, {"display": 1.0}, {"yes": 1.0}, {"donuts": 1.0}, {"yes": 1.0}, {"donuts": 1.0}], "vqa": [{"no": 0.3, "yes": 1}, {"3": 1}, {"donuts": 1, "pastries": 0.9}]}, "sentf": {"gqa": ["What kind of baked good is on the tray?", "Are there any cups?", "What kind of baked good is on the tray?", "What place does this represent?", "Which place is it?", "Are there both trays and donuts in this image?", "What is on the tray in the bottom of the picture?", "Are there donuts or candies?", "What is on the tray?"], "vqa": ["Are all the people of the same race?", "How many women are in the image?", "What type of food is being sold?"], "mscoco2": ["People are standing behind the bakery counter. "]}}, {"img_id": "COCO_val2014_000000057403", "labelf": {"vqa": [{"3": 1, "4": 0.6}, {"0": 0.9, "1": 1}, {"black": 1, "gray": 0.3, "green": 0.3, "silver": 0.6, "white": 0.3}]}, "sentf": {"vqa": ["How many window panels are visible?", "How many buckets are in the shot?", "What color is the desk lamp?"], "mscoco2": ["The office desk is still a mess and the computer is left on. "]}}, {"img_id": "COCO_val2014_000000491623", "labelf": {"vqa": [{"yes": 1}, {"no": 1}, {"no": 1}]}, "sentf": {"vqa": ["Is there a cab in the photo?", "Is anyone sleeping in the bed now?", "Is the bed frame orange?"], "mscoco2": ["A bed with a photograph hanging above it. "]}}, {"img_id": "COCO_val2014_000000218736", "labelf": {"vqa": [{}, {"yes": 1}, {"no": 1}, {"yes": 1}, {"mario": 1}]}, "sentf": {"vqa": ["What drinks are shown?", "Is there any mustard on the hot dog?", "Is there ketchup?", "Is there mustard on the hot dog?", "What game is that mushroom from?"], "mscoco2": ["A hot dog, sodas, waters, and a Super Mario mushroom on a table with people in the background. "]}}, {"img_id": "COCO_val2014_000000323356", "labelf": {"visual7w": [{"Blue and white.": 1.0}, {"During the day.": 1.0}, {"A man.": 1.0}, {"A toothbrush.": 1.0}, {"A string.": 1.0}, {"Blue.": 1.0}, {"One.": 1.0}, {"On the grass.": 1.0}, {"A toothbrush.": 1.0}, {"Male.": 1.0}, {"Grass.": 1.0}, {"On the ground.": 1.0}, {"Bristles.": 1.0}, {"Brush teeth in your mouth.": 1.0}, {"The teeth.": 1.0}, {"Back.": 1.0}, {"On the head of the brush.": 1.0}, {"On the brush.": 1.0}, {"Toothbrush.": 1.0}, {"Thin green cord.": 1.0}, {"Blue and white.": 1.0}, {"Curved.": 1.0}, {"Back.": 1.0}, {"Kneeling.": 1.0}, {"Grass.": 1.0}], "vqa": [{"brush": 0.3, "camping": 0.6, "clean": 0.3, "cleaning": 0.3}, {"no": 0.3}, {"blue": 1}]}, "sentf": {"visual7w": ["What color is the toothbrush?", "When was the picture taken?", "Who is in the picture?", "What is captured in the picture?", "What is around the toothbrush?", "What color is the man's jacket?", "How many toothbrushes are in the picture?", "Where is the man bending?", "What is this tooth brushing device?", "What gender is the bending person?", "What is growing up out of the ground that is green?", "Where is the grass?", "What is coming off the toothbrush that you brush with?", "How do you use this toothbrush?", "Where does this end of the toothbrush clean?", "What body part is the shirt on the man?", "Where are the bristles?", "Where are these bristles?", "What object is in the foreground?", "What is around the toothbrush handle?", "What kind of head is on the toothbrush?", "What shape are the toothbrush bristles?", "What part of the man is visible?", "What position is the man in?", "Where is the man kneeling?"], "vqa": ["Why is this toothbrush outside?", "How does the toothbrush help this man do lawn work?", "What color is the man's shirt?"], "mscoco2": ["A close up of a tooth brush and a blurred background of a man in a blue jacket facing the opposite direction. "]}}, {"img_id": "COCO_val2014_000000069757", "labelf": {"gqa": [{"sweater": 1.0}, {"no": 1.0}, {"table": 1.0}, {"shirt": 1.0}, {"gray": 1.0}, {"cake": 1.0}, {"cake": 1.0}, {"right": 1.0}, {"no": 1.0}, {"striped": 1.0}, {"no": 1.0}, {"sweater": 1.0}, {"small": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}], "visual7w": [{"Two people.": 1.0}, {"Tablecloth.": 1.0}, {"In a dining room.": 1.0}, {"Woman standing.": 1.0}, {"On the table.": 1.0}, {"Cake.": 1.0}, {"On a cake.": 1.0}, {"One.": 1.0}, {"Sitting.": 1.0}, {"Sitting.": 1.0}, {"Sitting.": 1.0}, {"Taking food.": 1.0}, {"Cake.": 1.0}, {"Cake.": 1.0}, {"Knife.": 1.0}, {"Tablecloth.": 1.0}, {"Table.": 1.0}, {"Glasses.": 1.0}, {"White.": 1.0}, {"Blue.": 1.0}, {"Male.": 1.0}, {"Older.": 1.0}, {"On the cake.": 1.0}, {"Glasses.": 1.0}, {"Chocolate.": 1.0}, {"The woman in the middle.": 1.0}, {"Sitting.": 1.0}, {"Standing.": 1.0}, {"Sitting.": 1.0}], "vqa": [{"cake": 1, "shadow": 0.3}, {"no": 1, "yes": 0.9}, {}, {"yes": 1}]}, "sentf": {"gqa": ["What kind of clothing is gray?", "Are there any knives or spoons that are not long?", "Is this a table or a mirror?", "What is the striped clothing item called?", "Which color is the sweater?", "What kind of dessert is in the plate which is to the right of the person?", "What is in the plate that is to the right of the person?", "Is the man to the right or to the left of the person that is wearing glasses?", "Are there chairs at the table?", "Is the shirt dotted or striped?", "Are there both plates and breads?", "What is that man wearing?", "How large is the round glass?", "Are there any spoons in the plate to the right of the person?", "Is the hair long and white?", "Are there people to the right of the plate that the cake is in?"], "visual7w": ["Who is sitting down?", "What is white?", "Where was the photo taken?", "Who is wearing light blue?", "Where are plates?", "What is round?", "Where is chocolate frosting?", "How many people are standing?", "What is the man doing?", "What is the man doing?", "What is the man doing?", "What is man doing?", "What is on the table?", "What is on the table?", "What is on the table?", "What is on the table?", "Where are the people sitting?", "What is woman wearing?", "What is hair color?", "What is jacket color?", "What is person's gender?", "What is man's age?", "Where are the candles?", "What is on the middle woman's face?", "What kind of cake is shown?", "Who is wearing the blue shirt?", "What position is the woman on the left in?", "What position is the middle woman in?", "What position is the man in?"], "vqa": ["What is black object on table?", "Is the man eating his finger?", "What kind of candy is on the chocolate cake?", "Are they having dessert?"], "mscoco2": ["Three people are sitting at the table together over cake. "]}}, {"img_id": "COCO_val2014_000000312144", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"3": 1}, {"5:05": 0.6, "5:30": 1}, {"2": 0.3, "35": 1, "5": 0.9}]}, "sentf": {"vqa": ["Is this house of wood?", "How many seats are shown?", "What time does the clock show?", "How many seconds past the minute does the clock show?"], "mscoco2": ["a clock hanging on a wall above some chairs"]}}, {"img_id": "COCO_val2014_000000061717", "labelf": {"gqa": [{"yes": 1.0}, {"yes": 1.0}, {"air conditioner": 1.0}, {"air conditioner": 1.0}, {"wall": 1.0}, {"no": 1.0}, {"left": 1.0}, {"orange": 1.0}, {"air conditioner": 1.0}, {"yes": 1.0}, {"color": 1.0}, {"bed": 1.0}, {"yes": 1.0}, {"indoors": 1.0}, {"air conditioner": 1.0}, {"air conditioner": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"bed": 1.0}, {"yes": 1.0}, {"air conditioner": 1.0}, {"air conditioner": 1.0}, {"green": 1.0}, {"right": 1.0}, {"red": 1.0}, {"no": 1.0}, {"bed": 1.0}, {"right": 1.0}, {"no": 1.0}, {"air conditioner": 1.0}, {"no": 1.0}, {"air conditioner": 1.0}, {"air conditioner": 1.0}, {"bed": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}], "visual7w": [{"Nobody.": 1.0}, {"Clear.": 1.0}, {"A bed.": 1.0}, {"Sheets.": 1.0}, {"Daytime.": 1.0}, {"Brown.": 1.0}, {"In a bedroom.": 1.0}], "vqa": [{"yes": 1}, {"black": 1, "brown": 0.3}, {"bedroom": 0.3, "hotel": 1}, {"yes": 1}, {"full": 0.3, "king": 0.9, "queen": 1}, {"1": 1}, {"no": 1}, {"no": 1}]}, "sentf": {"gqa": ["Do you see any pictures on the wall?", "Do the card and the chair have a different colors?", "Which kind of appliance is on the wall?", "What is the name of the appliance on the wall that looks yellow and brown?", "What is the air conditioner on?", "Is the window above a counter?", "Which side of the picture is the pillow on?", "What color are the curtains that are on the window?", "What is the appliance below the window the curtains are on called?", "Is the air conditioner on the wall?", "What do both the card and the bag have in common?", "What is the card on?", "Are there both curtains and blankets in the image?", "Is it outdoors or indoors?", "What appliance is under the window?", "What appliance is below the window?", "Is the picture on the left of the image?", "On which side of the picture is the rug?", "What is the pillow on?", "Are both the lamp and the ceiling the same color?", "What is the appliance to the right of the green bag?", "What kind of appliance is to the right of the bag?", "What color is the bag?", "On which side of the photo is the bag?", "What is the color of the chair?", "Is the blanket on the right side?", "Which kind of furniture is to the left of the rug?", "Is the green bag to the left or to the right of the chair?", "Are there any cars or dishwashers in this photo?", "How is the appliance under the window called?", "Is the air conditioner on the left?", "What is under the window that the curtains are on?", "What is under the window?", "Is that a bed or a table?", "Are there any boxes on the floor?", "Are there both nightstands and pillows in the image?", "Are there either bags or chairs that are green?", "Does the ceiling have a different color than the bag?"], "visual7w": ["Who is present?", "How is the photo?", "What is present?", "What else is visible?", "When was this?", "What color is the floor?", "Where was this photo taken?"], "vqa": ["Is the bed made?", "What color is the frame of the large picture?", "Where is this?", "Are the beds made?", "What kind of bed is that?", "How many beds?", "Are the lights on?", "Is the light on?"], "mscoco2": ["A bed sitting in a bedroom next to a window under pictures."]}}, {"img_id": "COCO_val2014_000000252701", "labelf": {"vqa": [{"ankle": 0.6, "cord": 0.3, "lanyard": 0.3, "strap": 0.3}, {"yes": 1}, {"blue": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["How is the boy attached to his board?", "Does this boy have a full wetsuit on?", "What color is the board?", "Is he wearing pants?"], "mscoco2": ["A young man is on his surf board with someone in the background. "]}}, {"img_id": "COCO_val2014_000000447854", "labelf": {"gqa": [{"yes": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"yellow": 1.0}, {"wall": 1.0}, {"wall": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"dress": 1.0}, {"no": 1.0}, {"table": 1.0}, {"cake": 1.0}, {"yes": 1.0}, {"dress": 1.0}, {"yes": 1.0}], "visual7w": [{"Bride's dress.": 1.0}, {"At a wedding reception.": 1.0}, {"Table.": 1.0}, {"Cake.": 1.0}, {"On the wall.": 1.0}, {"Lights.": 1.0}, {"Two.": 1.0}, {"The man.": 1.0}], "vqa": [{"bird": 0.9, "dog": 0.3, "fish": 1, "owl": 0.6}, {"cutting cake": 0.6}, {"3": 1, "4": 0.3}]}, "sentf": {"gqa": ["Is the cake the same color as the dress?", "Which side is the man on?", "Do you see lamps or vases?", "Which color is the table, yellow or gray?", "What is the lamp on?", "What's the lamp on?", "Are there men to the right of the cake?", "Is the picture to the right or to the left of the man?", "What is the clothing item that is white called?", "Are there any clocks on the wall?", "What is the cake on?", "What kind of dessert is on the table?", "Is the wall lamp on the left?", "What clothing item is white?", "Is there either a yellow bottle or table?"], "visual7w": ["What is white?", "Where was the photo taken?", "What is yellow?", "What has three tiers?", "Where is a painting?", "What is turned on?", "How many people are there?", "Who is wearing black?"], "vqa": ["On that wall, what is in that picture?", "What are the people holding?", "How many layers is the wedding cake?"], "mscoco2": ["A couple stands with small hatchets poised above a cake. "]}}, {"img_id": "COCO_val2014_000000070675", "labelf": {"vqa": [{"no": 1}, {"gray": 0.6, "red": 1, "silver": 0.3}, {"to see": 0.9, "yes": 0.3}]}, "sentf": {"vqa": ["Does the lady have a stun gun?", "What color is the remote button to the right of the woman's finger?", "Why is the woman wearing glasses?"], "mscoco2": ["older woman in glasses, pressing remote and coffee mug in foreground. "]}}, {"img_id": "COCO_val2014_000000172995", "labelf": {"vqa": [{"0": 1, "1": 1}, {"chicago": 0.9, "hot dog": 0.3, "new york": 0.3, "pickle": 0.9}, {}]}, "sentf": {"vqa": ["How many bites have been taken?", "What style of hot dog sandwich is this?", "What kind of pickle is on the hot dog?"], "mscoco2": ["A hot dog with a large pickle in someone's hand with a background of city buildings. "]}}, {"img_id": "COCO_val2014_000000015148", "labelf": {"vqa": [{"tennis": 1}, {"racket": 0.6, "racquet": 0.9, "tennis racket": 0.6, "tennis racquet": 0.6}, {"yes": 1}]}, "sentf": {"vqa": ["What are they taking a break from?", "What is on the floor leaning on the bench in between the people?", "Is there any green sign?"], "mscoco2": ["The couple is sitting down on the bench before playing a game of tennis. "]}}, {"img_id": "COCO_val2014_000000184386", "labelf": {"vqa": [{"no": 0.9, "yes": 1}, {"3": 0.6, "5": 0.3, "6": 0.3, "7": 1, "many": 0.3, "several": 0.3}, {"no": 1}, {"no": 1}, {"white": 1}]}, "sentf": {"vqa": ["Is the person who lives here a philosopher?", "How many objects on the counter?", "Are the pictures hung?", "Is there an apple computer in this picture?", "What color is the left wall?"], "mscoco2": ["a message poster with a bed and writing above it "]}}, {"img_id": "COCO_val2014_000000481596", "labelf": {"gqa": [{"no": 1.0}, {"bottom": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"hot dog": 1.0}, {"boy": 1.0}, {"yes": 1.0}, {"little": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"entrance": 1.0}, {"bracelet": 1.0}, {"cap": 1.0}, {"bottom": 1.0}], "visual7w": [{"Sunglasses.": 1.0}, {"Sports fan.": 1.0}, {"A hot dog.": 1.0}, {"To eat.": 1.0}, {"At a sporting event.": 1.0}, {"A polo shirt.": 1.0}, {"At a stadium.": 1.0}, {"Food.": 1.0}, {"Glasses.": 1.0}, {"Pepsi.": 1.0}, {"A hotdog.": 1.0}, {"In the stands.": 1.0}, {"Spectators.": 1.0}, {"Metal.": 1.0}, {"Woman wearing black.": 1.0}, {"Hotdog.": 1.0}, {"Sunglasses.": 1.0}, {"Brown.": 1.0}, {"Chairs.": 1.0}], "vqa": [{"yellow": 1}, {"no": 1}, {"hot dog": 1}]}, "sentf": {"gqa": ["Are there men to the right of the hot dog the bun is with?", "Where in the picture are the glasses, in the bottom or in the top?", "Does the person to the right of the boy wear a cap?", "On which side of the image is the hot dog?", "What is the food to the right of the man that is on the left?", "Who is younger, the woman or the boy?", "Are there any men to the left of the person that is wearing a shirt?", "How old is the boy?", "Do you see any palm trees to the left of the glasses?", "On which side is the bun?", "Where are the tags?", "What is the woman wearing?", "What clothing item is not gray?", "In which part of the photo is the palm, the bottom or the top?"], "visual7w": ["What is around the main sports fan's neck?", "Who is this?", "What does the man hold?", "Why does the man have the hot dog?", "Where is the man?", "What type of shirt does the man wear?", "Where was this photo taken?", "What is the closest person holding?", "What is hanging around the closest person's neck?", "What drink is advertised in the background?", "What kind of food is the man eating?", "Where are all the people sitting?", "What can be seen in the background?", "What are the railings made of?", "Who is directly behind the closest man?", "What does man have in hand?", "What does man have around neck?", "What is man hair color?", "What are people sitting on?"], "vqa": ["What color is the foul pole?", "Does this man have long hair?", "What is he eating?"], "mscoco2": ["A man holding a hot dog in his right hand."]}}, {"img_id": "COCO_val2014_000000274460", "labelf": {"vqa": [{"yes": 1}, {"blue": 0.3, "clothing": 0.3, "shirts": 0.3}, {"1": 0.3, "3": 0.3, "4": 0.6, "5": 1, "6": 0.3}]}, "sentf": {"vqa": ["Are they on the beach?", "What are all the bright colors in this picture?", "How many women are in the picture?"], "mscoco2": ["a group of people on a beach with buildings in the background and surfboards in the  foreground"]}}, {"img_id": "COCO_val2014_000000540681", "labelf": {"gqa": [{"shorts": 1.0}, {"jumping": 1.0}, {"no": 1.0}, {"white": 1.0}, {"racket": 1.0}, {"playing": 1.0}, {"jumping": 1.0}, {"shorts": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"white": 1.0}], "visual7w": [{"One.": 1.0}, {"In the air.": 1.0}, {"A man.": 1.0}, {"White.": 1.0}, {"Green.": 1.0}, {"Two.": 1.0}, {"During a tennis game.": 1.0}, {"During the daylight hours.": 1.0}, {"Tennis ball.": 1.0}, {"A tennis ball.": 1.0}, {"A tennis outfit.": 1.0}, {"The man.": 1.0}, {"Playing tennis.": 1.0}, {"A tennis racket.": 1.0}, {"On the ground.": 1.0}, {"Metal.": 1.0}, {"Behind the green canvas.": 1.0}, {"Watching the match.": 1.0}, {"A tennis racket.": 1.0}, {"Brown and green grass.": 1.0}, {"A tarp.": 1.0}, {"Green Fabric.": 1.0}, {"Playing tennis.": 1.0}], "vqa": [{"don't know": 0.3, "yes": 1}, {"tennis": 1}, {"nike": 0.3, "unknown": 0.3, "wilson": 1}, {"no": 1}, {"1": 0.9, "2": 1}]}, "sentf": {"gqa": ["What is the man that is jumping wearing?", "Does the person that is playing seem to be jumping or pointing?", "Is the color of the tennis racket different than the shoe?", "What color is the shirt?", "What does the man that is jumping hold?", "What is the man doing?", "What is he doing?", "What's the man wearing?", "Is the shoe red?", "Are there both rackets and balls in this picture?", "Which color is the racket?"], "visual7w": ["How many people play tennis?", "Where is the ball?", "Who is playing tennis?", "What color is his outfit?", "What color is the court?", "How many people in the photo?", "When is this taken?", "What time of day?", "What is the yellow object in air?", "What is the man reaching for?", "What is the man wearing?", "Who is wearing tennis shorts?", "What is the man doing?", "What is the man holding?", "Where is the white line?", "What is the pole made out of?", "Where is the dark grey wall?", "What is the official doing?", "What item is the man holding?", "What is on the ground?", "What is the green fabric?", "What is on the pole?", "What is the player doing?"], "vqa": ["Is this a professional match?", "What game is he playing?", "What brand of tennis racket is it?", "Is the person in the back wearing red?", "How many people are standing?"], "mscoco2": ["A man holding a tennis racquet in his left hand."]}}, {"img_id": "COCO_val2014_000000224647", "labelf": {"gqa": [{"blue": 1.0}, {"white": 1.0}, {"no": 1.0}, {"yellow": 1.0}, {"orange": 1.0}, {"boy": 1.0}, {"boy": 1.0}, {"racket": 1.0}, {"right": 1.0}, {"dress": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"sandal": 1.0}, {"sandal": 1.0}, {"girl": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"tennis ball": 1.0}, {"left": 1.0}, {"boy": 1.0}, {"tennis ball": 1.0}, {"racket": 1.0}, {"girl": 1.0}, {"yes": 1.0}, {"checkered": 1.0}, {"long": 1.0}, {"dress": 1.0}, {"no": 1.0}, {"boy": 1.0}], "visual7w": [{"Two.": 1.0}, {"One.": 1.0}, {"Yellow.": 1.0}, {"Blonde.": 1.0}, {"Orange and white.": 1.0}, {"Field.": 1.0}, {"Grass.": 1.0}, {"Green.": 1.0}], "vqa": [{"sandals": 1, "shoes": 0.3}, {"racket": 0.3, "tennis racket": 1, "tennis racquet": 0.6}, {"chevron": 0.6, "striped": 0.3, "wavy": 0.3, "yes": 0.3, "zig zag": 0.9}]}, "sentf": {"gqa": ["What is the color of the shirt?", "What color is the sandal that the girl wears?", "Are there either bags or benches in the image?", "Is the racket to the left of the boy yellow or black?", "The dress is what color?", "Who is wearing a shirt?", "Who is wearing the shirt?", "What is the girl that looks little carrying?", "On which side is the boy?", "What kind of clothing is orange?", "Does the curly hair look blond and long?", "Does the hair that looks long look blond?", "What's the girl wearing?", "What is the person to the left of the tennis ball wearing?", "Who is wearing a sandal?", "Is the person that is to the left of the tennis ball holding the racket?", "Is there either a black racket or baseball bat?", "Is the person that is to the right of the tennis racket holding a kite?", "What is the person that is to the right of the tennis racket holding?", "Is the little person to the left or to the right of the boy that is wearing a shirt?", "Who is holding the tennis ball?", "What is the boy holding?", "The girl is holding what?", "Who is holding the racket?", "Does the boy wear shorts?", "What's the pattern of the shorts?", "What is the length of the blond hair?", "What is the name of the orange clothing item?", "Are both these people female?", "Who walks in the grass?"], "visual7w": ["How many people are in the scene?", "How many tennis rackets are in the photo?", "What color is the tennis racket?", "What color is the little girl's hair?", "What color is the little girl's dress?", "Where is the little girl?", "What are these people standing on?", "What color is the grass?"], "vqa": ["What is on the little girls feet?", "What is the little girl holding?", "What pattern is her dress?"], "mscoco2": ["a little girl in an orange and white zig-zag pattern dress holding a tennis raquet with  a boy in the  background"]}}, {"img_id": "COCO_val2014_000000454457", "labelf": {"gqa": [{"pipe": 1.0}, {"no": 1.0}, {"air": 1.0}, {"yes": 1.0}, {"helmet": 1.0}, {"helmet": 1.0}, {"pipe": 1.0}, {"man": 1.0}, {"man": 1.0}, {"yes": 1.0}], "visual7w": [{"Two.": 1.0}, {"Daytime.": 1.0}, {"Blue.": 1.0}], "vqa": [{"railing": 0.3, "skate park": 0.6, "skatepark": 0.3, "stairs": 1, "steps": 0.3}, {"black": 1, "brown": 1}, {"brown": 1, "brown and black": 0.3, "gray": 0.3, "sepia": 0.3, "tan": 0.3}, {"no": 1}]}, "sentf": {"gqa": ["What's the man in front of?", "Are there any toilets in front of the pipe?", "What's the man in?", "Is the person in front of the pipe wearing a helmet?", "What is the man wearing?", "The person in front of the pipe is wearing what?", "What is the man in front of?", "Who is wearing a helmet?", "Who is wearing the helmet?", "Is the pipe behind the man?"], "visual7w": ["How many people do you see?", "When is the picture taken?", "What color is the wall?"], "vqa": ["Where is the man skateboarding?", "What color is the railing?", "What color are the steps?", "Is this an office building?"], "mscoco2": ["A young man skateboarding over a set of cement steps.  ", "A person jumping over a set of stairs with a skateboard. "]}}, {"img_id": "COCO_val2014_000000226967", "labelf": {"gqa": [{"coat": 1.0}, {"left": 1.0}, {"spectator": 1.0}, {"spectator": 1.0}, {"left": 1.0}, {"chair": 1.0}, {"no": 1.0}, {"green": 1.0}, {"no": 1.0}, {"right": 1.0}, {"no": 1.0}, {"right": 1.0}, {"no": 1.0}, {"no": 1.0}, {"blue": 1.0}, {"microphone": 1.0}, {"left": 1.0}, {"no": 1.0}, {"left": 1.0}, {"man": 1.0}, {"coat": 1.0}, {"white": 1.0}, {"coat": 1.0}], "visual7w": [{"Green.": 1.0}, {"To each other.": 1.0}, {"White.": 1.0}, {"Tennis.": 1.0}, {"Headset.": 1.0}, {"Day time.": 1.0}, {"At a tennis match.": 1.0}, {"Black.": 1.0}, {"Tennis racquet.": 1.0}, {"On a tennis court.": 1.0}, {"Blue.": 1.0}, {"Tennis court.": 1.0}, {"After game.": 1.0}, {"Players.": 1.0}, {"One.": 1.0}, {"Tennis equipment.": 1.0}, {"Green.": 1.0}, {"In the stands.": 1.0}, {"At a tennis game.": 1.0}, {"Seats.": 1.0}, {"Two.": 1.0}, {"To play tennis.": 1.0}, {"A net.": 1.0}, {"Seats.": 1.0}, {"Camera man.": 1.0}, {"Man on right.": 1.0}, {"Tennis racket.": 1.0}, {"Green and white.": 1.0}, {"Black.": 1.0}, {"Headphones.": 1.0}], "vqa": [{"tennis": 1}, {"court": 0.3, "field": 0.3, "in background": 0.3, "sitting": 0.3, "spectators": 0.3, "yes": 0.3}, {"over": 1}, {"adidas": 0.3, "nike": 1}]}, "sentf": {"gqa": ["What is the spectator wearing?", "Is the spectator to the right or to the left of the man that is holding the racket?", "Who is wearing a coat?", "Who is wearing the coat?", "Is the chair to the left or to the right of the man that is holding the tennis racket?", "What is the piece of furniture to the left of the man that is to the left of the camera called?", "Is the chair to the left of a plate?", "What color does the chair the man is to the right of have?", "Are there brown chairs?", "On which side of the picture is the microphone?", "Do you see spectators to the right of the man who holds the tennis racket?", "Is the camera to the left or to the right of the man that is to the right of the tennis racket?", "Do you see men to the left of the spectator on the left part?", "Are the net and the chair the same color?", "What color is the coat the spectator wears?", "What is the device to the right of the man that is holding the racket?", "On which side is the green chair, the right or the left?", "Is there a printer or a desk in this image?", "On which side is the tennis racket?", "Who wears a microphone?", "What kind of clothing is not white?", "What is the color of the shirt the man is in?", "What kind of clothing is not white?"], "visual7w": ["What is the color of the seating?", "How are the players facing?", "What is the net border color?", "What game is this?", "What is in the man ear?", "When is the picture taken?", "Where is the picture taken?", "What color is the man in the foreground's shorts?", "What is the man in the foreground holding?", "Where is the photo taken?", "What color is the camera man's shirt?", "Where is this picture taken?", "When is this picture taken?", "Who is holding a racket?", "How many spectators are wearing a white collared shirt?", "Why is there a net between the men?", "What color are the stands?", "Where are the sponsors labeled?", "Where does the scene take place?", "What is empty?", "How many players are pictured?", "Why are men holding rackets?", "What separates the players?", "What is green?", "Who has a headset on?", "Who has on a white shirt?", "What is black and white?", "What color are the stands?", "What color shorts are the men wearing?", "What is atop the man's head?"], "vqa": ["What sport is this?", "Where are the people in the stands?", "Is the match over or just starting?", "What brand of clothing is the man in blue wearing?"], "mscoco2": ["Two tennis players talking over the net on a tennis court "]}}, {"img_id": "COCO_val2014_000000294487", "labelf": {"gqa": [{"left": 1.0}, {"yes": 1.0}, {"material": 1.0}, {"drawer": 1.0}, {"large": 1.0}], "vqa": [{"wood": 0.3, "yes": 1}, {"canopy": 1, "twin": 0.6, "victorian": 0.3}, {"blanket": 0.3, "canopy": 1, "sheets": 0.3}]}, "sentf": {"gqa": ["Which side is the large drawer on?", "Is the drawer large and wooden?", "What is common to the post and the drawer?", "What type of furniture is made of the same material as the post?", "What is the size of the wood drawer?"], "vqa": ["Is the bed made?", "What type of bed is this?", "What covers the bed?"], "mscoco2": ["This bed has a canopy above it. "]}}, {"img_id": "COCO_val2014_000000180130", "labelf": {"vqa": [{"2": 1}, {"white": 1}, {"dinosaur": 0.6, "dragon": 1, "lobster": 0.3}]}, "sentf": {"vqa": ["How many people in the photo?", "What color shirt is the man wearing?", "What is on the cake?"], "mscoco2": ["A happy couple behind a cake on which a dragon figure is poised", "a couple celebrating a special occasion standing over a cake"]}}, {"img_id": "COCO_val2014_000000213455", "labelf": {"vqa": [{"air": 0.3, "park": 0.3, "skate park": 1, "skatepark": 0.3}, {"backwards": 1, "yes": 0.3}, {"flip": 0.9, "jumping": 0.6, "ollie": 0.6}, {"dc": 0.6, "nike": 0.6, "unknown": 0.3, "vans": 0.3}]}, "sentf": {"vqa": ["What location is the man skateboarding in?", "How is the man wearing his hat?", "What trick is he doing?", "What brand are his shoes?"], "mscoco2": ["The boy is midair and his skateboard is flipped under him. "]}}, {"img_id": "COCO_val2014_000000522163", "labelf": {"gqa": [{"poster": 1.0}, {"left": 1.0}, {"no": 1.0}, {"shelf": 1.0}, {"left": 1.0}, {"left": 1.0}, {"no": 1.0}, {"left": 1.0}, {"no": 1.0}, {"left": 1.0}], "vqa": [{"board": 0.3, "surfboard": 1}, {"no": 1}, {"no": 1}]}, "sentf": {"gqa": ["What is on the wall?", "Is the shelf to the left or to the right of the man?", "Do you see any ladies to the left of the man?", "What kind of furniture is to the left of the man?", "Which side of the photo is the book on?", "On which side of the image is the shelf?", "Is the man to the left of the shelf?", "On which side of the image is the bookshelf?", "Are there any tables or lamps in the photo?", "On which side of the picture is the bookshelf?"], "vqa": ["What is this person holding?", "Is this room neat and in order?", "Is this a tongue depressor?"], "mscoco2": ["the man holds a newly made surfboard before it is painted"]}}, {"img_id": "COCO_val2014_000000309859", "labelf": {"vqa": [{"red": 1, "red and white": 0.6}, {"no": 1}, {"no": 1}, {"cameraman": 0.9, "male": 0.3, "photographer": 0.6}, {"skateboard": 1}, {"2": 1, "3": 1}, {"no": 1, "yes": 0.3}]}, "sentf": {"vqa": ["What color is the skateboard?", "Is there water here?", "Is this a grayscale image?", "Aside from the skateboarder's, which other person's shadow is visible?", "What is the guy riding?", "How many chimneys do you see?", "Can you see his reflection?"], "mscoco2": ["A young male skateboarder leaps above his board in the street. "]}}, {"img_id": "COCO_val2014_000000343867", "labelf": {"vqa": [{"fans": 0.3, "no": 0.3, "spectators": 0.3, "woman": 0.6}, {"no": 0.3, "yes": 1}, {"knee pads": 0.3, "tape": 1}, {"no": 1}]}, "sentf": {"vqa": ["Who is wearing sunglasses?", "Is the guy a tennis player?", "What are around the player's knees?", "Is this a professional baseball game?"], "mscoco2": ["A tennis player finished his swing as people watch from behind him. "]}}, {"img_id": "COCO_val2014_000000282942", "labelf": {"gqa": [{"no": 1.0}, {"bottom": 1.0}, {"bottom": 1.0}, {"no": 1.0}, {"cake": 1.0}, {"lady": 1.0}, {"yes": 1.0}, {"lady": 1.0}, {"lady": 1.0}, {"lady": 1.0}, {"lady": 1.0}, {"window": 1.0}, {"right": 1.0}, {"white": 1.0}], "visual7w": [{"A knife.": 1.0}, {"Cut the cake.": 1.0}, {"A celebration.": 1.0}, {"A young woman.": 1.0}, {"White with pink.": 1.0}, {"On the table.": 1.0}, {"Cake.": 1.0}, {"On the table.": 1.0}, {"Brown.": 1.0}, {"Cake.": 1.0}, {"White.": 1.0}, {"Flowers.": 1.0}, {"Lights.": 1.0}, {"On the table.": 1.0}, {"A knife.": 1.0}, {"A shirt.": 1.0}, {"A t-shirt.": 1.0}, {"A window.": 1.0}, {"A knife.": 1.0}, {"She is cutting the cake.": 1.0}, {"A table full of food.": 1.0}, {"Christmas lights.": 1.0}, {"A large sheet cake.": 1.0}, {"A bracelet.": 1.0}, {"At a party.": 1.0}, {"A white bowl.": 1.0}], "vqa": [{"yes": 1}, {"cake": 1, "yes": 0.3}, {"yes": 1}]}, "sentf": {"gqa": ["Are there any men or kids?", "In which part of the photo is the bowl, the top or the bottom?", "In which part of the picture is the large dessert, the bottom or the top?", "Is there either a small cookie or cake?", "What dessert is to the left of the lady?", "Who is in front of the window?", "Is the bottle on the left side of the image?", "Who is wearing a bracelet?", "Who is wearing the bracelet?", "Who is wearing a shirt?", "Who is wearing the shirt?", "What is the lady in front of?", "On which side is the lady?", "Which color is the shirt, white or brown?"], "visual7w": ["What is she holding?", "What will she do?", "Why is there a cake?", "Who is holding the knife?", "What color is the cake?", "Where is the cake?", "What is the woman going to cut?", "Where is the cake?", "What shade is the woman's hair?", "What dessert is on the table?", "What shade is the icing?", "What decoration is on the cake?", "What is on in the room?", "Where is the cake located?", "What is the woman holding?", "What is white on the woman?", "What is the woman wearing?", "What is behind the woman?", "What is the woman holding?", "What is the woman doing?", "What is in front of the woman?", "What is hung along the wall?", "What is on the table?", "What is on the woman's wrist?", "Where was this picture taken?", "What is next to the cake?"], "vqa": ["Is the woman married?", "What is the woman cutting?", "Are there lights on the wall?"], "mscoco2": ["A woman stands over a cake with a knife."]}}, {"img_id": "COCO_val2014_000000313955", "labelf": {"vqa": [{"red": 0.3, "red and gray": 0.6, "red and white": 0.6}, {"catcher": 0.9, "looking": 0.3, "pitcher": 0.3, "side": 0.3}, {"umpire": 1}, {"yes": 1}]}, "sentf": {"vqa": ["What colors are this team's uniforms?", "Where is the batter looking?", "Who is behind the catcher?", "Is the Umpire Safe?"], "mscoco2": ["People watch a women's softball game from behind a chain link fence."]}}, {"img_id": "COCO_val2014_000000181303", "labelf": {"vqa": [{"vest": 1}, {"no": 1}, {"bag": 0.3, "kite": 1}]}, "sentf": {"vqa": ["What garment is the boy wearing over his yellow shirt?", "Is the boy crying?", "What is the boy holding above his head?"], "mscoco2": ["Small boy holding a kite over his head waiting."]}}, {"img_id": "COCO_val2014_000000247945", "labelf": {"gqa": [{"blue": 1.0}, {"left": 1.0}, {"shirt": 1.0}, {"yes": 1.0}], "visual7w": [{"A group of people.": 1.0}, {"For display.": 1.0}, {"Brick.": 1.0}, {"One.": 1.0}, {"On the pole.": 1.0}, {"Daytime.": 1.0}, {"Buildings.": 1.0}, {"Arched.": 1.0}], "vqa": [{"red": 0.3, "red and yellow": 0.3, "yellow and red": 0.3}, {"11:20": 0.3, "3:20": 0.3, "3:50": 0.3, "3:55": 0.3, "4:00": 0.3, "4:50": 0.3, "daytime": 0.3, "noon": 0.3}, {"no": 0.9, "yes": 1}]}, "sentf": {"gqa": ["What color is the shirt?", "On which side are the flags?", "What is the man wearing?", "Is the person in the bottom of the photo?"], "visual7w": ["Who is in the photo?", "Why is there a flag?", "What is the building made of?", "How many flags are shown?", "Where is the flag?", "When was the photo taken?", "What is in the background?", "What kind of doorway is visible?"], "vqa": ["What color is the flag?", "What time is it?", "Is that a fibonacci spiral on the side of the building?"], "mscoco2": ["A large clock hanging off the side of a building above a crowd."]}}, {"img_id": "COCO_val2014_000000079084", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}, {"red": 1.0}, {"no": 1.0}, {"right": 1.0}, {"bottom": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"girl": 1.0}, {"girl": 1.0}, {"jacket": 1.0}], "visual7w": [{"Playing tennis.": 1.0}, {"Tennis racquet.": 1.0}, {"Red.": 1.0}, {"Between crowd and player.": 1.0}, {"One.": 1.0}, {"No dog.": 1.0}, {"A man in crowd.": 1.0}, {"Day time.": 1.0}, {"A racket.": 1.0}, {"Tree.": 1.0}, {"Playing.": 1.0}, {"Tennis.": 1.0}, {"Add.": 1.0}, {"Board.": 1.0}, {"Watching.": 1.0}, {"Jacket.": 1.0}, {"A red tank top.": 1.0}, {"In the stands.": 1.0}, {"A black tennis racket.": 1.0}, {"A racket.": 1.0}, {"The woman playing tennis.": 1.0}, {"The tennis player.": 1.0}, {"Waiting for the ball.": 1.0}, {"The spectator.": 1.0}, {"A can.": 1.0}, {"Spectators.": 1.0}, {"Nike.": 1.0}, {"A woman.": 1.0}], "vqa": [{"6": 0.3, "7": 0.9, "8": 1, "several": 0.3}, {"1": 1}, {"head": 0.3, "unknown": 0.9, "wilson": 0.9}, {"bored": 0.3}, {"no": 1}, {"l": 0.3, "lexus": 1}]}, "sentf": {"gqa": ["Are there backpacks to the left of the man that is wearing a hat?", "Do you see any white hats or fences?", "Do you see both knee pads and rackets?", "Does the girl to the left of the man wear a boot?", "Are there any men to the left of the girl on the left?", "What color is the jacket that the girl wears?", "Do you see bags to the right of the woman on the right of the image?", "Is the beverage on the left side or on the right?", "Is the fence in the top part or in the bottom of the image?", "Are there any women or glasses in this image?", "Are there any chickens or pizza trays?", "Are there helmets to the left of the man that is wearing a hat?", "Is the girl to the left of a man?", "Who wears a jacket?", "Who wears the jacket?", "What does the girl to the left of the man wear?"], "visual7w": ["What is the person doing?", "What is in her hand?", "What color is players shirt?", "Where is the fence?", "How many players are shown?", "Why is the dog on the court?", "Who has on a red coat?", "When was this taken?", "What is the woman holding?", "What are in the ground?", "What is the woman doing?", "What is the game?", "What is in the side?", "What are in the ground?", "What are the people doing?", "What is the woman wearing?", "What shirt is the player wearing?", "Where is the standing male spectator?", "What is in the woman's hands?", "What is the woman holding?", "Who is wearing a white cap?", "Who is wearing a red tank?", "What is the player doing?", "Who is wearing a white hat and white top?", "What is the man holding in right hand?", "Who is watching the game?", "What brand of jacket is this?", "Who is wearing a tank top?"], "vqa": ["How many hats do you  see?", "How many people are wearing pink hat's?", "What brand racquet does she use?", "Are watchers interested to watch match or bored?", "Will they hit someone with a racket?", "Who is a sponsor of the tournament?"], "mscoco2": ["A tennis player facing left while standing in front of a banner on a fence"]}}, {"img_id": "COCO_val2014_000000001955", "labelf": {"vqa": [{"100": 0.3, "15": 0.3, "20": 0.6, "50": 0.3, "8": 0.3, "lot": 0.3}, {"cloudy": 1, "overcast": 0.6, "sunny": 0.3}, {"green": 1, "green and brown": 0.3}]}, "sentf": {"vqa": ["How many blue dots are on the kite?", "What kind of day is it?", "What color is the grass?"], "mscoco2": ["A girl flies a kite over her head. "]}}, {"img_id": "COCO_val2014_000000453273", "labelf": {"vqa": [{"pink": 0.3, "red": 1, "yellow": 0.3}, {"chicago": 0.3, "dc": 0.3, "london": 0.3, "new york": 0.3, "not sure": 0.3, "paris": 0.6, "washington dc": 0.3}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What color flower is growing from the larger concrete planter?", "What city is this?", "Is the tree very old?"], "mscoco2": ["The newel of a railing with a cemetery in the background. "]}}, {"img_id": "COCO_val2014_000000024601", "labelf": {"vqa": [{"yes": 1}, {"tennis": 1}, {"neither": 0.9, "no": 0.9}, {"man": 0.3, "referee": 0.3}, {"0": 0.3, "1": 1, "2": 0.3}, {"tennis": 1, "tennis court": 0.3}]}, "sentf": {"vqa": ["Will she hit the ball?", "What sport is this?", "Is this player Serena or Venus Williams?", "Who has on red?", "How many teams have players in this picture?", "What are they playing?"], "mscoco2": ["A woman swings her hand out to hit a ball as people are staring in the background. "]}}, {"img_id": "COCO_val2014_000000519471", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"dragon": 0.3}, {"yes": 1}, {}]}, "sentf": {"vqa": ["Is there a view of the beach?", "What is the website name?", "Is the monitor on?", "What is the name on the banner?"], "mscoco2": ["The view from a computer screen, overlooking a crowd of people below. "]}}, {"img_id": "COCO_val2014_000000533173", "labelf": {"vqa": [{"no": 1, "yes": 0.3}, {"yes": 1}, {"3": 1, "5": 0.3}]}, "sentf": {"vqa": ["Are those birds in the sky?", "Are people parasailing?", "How many people are standing?"], "mscoco2": ["A number of kites flying in the sky above the sand."]}}, {"img_id": "COCO_val2014_000000092020", "labelf": {"vqa": [{"drying": 0.3}, {"poodle": 1}, {"blue": 1}]}, "sentf": {"vqa": ["What is the person doing with a blow dryer?", "What type of dog is this?", "What is the color of the blow dry?"], "mscoco2": ["a person holding a blow dryer up to a dog sitting before the person."]}}, {"img_id": "COCO_val2014_000000566314", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"yes": 1}, {"stained glass": 1}]}, "sentf": {"vqa": ["Does this picture make you want to pray?", "Is the clock working?", "What are these type of windows called?"], "mscoco2": ["A clock below a stained glassed window with light coming in."]}}, {"img_id": "COCO_val2014_000000394449", "labelf": {"gqa": [{"right": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"ceiling": 1.0}, {"train station": 1.0}, {"train station": 1.0}, {"paper": 1.0}, {"shirt": 1.0}, {"bench": 1.0}, {"yes": 1.0}, {"top": 1.0}, {"paper": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"train station": 1.0}, {"no": 1.0}, {"no": 1.0}, {"no": 1.0}, {"train": 1.0}, {"no": 1.0}, {"no": 1.0}], "vqa": [{"1:40": 0.3, "8:05": 1}, {"no": 0.9, "yes": 1}, {"no": 1, "yes": 0.9}, {"bench": 1}, {"doorway": 0.3, "train": 1, "window": 0.3}]}, "sentf": {"gqa": ["On which side is the red vehicle?", "Does that train look modern and red?", "Are there either any benches or strollers in this image?", "What is the clock hanging from?", "Where is the train parked?", "This train is parked where?", "What's the man reading?", "What is the man wearing?", "What is the man sitting on?", "Does the bench to the right of the woman look green?", "Is the antique clock in the bottom part or in the top of the picture?", "What is the man to the right of the bench reading?", "On which side of the image is the man?", "Is this the train station?", "Which place is it?", "Are there both a train and a cab in the image?", "Are there any trash cans to the right of the empty bench?", "Is the color of the sign different than the door?", "What vehicle is it?", "Are there both balls and clocks in this photo?", "Do you see any doors in this image that are not green?"], "vqa": ["What time is shown on the clock?", "Is it hot outside?", "Is the road paved?", "What are they sitting on?", "What is behind the people on the bench?"], "mscoco2": ["People are sitting on a bench below a large clock. "]}}, {"img_id": "COCO_val2014_000000131856", "labelf": {"gqa": [{"no": 1.0}], "visual7w": [{"Two.": 1.0}, {"A hill.": 1.0}, {"Blue.": 1.0}, {"In the sky.": 1.0}, {"Green.": 1.0}, {"It is windy.": 1.0}, {"An ocean.": 1.0}, {"Parasails.": 1.0}, {"Clear.": 1.0}, {"Hill.": 1.0}, {"Water.": 1.0}, {"Calm.": 1.0}, {"Sky.": 1.0}, {"Water.": 1.0}, {"A person.": 1.0}, {"A person.": 1.0}, {"It is a little foggy.": 1.0}], "vqa": [{"no": 1, "yes": 0.3}, {"hill": 0.3, "island": 0.9, "mountain": 0.6, "mountains": 0.3, "yes": 0.3}, {"kite": 0.3, "kites": 1, "sail": 0.3}]}, "sentf": {"gqa": ["Do you see any flags?"], "visual7w": ["How many kits are seen?", "What is in the background?", "What color is the sky?", "Where are the kites?", "What color are the waters?", "Why are the kites flying?", "When was the phot taken?", "What is above the water?", "What is the condition of the sky?", "What is on the horizon?", "What are the parasails flying over?", "What is the state of the water?", "What is above the water?", "What is below the sky?", "Who is in the water?", "Who is holding the parasails?", "How clear is the sky?"], "vqa": ["Is it a cloudy day?", "What landform is in the distance?", "What is floating in the sky?"], "mscoco2": ["Kites flying over the water with someone watching below", "There are two kites that are flying over the water at a beach"]}}, {"img_id": "COCO_val2014_000000137678", "labelf": {"gqa": [{"roof": 1.0}, {"roof": 1.0}, {"no": 1.0}, {"no": 1.0}, {"bell tower": 1.0}, {"bottom": 1.0}, {"small": 1.0}, {"bell tower": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"bell": 1.0}, {"bell": 1.0}], "visual7w": [{"Daytime.": 1.0}, {"One.": 1.0}, {"Blue.": 1.0}, {"17.": 1.0}, {"Top of building.": 1.0}, {"Gray.": 1.0}, {"Black.": 1.0}], "vqa": [{"roman": 0.3}, {"no": 1, "yes": 1}, {"0": 0.9, "1": 1}]}, "sentf": {"gqa": ["What do you think does the bird stand on?", "What does the bird stand on?", "Is there either a large flag or balloon?", "Are there mirrors in this photo?", "What is the bell in?", "Is the clock in the top part or in the bottom of the picture?", "How large is the flag?", "Is that a castle or a bell tower?", "Are there both a bell tower and a clock in the photograph?", "Is the window wooden?", "What is in the building the clock is on the side of?", "What is in the bell tower?"], "visual7w": ["When was the photo taken?", "How many clocks are shown?", "What color is the sky?", "What number is on the bottom left of the clock?", "Where is the bell?", "What color is the door?", "What color is the clock face?"], "vqa": ["What number is on the clock?", "Is this a church?", "How many birds are in the picture?"], "mscoco2": ["Looking up at a bell tower over an outdoor clock"]}}, {"img_id": "COCO_val2014_000000451674", "labelf": {"vqa": [{"no": 1}, {"kite": 1}, {"no": 1}, {"building": 0.6, "kite": 1}, {"blue and red": 0.3, "white": 0.6, "yellow": 1}, {"car": 1, "sedan": 0.6}, {"cannot tell": 0.3, "no": 1, "yes": 0.3}, {"4": 1, "5": 0.9, "6": 0.6}]}, "sentf": {"vqa": ["Is there more than one taxi in the photo?", "What is up in the sky?", "Is he wearing goggles?", "What is in the distance?", "What color is the nearest streamer?", "What type of vehicle is parked?", "Is this a big city?", "How many people are visible?"], "mscoco2": ["A yellow kite flies high above a building and a small group of people.", "A kite flying over a street with a car and people.", "A yellow kite floats above people on a road. "]}}, {"img_id": "COCO_val2014_000000159112", "labelf": {"vqa": [{"no": 1, "yes": 0.3}, {"yes": 1}, {"feta": 0.6, "goat": 0.3, "mozzarella": 1}]}, "sentf": {"vqa": ["Do you typically see lemon on a pizza?", "Are there lemon slices on here?", "What kind of cheese is this?"], "mscoco2": ["Two lemon slices garnish a food topping of tomatoes and diced meat mixed with a white sauce and spread over crusty bread.  "]}}, {"img_id": "COCO_val2014_000000531135", "labelf": {"vqa": [{}, {"18": 1, "21": 0.3}, {"no": 1, "yes": 1}, {"yes": 1}]}, "sentf": {"vqa": ["What insurance company is advertised?", "How many lights on the large light pole?", "Is anyone on base?", "Has the pitcher thrown the ball?"], "mscoco2": ["A baseball game is being played before a crowd."]}}, {"img_id": "COCO_val2014_000000281882", "labelf": {"vqa": [{"coffee": 1}, {"cup": 0.3, "phone": 0.3, "shadow": 0.3, "window": 1, "windows": 0.9}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What drink is this?", "What is the reflection of on the table?", "Does this look good?"], "mscoco2": ["The cellphone is left out by the coffee cup. "]}}, {"img_id": "COCO_val2014_000000207538", "labelf": {"vqa": [{"no": 1}, {"above stove": 0.3, "kitchen": 0.9}, {"no": 1}, {"1": 1, "2": 0.6}, {"no": 0.9, "yes": 1}, {"10": 0.3, "100": 0.3, "1000": 0.6, "350": 0.3, "don't know": 0.3}, {"no": 1, "yes": 1}]}, "sentf": {"vqa": ["Is there a radio in the picture?", "Where is the microwave located?", "Is that a TV?", "How many electrical objects are visible?", "Is there a reflection in the microwave?", "What's the wattage on this microwave?", "Is the microwave in use?"], "mscoco2": ["A white microwave hangs above the oven under cabinets"]}}, {"img_id": "COCO_val2014_000000053949", "labelf": {"vqa": [{"no": 0.9, "yes": 1}, {"yes": 1}, {"tennis": 1}, {"3": 0.3, "tennis": 1}]}, "sentf": {"vqa": ["Are they discussing the distance of the ball from the line?", "At the end of each game, do most people shake hands?", "What game are they playing?", "What kind of rackets are they?"], "mscoco2": ["Tennis players shake hands over a tennis net. "]}}, {"img_id": "COCO_val2014_000000308531", "labelf": {"gqa": [{"right": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"park": 1.0}, {"no": 1.0}, {"car": 1.0}, {"trees": 1.0}, {"trees": 1.0}], "visual7w": [{"On the tower.": 1.0}, {"Blue.": 1.0}, {"One.": 1.0}, {"Green.": 1.0}, {"Clouds.": 1.0}, {"Daytime.": 1.0}, {"Clock.": 1.0}, {"Palm tree.": 1.0}, {"Palm trees.": 1.0}, {"Palm fronds.": 1.0}, {"A tall pink clock tower.": 1.0}, {"A sign.": 1.0}, {"Plants.": 1.0}, {"It is trimmed.": 1.0}, {"A flag.": 1.0}, {"A pole.": 1.0}, {"Clouds.": 1.0}, {"Afternoon.": 1.0}, {"During the daytime.": 1.0}, {"Outside somewhere.": 1.0}], "vqa": [{"3:45": 0.9, "4:45": 0.6, "9:20": 0.9}, {"yes": 1}, {"pink": 1, "purple": 0.3, "red": 0.9}]}, "sentf": {"gqa": ["On which side of the picture is the white vehicle?", "Is there a white flag or kite?", "Does the clock look white?", "Is it a park?", "Which place is it?", "Are there any fire hydrants?", "What kind of vehicle has the same color as the clock in the top part of the picture?", "What's in front of the car?", "What is in front of the vehicle that is parked in the sidewalk?"], "visual7w": ["Where is the clock?", "What color is the sign?", "How many towers are there?", "What color is the vegetation?", "What is in the sky?", "When is the photo taken?", "What kind of tower is this?", "What kind of tree branches are towards the top?", "What kind of trees are most prominent?", "What is seen at the top left and right?", "What is in the background?", "What is the blue object?", "What are the green objects?", "Why is the bush so perfectly shaped?", "What is hanging from the pole?", "What is on top of the building?", "What are the white things in the sky?", "What time is it?", "When was the photo taken?", "Where was the photo taken?"], "vqa": ["What time is it?", "Are there any signs outside?", "What color is the building with the clock?"], "mscoco2": ["a tall clock tower with bushes and trees in the foreground"]}}, {"img_id": "COCO_val2014_000000435389", "labelf": {"gqa": [{"yes": 1.0}, {"black": 1.0}, {"television": 1.0}, {"shelf": 1.0}, {"no": 1.0}, {"shelf": 1.0}], "visual7w": [{"6:04.": 1.0}, {"1.": 1.0}, {"On the wall.": 1.0}, {"On the shelf.": 1.0}, {"White.": 1.0}, {"Black.": 1.0}, {"Wood.": 1.0}, {"Beige.": 1.0}, {"A television.": 1.0}, {"White flowers.": 1.0}, {"6:05.": 1.0}, {"Television.": 1.0}, {"Shelf.": 1.0}, {"Keep flowers alive.": 1.0}, {"Power the television.": 1.0}, {"Box.": 1.0}, {"Right side of shelf.": 1.0}, {"Clock.": 1.0}, {"Flowers.": 1.0}, {"Wood.": 1.0}, {"TV.": 1.0}, {"6.": 1.0}, {"1.": 1.0}, {"On the wall.": 1.0}, {"Round.": 1.0}, {"On the clock.": 1.0}, {"On the wall.": 1.0}, {"The mantle.": 1.0}, {"In a vase.": 1.0}, {"On a gift bag.": 1.0}, {"On the mantle.": 1.0}, {"TV screen.": 1.0}, {"Around a pink box.": 1.0}], "vqa": [{"no": 1}, {"10": 0.3, "3": 0.6, "4": 0.9, "5": 0.6, "many": 0.3, "several": 0.3}, {"white": 1, "white and yellow": 0.3}, {"flowers": 1}, {"yes": 1}, {"1:30": 0.6, "6:05": 1}, {"clock": 0.9, "tv": 0.6}, {"can't tell": 0.3, "yes": 1}]}, "sentf": {"gqa": ["Are there either clocks or books in the scene?", "What is the color of the card?", "What device is mounted on the wall?", "Which kind of furniture is it?", "Do the card and the heart have the same color?", "What is the name of the piece of furniture that is shown in this picture?"], "visual7w": ["What time is it?", "How many screens are on the wall?", "Where is the clock?", "Where is the purple bag?", "What color is the clocks background?", "What color are the numbers on the clock?", "What is the frame of the clock made of?", "What color is the shelf?", "What is black and hanging from the wall?", "What is in the vase?", "What time is indicated?", "What is the black square?", "What is the vase on?", "Why is there water in the vase?", "Why is there a black wire?", "What is the pink ribbon on?", "Where is the gift bag?", "What has black hands?", "What has green leaves?", "What is the clock frame made of?", "What is the black object on the wall?", "What is the small hand on the clock pointing at?", "What is the long hand on the clock pointing at?", "Where is a clock?", "What shape is the clock?", "Where are numbers?", "Where is a television?", "What is made of wood?", "Where are flowers?", "Where is a heart?", "Where is a card?", "What is turned off?", "Where is a ribbon?"], "vqa": ["Is the television on?", "How many flowers are in each bucket?", "What color are the flowers to the right?", "What does the largest object to left of vase have in it?", "Is the TV hanging from the wall?", "What time is it?", "What is hanging on the wall?", "Is the time correct?"], "mscoco2": ["A TV is above the fake flowers, bag, and there is also a clock. "]}}, {"img_id": "COCO_val2014_000000199437", "labelf": {"visual7w": [{"Black.": 1.0}, {"Shirt.": 1.0}, {"Table.": 1.0}, {"Table.": 1.0}, {"Wall.": 1.0}, {"Wall.": 1.0}, {"Table.": 1.0}, {"Counter.": 1.0}, {"Table.": 1.0}, {"Oven.": 1.0}, {"Chef.": 1.0}, {"A white coat.": 1.0}, {"Pans.": 1.0}, {"Metal.": 1.0}, {"Amazing.": 1.0}, {"Tiles.": 1.0}, {"In a kitchen.": 1.0}, {"Preparing food.": 1.0}, {"On the black wall above the man.": 1.0}, {"To the right of the man.": 1.0}, {"On the black sign above the meat slicer.": 1.0}, {"In a bun.": 1.0}, {"Above the woman.": 1.0}, {"Meat slicer.": 1.0}, {"Tiny black tile.": 1.0}, {"On the table by the counter.": 1.0}], "vqa": [{}, {"no": 1, "yes": 0.3}, {"2": 0.9, "3": 1}, {"no": 0.3, "on wall": 1, "wall": 0.3}]}, "sentf": {"visual7w": ["What color is the tile behind the oven?", "What is the white item the man is wearing?", "Where is the meat slicer located?", "Where is the long silver pan located?", "Where is the oven located?", "Where is the sign located at?", "Where is the silver bread tin located at?", "Where is the lady chef standing behind?", "Where is the cutting machine located at?", "What is built into the wall?", "What career does the man have?", "What is the man wearing?", "What is on the the table?", "What are the pans made of?", "What does the text box on the wall say?", "What makes up the black wall?", "Where was the picture taken?", "What are the people doing?", "Where is the Market Choice sign?", "Where is the silver meat slicer?", "Where is the green writing?", "How is the woman's hair up?", "Where is the hanging light fixture?", "What is the stainless steel object to the right of the man?", "What kind of wall is in front of the man?", "Where is the long metal bin?"], "vqa": ["What does it say on the yellow sign?", "Are they all wearing different colors?", "How many cooks are in the kitchen?", "Where is the market choice sign \"Amazing\"?"], "mscoco2": ["A man and a woman behind the counter of a restaurant. "]}}, {"img_id": "COCO_val2014_000000140487", "labelf": {"gqa": [{"drinking": 1.0}, {"drinking": 1.0}, {"couch": 1.0}, {"couch": 1.0}, {"couch": 1.0}, {"couch": 1.0}, {"woman": 1.0}, {"no": 1.0}, {"bookcase": 1.0}, {"bookcase": 1.0}, {"couch": 1.0}, {"no": 1.0}, {"bike": 1.0}, {"right": 1.0}, {"no": 1.0}, {"drinking": 1.0}, {"bottom": 1.0}, {"couch": 1.0}, {"woman": 1.0}, {"couch": 1.0}, {"riding": 1.0}, {"right": 1.0}, {"no": 1.0}, {"no": 1.0}], "vqa": [{"man": 1, "man on left": 0.3}, {"drinking": 1, "sitting": 0.3}, {"yes": 1}]}, "sentf": {"gqa": ["What is the person to the right of the person doing?", "What is the man doing?", "What type of furniture is brown, the couch or the bookcase?", "What's the woman on?", "How is the piece of furniture that the woman is on called?", "Which kind of furniture is the woman on?", "Who is on the couch that looks gray and brown?", "Is there a couch that is white?", "What is the piece of furniture that is not brown?", "Which kind of furniture is not brown?", "Which kind of furniture is brown?", "Are there people to the right of the glasses in the top of the picture?", "What is the person that is riding riding?", "Is the woman on the left side or on the right of the picture?", "Is there a fence to the left of the man that is presented in the image?", "What is the woman doing?", "Is the skateboard in the top or in the bottom part?", "What kind of furniture is to the right of the skateboard?", "Who is sitting?", "What is the piece of furniture to the right of the person that rides a bike called?", "What is the person to the left of the couch doing?", "On which side of the picture is the bookcase?", "Is the bookcase to the right of coffee?", "Is there a bag to the left of the brown couch?"], "vqa": ["Who has a bike?", "What is the woman doing?", "Is it blurry?"], "mscoco2": ["A man rides his bike in a room while a person sits nearby and another stands behind the sofa. "]}}, {"img_id": "COCO_val2014_000000107389", "labelf": {"visual7w": [{"A woman.": 1.0}, {"Daytime.": 1.0}, {"On a tennis court.": 1.0}, {"Blue.": 1.0}, {"One.": 1.0}, {"Tennis.": 1.0}, {"Female.": 1.0}, {"Cap.": 1.0}, {"Woman's right hand.": 1.0}, {"161.": 1.0}, {"IBM.": 1.0}, {"Court.": 1.0}, {"To the left of the person.": 1.0}, {"Sneakers.": 1.0}, {"Tennis.": 1.0}, {"White cap.": 1.0}, {"White shoes and white socks.": 1.0}, {"White wristband.": 1.0}, {"Swing the racket.": 1.0}, {"IBM.": 1.0}, {"Tennis court.": 1.0}, {"Tennis Ball.": 1.0}, {"161.": 1.0}, {"Skirt.": 1.0}, {"Racket.": 1.0}, {"Hat.": 1.0}, {"Tennis.": 1.0}, {"Hard Court.": 1.0}], "vqa": [{}, {}, {"tennis": 1}, {"computers": 1, "ibm": 0.6}]}, "sentf": {"visual7w": ["Who is in the photo?", "When was the photo taken?", "Where is the woman?", "What color is the tennis court?", "How many people are there?", "What game is being shown?", "What is the gender of the player?", "What is on the woman's head?", "Where is the racket?", "What number is lit up?", "What letters are above the numbers 161?", "Where are the white lines?", "Where is the shadow?", "What type of shoes is the person wearing?", "What sport is being played?", "What is on the player's head?", "What is on the players feet?", "What is on the player's left wrist?", "What is the player about to do?", "What company's logo is featured over the digital readout?", "What is the player standing on?", "What is the woman hitting?", "What is the number under IBM?", "What type of bottom garment is the woman wearing?", "What is in the woman's hand?", "What is on the woman's head?", "What sport is the woman playing?", "What type of tennis court is the woman playing on?"], "vqa": ["What is the number under IBM?", "What is the number lit up under the 3 letters I B M?", "What sport is being played?", "What is the company identified by 3 letters known for?"], "mscoco2": ["A woman in a red tennis skirt and a white tank top holding a tennis racket behind her. "]}}, {"img_id": "COCO_val2014_000000277239", "labelf": {"vqa": [{"0": 0.6, "10": 0.6, "4": 0.3, "8": 0.3, "9": 1}, {"day": 1, "day time": 1, "daytime": 0.3}, {}]}, "sentf": {"vqa": ["How many people can be seated at the tables currently?", "Is it night time or day time?", "What is this room used for?"], "mscoco2": ["long tables with black chairs behind them "]}}, {"img_id": "COCO_val2014_000000127074", "labelf": {"gqa": [{"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"blue": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"no": 1.0}, {"standing": 1.0}, {"no": 1.0}, {"right": 1.0}, {"no": 1.0}, {"kite": 1.0}, {"gray": 1.0}, {"boy": 1.0}, {"brown": 1.0}, {"no": 1.0}, {"left": 1.0}, {"left": 1.0}, {"right": 1.0}, {"boy": 1.0}, {"boy": 1.0}], "visual7w": [{"A park.": 1.0}, {"A kite.": 1.0}, {"Yellow and pink.": 1.0}, {"Green.": 1.0}, {"Clear.": 1.0}, {"Daytime.": 1.0}, {"Blonde.": 1.0}], "vqa": [{"gray": 0.3, "multi": 0.3, "pink": 0.3, "tan": 1, "yellow": 0.9}, {"grass": 1}, {"background": 0.6, "below": 0.3, "grass": 0.6, "in background": 0.3, "on grass": 0.3, "stroller": 0.3}, {"fly": 0.3}]}, "sentf": {"gqa": ["Is the person to the left of the man holding a racket?", "Are there both bags and women in this photo?", "Is the stroller on the left side?", "What is the color of the stroller?", "On which side is the girl, the left or the right?", "Are there either any benches or kites in the image?", "Is the boy to the right or to the left of the person that is to the right of the man?", "Are there any chairs to the left of the person the bag is to the right of?", "What is the person to the right of the girl doing?", "Do you see any birds on the ground in the picture?", "Is the bag to the right or to the left of the person that is wearing shoes?", "Do the jeans look blue?", "What is the woman that is to the left of the man holding?", "Is the coat gray or red?", "Who stands on the grass in this picture?", "What color are the shoes the man is wearing?", "Is the person to the right of the stroller wearing skis?", "Is the man to the right or to the left of the girl?", "On which side of the picture is the kite, the left or the right?", "Is the man to the right or to the left of the kite?", "Which is younger, the boy or the woman?", "Who is standing?"], "visual7w": ["Where is this picture taken?", "What is the man in the foreground holding?", "What color is the man's kite?", "What color is the grass?", "How is the weather?", "When was this picture taken?", "What is the foreground man's hair color?"], "vqa": ["What color is the man's bow tie?", "What type of surface is the man standing on?", "Where are the baby carts?", "What is the man trying to do with the kite?"], "mscoco2": ["A man holding a kite with a sea of people behind him. "]}}, {"img_id": "COCO_val2014_000000091080", "labelf": {"vqa": [{"2": 0.3, "black": 1}, {"kitchen": 1}, {"1": 1, "2": 0.3}, {"kitchen": 1}, {"no": 1}, {"yes": 1}, {"0": 0.3, "1": 0.9, "2": 0.6, "3": 0.6, "4": 0.6}, {"10": 0.3, "12": 0.9, "13": 0.3, "14": 0.3, "8": 0.6, "9": 0.6}, {"cook": 1, "cooking": 0.3}, {"kettle": 1}]}, "sentf": {"vqa": ["What color is the microwave?", "What kind of room is this?", "How many handles does the black oven have?", "What room is this?", "Is something cooking?", "Do all these appliances still work?", "How many electronics are seen?", "How many cabinet doors are visible?", "What can you do in this room?", "What is on the stove?"], "mscoco2": ["A kitchen that has a brick wall as a background. "]}}, {"img_id": "COCO_val2014_000000420052", "labelf": {"gqa": [{"concrete": 1.0}, {"car": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"trash": 1.0}, {"refrigerator": 1.0}, {"no": 1.0}, {"clouds": 1.0}, {"yes": 1.0}, {"clean": 1.0}, {"large": 1.0}, {"no": 1.0}, {"bottom": 1.0}, {"blue": 1.0}], "visual7w": [{"The gate.": 1.0}], "vqa": [{"yes": 1}, {"asphalt": 1, "cement": 0.3, "gravel": 0.3, "lines": 0.3}, {"no": 1, "yes": 1}]}, "sentf": {"gqa": ["What is the sidewalk made of?", "What vehicle is to the left of the freezer that the litter is surrounding?", "Are there both refrigerators and dryers in the picture?", "Are there either any doors or cars in this image?", "What is the refrigerator surrounded by?", "What appliance is to the right of the car?", "Are there any black refrigerators or dishwashers?", "What is in the sky?", "Do the trash bags have white color?", "How clean is the road the freezer is on the side of?", "How large is the gate that is on the sidewalk?", "Are both the gate and the refrigerator the same color?", "Are the white bags in the bottom or in the top of the image?", "What color is the parked car on the road, blue or red?"], "visual7w": ["What is behind it?"], "vqa": ["Are there any cars on the road?", "What is the road paved with?", "Did someone get thrown out of their apartment?"], "mscoco2": ["Garbage left outside of a gate across the street fro homes. "]}}, {"img_id": "COCO_val2014_000000245440", "labelf": {"visual7w": [{"In the daytime.": 1.0}, {"Green.": 1.0}, {"Blue.": 1.0}], "vqa": [{"yes": 1}, {"no": 0.9, "yes": 1}, {"balloons": 0.6, "kites": 1}, {"no": 1, "yes": 0.3}, {"10": 1, "lot": 0.3}, {"air": 0.3, "in air": 0.3, "in sky": 0.6, "outside": 0.3, "sky": 1}, {"1": 1, "10": 0.9, "11": 0.3, "2": 0.3}, {"lake": 0.3, "outdoors": 0.3, "outside": 0.3, "park": 0.3, "river": 0.6}, {"kite": 0.3, "yes": 1}]}, "sentf": {"visual7w": ["When was this photo taken?", "What color is the grass?", "What color is the sky?"], "vqa": ["Is there grass in the scene?", "Is it daybreak?", "What is in the air?", "Is the sun setting?", "How many kites are in the sky?", "Where are the kites?", "How many strings hold the kite?", "Where was this picture taken?", "Is there a festival going on?"], "mscoco2": ["A bunch of kites are above a river", "some colorful kites flying in the air above a river "]}}, {"img_id": "COCO_val2014_000000140860", "labelf": {"vqa": [{"left": 1, "left side": 0.3, "right": 0.3}, {"basketball": 0.3, "black and white": 0.3, "blue and white": 0.3, "converse": 1}, {"carpet": 0.3, "floor": 1}]}, "sentf": {"vqa": ["What side of the laptop does the charger go in?", "What type of sneakers is the man wearing?", "What is the man sitting on?"], "mscoco2": ["A male college student sits on a classroom floor looking over notes with a laptop on his lap. "]}}, {"img_id": "COCO_val2014_000000173932", "labelf": {"vqa": [{"blender": 0.3, "blending": 1, "grinding": 0.3}, {"no": 0.3, "yes": 1}, {"blender": 0.6, "candle": 0.3, "container": 0.3, "jar": 0.3, "lid": 0.3, "mixer": 0.3, "no": 0.3}, {"red and white": 1, "white": 0.3, "white and red": 0.9}]}, "sentf": {"vqa": ["What is the appliance used for?", "Is there an outlet close by?", "What is the name of the large object at the top right?", "What colors are the buttons?"], "mscoco2": ["A blender sitting on a countertop with a jar over the blades "]}}, {"img_id": "COCO_val2014_000000392228", "labelf": {"gqa": [{"yes": 1.0}], "visual7w": [{"Wood.": 1.0}, {"On the roof.": 1.0}, {"Roman numerals.": 1.0}, {"Front of the building.": 1.0}, {"On top of building.": 1.0}, {"Gold.": 1.0}, {"Roman numerals.": 1.0}, {"White.": 1.0}, {"Weather vane.": 1.0}, {"Clock.": 1.0}, {"Roman.": 1.0}, {"5:36.": 1.0}, {"White.": 1.0}, {"Black.": 1.0}, {"A frame.": 1.0}, {"Bell tower.": 1.0}, {"1.": 1.0}, {"Clock face.": 1.0}, {"Black.": 1.0}, {"Yellow and black.": 1.0}, {"A high pitched roof.": 1.0}, {"Wood.": 1.0}, {"Overcast.": 1.0}, {"At 5:36.": 1.0}, {"Brown.": 1.0}, {"To the right.": 1.0}, {"A brown and yellow analog clock.": 1.0}, {"A clock.": 1.0}, {"White.": 1.0}, {"Wood.": 1.0}, {"Roman.": 1.0}, {"Gold.": 1.0}], "vqa": [{}, {"no": 1, "yes": 1}, {"weather vane": 1}]}, "sentf": {"gqa": ["Is the sky white?"], "visual7w": ["What is the trim made of?", "Where is the arrow?", "What is on the clock?", "What is the clock?", "Where is the weather vane?", "What color is the trim on clock?", "What type of numbers on clock?", "What color is the building?", "What is pointing in the sky?", "What is there telling time?", "What kind of numerals are on the clock?", "What time is it?", "What color is the building?", "What color are the clock hands?", "What shape is the roof?", "What is the weather vane on?", "How many beams below clock?", "Where is the gold circle?", "What color are the hands of the clock?", "What are the two main colors of the clock?", "What type of roof does the builidng have?", "What material are the accents of the builiding?", "How does the weather look in the photo?", "When was this photo taken?", "What color are the shingles on the tower?", "Where is the weathervane pointing?", "What type of clock is displayed?", "What is the round object on the building?", "What color is the building?", "What is the roof made of?", "What kind of numerals are on the clock?", "What color are the circles inside the clock?"], "vqa": ["What time does the clock face display?", "Is this a church?", "What is at the very top of the building?"], "mscoco2": ["a clock on a building with a sky background"]}}, {"img_id": "COCO_val2014_000000451859", "labelf": {"vqa": [{"barrier": 0.3, "benches": 0.3, "fence": 0.6, "kites": 0.3, "poles": 0.3, "trees": 0.3}, {"fish": 1, "lobster": 0.3, "shark": 0.6}, {"no": 1, "yes": 1}, {"10": 0.3, "11": 0.6, "12": 0.6, "15": 0.3, "18": 0.9}, {"1": 0.3, "2": 1}]}, "sentf": {"vqa": ["What is marking off the different areas of the field?", "What type of animal is depicted floating in the sky?", "Do the kites make the sky look like it's under the sea?", "How many kites do you see?", "How many people are in the picture?"], "mscoco2": ["a number of large kites flying in the sky over a field"]}}, {"img_id": "COCO_val2014_000000112997", "labelf": {"vqa": [{"cell phone": 0.6, "phone": 1}, {"motorola": 0.3, "someone": 0.3}, {}, {"no": 1}, {"black": 0.6, "gray": 1, "silver": 0.3}, {"10 years": 0.3, "older": 0.3, "very old": 0.6}]}, "sentf": {"vqa": ["What is the person holding in their hand?", "Who manufactures this item?", "What brand is the phone?", "Is this a house phone?", "What color is this phone?", "How old do you think this device is?"], "mscoco2": ["A person holding a walkie talkie in their left hand."]}}, {"img_id": "COCO_val2014_000000425227", "labelf": {"gqa": [{"green": 1.0}, {"gray": 1.0}, {"kites": 1.0}, {"no": 1.0}, {"no": 1.0}, {"outdoors": 1.0}, {"bottom": 1.0}], "visual7w": [{"Two.": 1.0}, {"Clouds.": 1.0}, {"A surfboard.": 1.0}, {"Beach.": 1.0}, {"Afternoon.": 1.0}, {"Flying a kite.": 1.0}, {"Daytime.": 1.0}, {"2.": 1.0}, {"It is overcast.": 1.0}, {"The beach.": 1.0}, {"Sand.": 1.0}, {"At the beach.": 1.0}, {"A kite.": 1.0}, {"Two.": 1.0}, {"Ocean.": 1.0}, {"Surfboard.": 1.0}, {"Kite.": 1.0}, {"Parasailing.": 1.0}, {"Brown.": 1.0}, {"2.": 1.0}, {"2.": 1.0}], "vqa": [{"blue": 0.9, "blue and white": 0.3, "gray": 1, "white": 0.3}, {"yes": 1}, {"no": 1, "yes": 0.6}, {}, {"beach": 1, "sand": 1}]}, "sentf": {"gqa": ["What color is the kite that is lying down?", "What is the color of the water?", "What is in the sky?", "Do you see any airplanes in the air?", "Is that water gray and choppy?", "Is it indoors or outdoors?", "In which part of the picture is the man, the top or the bottom?"], "visual7w": ["How many people are there?", "What is in the sky?", "What is he holding?", "Where are they?", "When was the photo taken?", "What are the people doing?", "What time is it?", "How many people are shown?", "Why is the sky grey?", "Where was this picture taken?", "What are the people standing on?", "Where are the people?", "What are the people flying?", "How many people are in the photograph?", "What is the water near?", "What kind of board is the person holding?", "What is the person flying?", "What is the person flying above the water doing?", "What color is the sand?", "How many people are shown?", "How many kites are in the air?"], "vqa": ["What is the color of the sky?", "Does this kite have a good height?", "Does the water look still?", "Is this a lake or a sea?", "What are the people standing on?"], "mscoco2": ["A being is doing something as of right now that is splendid. \n"]}}, {"img_id": "COCO_val2014_000000330535", "labelf": {"gqa": [{"yes": 1.0}, {"sky": 1.0}, {"building": 1.0}, {"yes": 1.0}, {"yes": 1.0}], "visual7w": [{"Top.": 1.0}, {"Balcony.": 1.0}, {"Rust.": 1.0}, {"Cloudy.": 1.0}, {"Daytime.": 1.0}, {"Trees.": 1.0}, {"Green.": 1.0}, {"Red.": 1.0}, {"Retaining water.": 1.0}, {"Green.": 1.0}, {"Green.": 1.0}, {"Green.": 1.0}, {"Tan.": 1.0}, {"White.": 1.0}, {"Good.": 1.0}, {"Sky is cloudy.": 1.0}, {"Good.": 1.0}, {"Tall.": 1.0}], "vqa": [{"no": 1, "yes": 1}, {"no": 1, "yes": 1}, {"elm": 0.3, "green": 0.3, "oak": 0.6}, {"church": 1, "living": 0.3, "museum": 0.3}]}, "sentf": {"gqa": ["Are there either any doors or windows that are closed?", "What is the building in front of?", "What is in front of the sky?", "Are there either round clocks or windows?", "Is the tall building behind the tree the leaves are on?"], "visual7w": ["Where are the steeples?", "What is in the middle of building?", "What is border color of building?", "Why the sky has two colors?", "When was photo taken?", "What is green?", "How are the trees colored?", "What is the building trim colored?", "What makes the clouds turn grey?", "What are the bushes colored?", "What are the plants colored?", "What are the tree leaves colored?", "What is the base color of the building?", "How are the clouds in the sky?", "How the image looks like?", "When is the image taken?", "How the image looks like?", "How the building looks like?"], "vqa": ["Is this a private home?", "Is there a clock on the tower?", "What kind of tree is in the middle?", "What is this building used for?"], "mscoco2": ["a white cloud sky above a large building"]}}, {"img_id": "COCO_val2014_000000199764", "labelf": {"gqa": [{"market": 1.0}, {"no": 1.0}, {"lady": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"market": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"market": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"blue": 1.0}], "visual7w": [{"The man.": 1.0}, {"Fresh roasted peanuts.": 1.0}, {"Two.": 1.0}, {"Fresh roasted peanuts.": 1.0}, {"Paper Bags.": 1.0}, {"Background.": 1.0}, {"Day time.": 1.0}, {"To hold peanuts.": 1.0}], "vqa": [{"wood": 1}, {"fresh": 0.3, "not sure": 0.3}, {"yes": 1}]}, "sentf": {"gqa": ["What type of place do you think it is?", "Are there ladies to the left of the person that is on the market?", "Who is holding the blue bag?", "Does the bag to the left of the box have brown color?", "Are there either any safety vests or dispensers?", "Which place is it?", "Are there mats or light bulbs?", "Are there tents to the left of the barn on the right side?", "Where is the guy?", "Are there any guys on the market?", "Is the guy on the right side or on the left?", "Do you see ladies to the left of the people in the market?", "Are there boxes to the right of the peanuts on the left side?", "Is the lady to the left of the people holding the blue bag?", "What color is the bag the lady is holding?"], "visual7w": ["Who is selling peanuts?", "What does the signs say?", "How many peanut signs are there?", "What is the man selling?", "What is in the box on the table?", "Where is the picnic table?", "When is the picture taken?", "Why are there paper bags?"], "vqa": ["What are the boxes around the table constructed of?", "What is written on the white sign hanging from the string?", "Is it possible that this event is a farmers market?"], "mscoco2": ["A man standing at a table behind a rope"]}}, {"img_id": "COCO_val2014_000000271117", "labelf": {"vqa": [{"10": 0.3, "12": 0.6, "14": 0.6, "15": 0.3, "17": 0.3, "21": 0.3, "3": 0.3}, {"no": 1, "yes": 0.9}, {"no": 0.6, "yes": 1}, {"orange": 0.3, "orange and yellow": 0.6, "yellow": 0.6}, {"yellow": 1}, {"no": 1, "yes": 0.9}]}, "sentf": {"vqa": ["How many items are on the table?", "Is this a student's desk?", "Is a clock useful in a kitchen?", "What color flowers are there?", "What color is the wall?", "Is there a cordless phone?"], "mscoco2": ["An organized table with shelf above including a telephone, flowers and alcohol. "]}}, {"img_id": "COCO_val2014_000000454623", "labelf": {"visual7w": [{"Natural lighting.": 1.0}, {"Picture is in black and white.": 1.0}, {"Third.": 1.0}, {"Cloudy.": 1.0}, {"Stone.": 1.0}, {"In a city.": 1.0}, {"Clock.": 1.0}, {"Entrance.": 1.0}, {"Cloc ktower.": 1.0}, {"Arch.": 1.0}, {"Statues.": 1.0}, {"Sky.": 1.0}, {"Third.": 1.0}], "vqa": [{"no": 1}, {"yes": 1}, {"2": 0.9, "3": 1}]}, "sentf": {"visual7w": ["How was this picture lit?", "Why is it hard to tell the colors?", "What level is the clock on?", "What is the weather like?", "What is the building made of?", "Where was this picture taken?", "What is on the building?", "What is the part?", "What part of the building?", "What is the type of the entrance?", "What are on top of the roof?", "Where are the clouds?", "What tier has the clock?"], "vqa": ["Is this modern architecture?", "Is this likely a church?", "How many tiers does the structure seen in the image have?"], "mscoco2": ["a tall clock tower with a sky background"]}}, {"img_id": "COCO_val2014_000000137809", "labelf": {"vqa": [{"1": 1, "2": 1, "3": 0.3}, {}, {"yes": 1}, {"3": 1, "4": 0.3}]}, "sentf": {"vqa": ["How many people are in this photo?", "What colors is the kite?", "Is it a sunny day?", "How many colors is the kite made of?"], "mscoco2": ["a kite flies through the air over a park area "]}}, {"img_id": "COCO_val2014_000000319228", "labelf": {"vqa": [{}, {"orange": 0.9, "yellow": 1}, {"keys": 0.3, "windows": 1}, {"at&t": 0.3, "nokia": 1, "verizon": 0.3}]}, "sentf": {"vqa": ["What is shown?", "What color is the lighter?", "What OS is used on the computer that the keyboard is attached to?", "What brand of mobile device is this?"], "mscoco2": ["A cellphone next to a lighter behind a keyboard. "]}}, {"img_id": "COCO_val2014_000000571920", "labelf": {"vqa": [{"12:40": 0.6, "12:45": 0.9, "1:40": 0.3}, {"yes": 1}, {"blue": 1}, {"1": 0.3, "2": 1}]}, "sentf": {"vqa": ["What time is shown on the clock?", "Are these domesticated animals?", "What color is the dog's backpack?", "How many dogs are shown?"], "mscoco2": ["Two women sitting under a clock with their dogs "]}}, {"img_id": "COCO_val2014_000000366723", "labelf": {"gqa": [{"desk": 1.0}, {"top": 1.0}, {"computer mouse": 1.0}, {"desk": 1.0}, {"desk": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"computer mouse": 1.0}, {"desk": 1.0}], "visual7w": [{"Right of the keyboard.": 1.0}, {"Keyboard.": 1.0}, {"Dell.": 1.0}, {"Desktop.": 1.0}, {"Mouse.": 1.0}, {"Desk.": 1.0}, {"Keyboard.": 1.0}, {"Mouse.": 1.0}, {"Armrest.": 1.0}, {"Desk.": 1.0}, {"Black and silver.": 1.0}, {"Keyboard.": 1.0}, {"Mouse.": 1.0}, {"Spacebar.": 1.0}, {"Keyboard.": 1.0}], "vqa": [{"dell": 1}, {"green": 0.3, "yes": 1}, {"no": 1, "yes": 0.9}]}, "sentf": {"gqa": ["What is the name of the item of furniture?", "Where in the image is the computer, in the top or in the bottom?", "What device is on the desk?", "What is the brown piece of furniture called?", "What piece of furniture is it?", "Are there both keyboards and desks in the scene?", "Are there printers or radios?", "What is the device that is to the right of the computer in the top of the picture?", "Which kind of furniture is wooden?"], "visual7w": ["Where is the computer mouse?", "What is this item?", "What brand monitor is this?", "What kind of computer is this?", "What is next to the keyboard?", "Where is the computer?", "What is under the monitor?", "What is to the right of keyboard?", "What is in front of the keyboard?", "Where is the computer?", "What is the pattern on the computer monitor?", "Where do people type at?", "What is being used to move around on the screen?", "What is being used to add spaces?", "What is used to type letters and numbers?"], "vqa": ["What brand is the monitor?", "Are the lights on the monitor and keyboard green?", "Is the space bar clean?"], "mscoco2": ["a keyboard sits under neath a monitor "]}}, {"img_id": "COCO_val2014_000000537027", "labelf": {"gqa": [{"yes": 1.0}, {"black": 1.0}, {"fire extinguisher": 1.0}, {"straw": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"no": 1.0}, {"closed": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"phone": 1.0}, {"fire extinguisher": 1.0}, {"no": 1.0}, {"phone": 1.0}, {"straw": 1.0}], "visual7w": [{"Black.": 1.0}, {"One.": 1.0}, {"Black.": 1.0}, {"Yellow.": 1.0}, {"One.": 1.0}], "vqa": [{"bar": 1, "restaurant": 0.3}, {"no": 1}, {"cell phone": 1, "glass": 0.3, "phone": 0.9}, {"gray": 1, "silver": 1}]}, "sentf": {"gqa": ["Is the man to the right of the extinguisher wearing glasses?", "Which color are the glasses?", "What is on the wall?", "What is in the cup?", "Is the telephone on the right of the picture?", "Does that shirt have black color?", "Do the shirt and the box have a different colors?", "Is the door closed and white?", "Is the door that looks brown closed or open?", "Is the extinguisher on the right side or on the left?", "Is the man holding a phone?", "Does the container that is to the right of the phone look black?", "Is the straw in a cup?", "What device is the man holding?", "What is on the wall made out of wood?", "Are there either doors or windows that are not closed?", "What device is to the left of the cup?", "What is in the cup he is holding?"], "visual7w": ["What color is man's shirt?", "How many drinks is the man holding?", "What color is the man's glasses?", "What color is the logo on shirt?", "How many straws are in the drink?"], "vqa": ["Where is this man?", "Is the man using a touchscreen phone?", "What is the man holding?", "What color is the man's phone?"], "mscoco2": ["A man holding a smart phone in his right hand."]}}, {"img_id": "COCO_val2014_000000163253", "labelf": {"vqa": [{"electric": 0.3, "gas": 1}, {"yes": 1}, {"right": 1}, {"no": 1}]}, "sentf": {"vqa": ["Is this an electric or a gas stove?", "Is the laptop powered on?", "Is the pot on the right or left burner?", "Is this in a restaurant?"], "mscoco2": ["A laptop on top of a steel over"]}}, {"img_id": "COCO_val2014_000000075725", "labelf": {"vqa": [{"no": 1, "yes": 1}, {"decorative": 0.3}, {"cross": 0.3, "flower": 0.3, "no": 0.3, "nothing": 1, "statue": 0.3}, {"yes": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["Do you think the light fixture has electricity?", "What do people most commonly do in this space?", "What does it say above the clock?", "Is this a church?", "Is this altar indoors?"], "mscoco2": ["A gold sculpture in a church and a wall design behind it. "]}}, {"img_id": "COCO_val2014_000000502220", "labelf": {"gqa": [{"left": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"kite": 1.0}, {"right": 1.0}, {"yes": 1.0}], "visual7w": [{"Blue.": 1.0}, {"A kite.": 1.0}, {"Green.": 1.0}], "vqa": [{"1": 1, "2": 0.6}, {"no": 1}, {"flying kite": 1, "kite flying": 0.3}, {"no": 1, "yes": 0.9}, {"yes": 1}, {"2": 1, "3": 0.3, "4": 0.9}]}, "sentf": {"gqa": ["Is the man on the left side or on the right?", "Are there chairs or drawers in the image?", "Is the chair behind a desk?", "What is in the sky?", "Is the small child to the right or to the left of the woman on the left?", "Does the shirt look long and black?"], "visual7w": ["What color is the sky?", "What is the flying object?", "What color are the trees in the background?"], "vqa": ["How many kites are there?", "Is it night time?", "What's the kid doing?", "Is the girl flying the plane?", "Was it taken during  daytime?", "How many chairs?"], "mscoco2": ["A person flying a kite over another person on a roof."]}}, {"img_id": "COCO_val2014_000000405348", "labelf": {"vqa": [{"apartments": 0.3, "brick": 0.3, "church": 0.6, "old": 0.3, "residential": 0.3}, {"yes": 1}, {"apartments": 1, "hotel": 1, "yes": 0.3}, {"0": 0.3, "10": 0.9, "2": 0.3, "3": 0.3, "5": 0.3, "6": 0.3, "9": 0.6}]}, "sentf": {"vqa": ["What kind of building is shown?", "Is there a clock on one of the buildings?", "Building shown is hotel or apartments?", "How many umbrellas do you see?"], "mscoco2": ["Several buildings right next to each other on a stet with a lot of people on it. "]}}, {"img_id": "COCO_val2014_000000340646", "labelf": {"gqa": [{"left": 1.0}, {"boy": 1.0}, {"woman": 1.0}, {"woman": 1.0}, {"no": 1.0}, {"people": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"right": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"no": 1.0}, {"kites": 1.0}, {"kites": 1.0}, {"woman": 1.0}, {"yes": 1.0}, {"green": 1.0}, {"down": 1.0}, {"man": 1.0}, {"no": 1.0}, {"man": 1.0}, {"shirt": 1.0}, {"no": 1.0}, {"right": 1.0}], "visual7w": [{"Blue.": 1.0}, {"Kites.": 1.0}, {"Green.": 1.0}, {"On the far right.": 1.0}, {"In the daytime?.": 1.0}, {"A building.": 1.0}, {"Orange and white.": 1.0}], "vqa": [{"cones": 1}, {"kite": 0.3, "kites": 1}, {"no": 1, "yes": 0.6}, {"100": 0.3, "20": 0.3, "38": 0.3, "48": 0.3, "50": 0.3, "lots": 0.3, "many": 0.3}]}, "sentf": {"gqa": ["Is the man to the left or to the right of the bag that is carried by the woman?", "Who is the woman to the right of the man holding?", "Who is holding the boy in the image?", "Who is carrying the bag?", "Are the people in the top part of the picture?", "Who in the scene is standing?", "Are there any kites in the sky?", "Is the man to the left or to the right of the woman that is carrying a bag?", "Is the man to the right or to the left of the orange cones?", "Are there both skis and kites in the image?", "Is the sky both blue and cloudy?", "Is the man to the left or to the right of the woman that is watching the kites?", "Is there any snowboard or fence in the scene?", "What is the sky full of?", "What is the blue sky full of?", "Who is walking?", "Is there a woman to the right of the boy?", "What color is the ground?", "Which direction is the person that is to the right of the woman looking at?", "Who is looking down?", "Are there any chairs to the right of the person that is wearing a shirt?", "Who wears the shirt?", "What does the man wear?", "Does the ground look grassy and brown?", "On which side of the photo is the man?"], "visual7w": ["What color is the sky?", "What is flying in the air?", "What color is the grass?", "Where is the little boy in the green shirt?", "When is this taking place?", "What structure is on the far right?", "What color are the traffic cones?"], "vqa": ["What is marking off the different areas of the field?", "What is flying in the sky?", "Does the kite on the ground match the ones in the air?", "How many kites are flying right now?"], "mscoco2": ["a number of kites flying over a field "]}}, {"img_id": "COCO_val2014_000000312412", "labelf": {"gqa": [{"left": 1.0}, {"glass": 1.0}, {"glass": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"left": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"yes": 1.0}, {"no": 1.0}, {"left": 1.0}, {"white": 1.0}, {"no": 1.0}, {"left": 1.0}, {"bottom": 1.0}, {"no": 1.0}, {"no": 1.0}, {"right": 1.0}, {"empty": 1.0}, {"liquid": 1.0}, {"no": 1.0}, {"blue": 1.0}, {"right": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"full": 1.0}, {"yes": 1.0}, {"yes": 1.0}, {"color": 1.0}, {"yes": 1.0}], "visual7w": [{"White.": 1.0}, {"7.": 1.0}, {"In the background.": 1.0}, {"An empty wine glass.": 1.0}, {"Bottles of wine.": 1.0}, {"Square food.": 1.0}, {"Square.": 1.0}, {"Rounded.": 1.0}, {"Wine.": 1.0}, {"Wine.": 1.0}, {"Wine bottles.": 1.0}, {"On the table.": 1.0}, {"Wood.": 1.0}, {"Picture.": 1.0}, {"Red wine.": 1.0}, {"Drinking glasses.": 1.0}, {"Plates.": 1.0}, {"On the table.": 1.0}, {"Olive oil.": 1.0}, {"Wine.": 1.0}, {"Short.": 1.0}, {"Dark.": 1.0}, {"A rack.": 1.0}, {"Pictures.": 1.0}, {"In semi-darkness.": 1.0}, {"Bread.": 1.0}, {"On the table.": 1.0}, {"A wine glass.": 1.0}, {"A wine bottle.": 1.0}, {"A wine bottle.": 1.0}, {"A wine glass.": 1.0}, {"A door.": 1.0}, {"The table.": 1.0}, {"A plate.": 1.0}, {"Cheese.": 1.0}], "vqa": [{"yes": 1}, {"wine": 1}, {"4": 0.3, "5": 0.9, "6": 1, "7": 0.3, "8": 0.3}]}, "sentf": {"gqa": ["Is the wine on the right or on the left side of the picture?", "What's the cup made of?", "What is the material of the cup?", "Are there both plates and wine glasses in the picture?", "Are there full bowls or wine glasses?", "Is the red drink to the left or to the right of the plate on the table?", "Are there wine bottles to the right of the bottle that is to the right of the picture?", "Is there a pepper to the left of the food that is to the left of the wine glass?", "Is the tray in the top of the image?", "Is the tray to the left of a donut?", "Is the small cup to the left or to the right of the plate that is to the left of the wine bottle?", "What color is the door, white or red?", "Is there any door in this picture that is not white?", "Which side of the picture is the pillow on?", "Is the cup in the bottom part or in the top of the photo?", "Are there both plates and knives in the image?", "Is the cup large and empty?", "Is the wine bottle on the left side or on the right of the photo?", "Does the cup look empty or full?", "What is in the wine glass on the right?", "Is the pillow to the left of tea?", "What color is the cap?", "Is the wine bottle to the right or to the left of the bottle the picture is to the left of?", "Do you see any plates or bottles?", "Is the tray to the left of the bottle on the table?", "Does the wine glass to the right of the plate seem to be full or empty?", "Is there a spoon or a cup in this image?", "Is there a bottle to the left of the wineglass that the liquid is in?", "What do the label and the cap have in common?", "Is the color of the door different than the label?"], "visual7w": ["What color is the placemat?", "How many wine bottles are there?", "Where are the wine bottles?", "What is on the place mat?", "What is on the table?", "What is on the plate?", "What shape do the plates have?", "How are the edges of the plates?", "What is in the glasses?", "What is in the bottles?", "What glass items have labels?", "Where are the glasses?", "What is the table made of?", "What is hanging on the wall?", "What type of wine is served?", "What is made of clear glass?", "What is the white glass item?", "Where are the plates?", "What is on the plate?", "What is in the glass?", "How is the glass?", "What are the bottles like?", "What is on the back of the table?", "What is on the wall?", "How is the pillow?", "What is with the oil?", "Where is the glass?", "What item has wine in it?", "What item has a white label?", "What item has a blue label?", "What item does not have wine in it?", "What item is used to let people in?", "What wooden item is displayed?", "What item is the cheese on?", "What food item is displayed?"], "vqa": ["Is there wine in any of the glasses?", "What is in the bottles?", "How many wine glasses are on the table?"], "mscoco2": ["some dirty dishes and used wine glasses rest on a table after a party has left. "]}}, {"img_id": "COCO_val2014_000000462289", "labelf": {"gqa": [{"lobster": 1.0}, {"lobster": 1.0}, {"yes": 1.0}, {"salad": 1.0}, {"yes": 1.0}, {"right": 1.0}, {"bowl": 1.0}, {"yes": 1.0}, {"salad": 1.0}, {"no": 1.0}, {"no": 1.0}, {"salad": 1.0}, {"yes": 1.0}, {"girl": 1.0}, {"green": 1.0}, {"no": 1.0}, {"no": 1.0}, {"salad": 1.0}, {"right": 1.0}, {"yes": 1.0}], "visual7w": [{"Sunny.": 1.0}, {"Daytime.": 1.0}], "vqa": [{"yes": 1}, {"lobster": 1}, {"yes": 1}]}, "sentf": {"gqa": ["What is the animal that the person that is to the left of the chair is eating?", "Which kind of animal is the girl eating?", "Are there any girls to the left of the chair that is to the left of the bowl?", "What is the food that the girl that is to the left of the chair is eating?", "Are there any chairs that are white?", "In which part is the green salad, the right or the left?", "What is on the table?", "Is the salad the same color as the grass?", "What food is the same color as the grass?", "Do the chair and the cup have the same color?", "Is the person to the left of the chair eating pasta?", "Which kind of food is the girl eating?", "Is there a television or a chair in this image?", "Who is eating the lobster?", "What color is the grass?", "Is the fork on the left?", "Is there any broccoli in the bowl to the right of the lobster?", "What is in the bowl the lobster is to the left of?", "On which side are the tools?", "Is there a cup to the right of the girl?"], "visual7w": ["What color is the weather?", "When was this?"], "vqa": ["Do you see a solo cup?", "What's in the bowl?", "Is the child smiling?"], "mscoco2": ["A girl sits at an outdoor table, there are lobsters in a bowl on the table, and trees and water in the background. "]}}, {"img_id": "COCO_val2014_000000239306", "labelf": {"vqa": [{"beige": 0.6, "brown": 0.6, "tan": 0.9, "white": 0.6}, {"no": 0.3, "yes": 1}, {"air": 0.3, "blue": 0.3, "lid": 0.6, "nothing": 0.9, "unknown": 0.3, "vase": 0.3}, {"vase": 0.3, "vases": 1}, {"no": 1, "yes": 1}, {"no": 0.3, "yes": 1}]}, "sentf": {"vqa": ["What color is the shelf?", "Is that art?", "What is on top of table in the vase?", "What are the blue and white items?", "Are these hand painted?", "Are tiles on the wall?"], "mscoco2": ["Three blue and white vase on a shelf against a patterned background. "]}}, {"img_id": "COCO_val2014_000000118846", "labelf": {"gqa": [{"purple": 1.0}, {"shirt": 1.0}, {"no": 1.0}, {"short sleeved": 1.0}, {"man": 1.0}, {"yes": 1.0}, {"man": 1.0}, {"top": 1.0}, {"black": 1.0}, {"hair": 1.0}, {"bottom": 1.0}, {"bottom": 1.0}, {"open": 1.0}], "visual7w": [{"Brown.": 1.0}, {"Black and silver.": 1.0}, {"One.": 1.0}, {"A man.": 1.0}, {"Morning.": 1.0}, {"In his backyard.": 1.0}, {"Scissors.": 1.0}, {"Cutting his hair.": 1.0}, {"Birds.": 1.0}, {"Rubber band.": 1.0}, {"Silver ring.": 1.0}, {"Cutting hair.": 1.0}, {"A man.": 1.0}, {"Outside a house.": 1.0}, {"His hair.": 1.0}, {"Birds.": 1.0}, {"A ring.": 1.0}, {"Earrings.": 1.0}, {"Open.": 1.0}, {"Arched.": 1.0}, {"Surprised.": 1.0}, {"Scissors.": 1.0}, {"Birds.": 1.0}, {"Buildings.": 1.0}], "vqa": [{"yes": 1}, {"hair": 0.3, "nowhere": 0.3}, {"birds": 1, "nothing": 0.6}, {"no": 1}, {"bird": 0.3, "birds": 0.3, "nothing": 0.9, "shirt": 1}, {"bird": 1, "birds": 1, "crow": 0.3, "seagull": 0.3}, {"yes": 1}, {"cutting": 1}]}, "sentf": {"gqa": ["What color is the shirt that the man is wearing?", "What is the purple clothing item in the picture?", "Do you see either women or chefs there?", "Is the shirt short sleeved or long sleeved?", "Who is wearing the ring?", "Is the shirt short sleeved and purple?", "Who is wearing a shirt?", "Are the scissors in the bottom part or in the top of the photo?", "What color do the scissors have?", "He is cutting what?", "Are the birds in the bottom or in the top part of the image?", "Is the bird in the top or in the bottom of the picture?", "How do the black eyes look, open or closed?"], "visual7w": ["What color is his hair?", "What color are the scissors?", "How many scissors are there?", "Who is cutting hair?", "When was picture taken?", "Where is the man?", "What is the man holding?", "What is the man doing?", "What animals are on the man's shirt?", "What is the purple item in the man's hair?", "What is on the ring finger of the man's right hand?", "Why is the man surprised or shocked?", "What is this photo of?", "Where is the man?", "What is on the man's head?", "What is on the man's shirt?", "What is on the man's finger?", "What is in the man's ears?", "How is the man's mouth?", "How are the man's eyebrow's?", "What kind of look is on the man's face?", "What is in the man's hand?", "What is on the man's shirt?", "What is in the background?"], "vqa": ["Is the man young?", "Where is the knife?", "What are the designs on the man's wrist?", "Does it look like it's probably night time in this scene?", "What does this man have on his shoulder?", "What animal is featured on this man's shirt?", "Does the man look surprised?", "What is the man doing to his hair?"], "mscoco2": ["A man holding scissors over his head getting ready to cut his hair "]}}, {"img_id": "COCO_val2014_000000522638", "labelf": {"visual7w": [{"Brown.": 1.0}, {"Brown and tan.": 1.0}, {"Next to the stuffed animal monkey.": 1.0}, {"Two.": 1.0}, {"Gray.": 1.0}], "vqa": [{"no": 1}, {"blue": 0.3, "brown": 1, "tan": 0.9}, {"1": 1, "2": 0.3}, {"bear": 0.3, "monkey": 1}]}, "sentf": {"visual7w": ["What color is the teddy bear?", "What color is the stuffed animal monkey?", "Where is the teddy bear?", "How many stuffed animals are there?", "What color is the backdrop?"], "vqa": ["Are both of the animals bears?", "What color are the  teddy bears?", "How many bears are there?", "What is the other animal?"], "mscoco2": ["Teddy bear next to monkey in foreground of picture. "]}}]